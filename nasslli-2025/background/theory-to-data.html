<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>The bridge from theory to data – Probabilistic dynamic semantics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-ec59717222d4d18488216d07f8bb4c3b.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-3c5b3ed224f457cdcbda003fac2adf13.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">
      Probabilistic dynamic semantics
      </li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Probabilistic dynamic semantics</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probabilistic dynamic semantics</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Background</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../background/traditional-methodology.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">From theory to data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../background/experimental-turn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The experimental turn</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../background/understanding-gradience.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Understanding gradience</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../background/case-studies.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Two case studies</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../background/new-frameworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The need for new frameworks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../background/theoretically-oriented-approach.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rational Speech Act models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../background/setting-stage.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setting the stage</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Introduction to probabilistic dynamic semantics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pds-intro/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pds-intro/ccg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Combinatory Categorial Grammar</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pds-intro/adding-probabilistic-types.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Adding probabilistic types</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pds-intro/common-ground.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The common ground</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pds-intro/expressions-and-discourses.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Expressions and discourses</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pds-intro/constants.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Constants</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../pds-intro/delta-rules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Delta rules</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Vagueness and imprecision</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../adjectives/adjectives-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vague gradable adjectives</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../adjectives/collecting-judgments.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Collecting inference judgments</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../adjectives/compiling-kernel-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Compiling kernel models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../adjectives/norming-model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Norming model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../adjectives/modeling-vagueness.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Modeling vagueness</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Factivity inferences</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../factivity/factivity-projection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Factivity and projection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../factivity/important-distinction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">An important distinction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../factivity/hypotheses.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Two competing hypotheses</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../factivity/experimental-paradigms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Experimental paradigms</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../factivity/additional-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Additional models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../factivity/additional-dimensions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exploring additional dimensions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../factivity/challenges-solutions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Implementation challenges and solutions</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#traditional-semantic-methodology-foundations-of-success" id="toc-traditional-semantic-methodology-foundations-of-success" class="nav-link active" data-scroll-target="#traditional-semantic-methodology-foundations-of-success">Traditional Semantic Methodology: Foundations of Success</a>
  <ul class="collapse">
  <li><a href="#observational-adequacy" id="toc-observational-adequacy" class="nav-link" data-scroll-target="#observational-adequacy">Observational Adequacy</a></li>
  <li><a href="#descriptive-adequacy-and-theoretical-depth" id="toc-descriptive-adequacy-and-theoretical-depth" class="nav-link" data-scroll-target="#descriptive-adequacy-and-theoretical-depth">Descriptive Adequacy and Theoretical Depth</a></li>
  <li><a href="#the-power-and-natural-boundaries-of-traditional-methods" id="toc-the-power-and-natural-boundaries-of-traditional-methods" class="nav-link" data-scroll-target="#the-power-and-natural-boundaries-of-traditional-methods">The Power and Natural Boundaries of Traditional Methods</a></li>
  </ul></li>
  <li><a href="#the-experimental-turn-new-opportunities-for-semantic-theory" id="toc-the-experimental-turn-new-opportunities-for-semantic-theory" class="nav-link" data-scroll-target="#the-experimental-turn-new-opportunities-for-semantic-theory">The Experimental Turn: New Opportunities for Semantic Theory</a>
  <ul class="collapse">
  <li><a href="#scaling-semantic-investigation" id="toc-scaling-semantic-investigation" class="nav-link" data-scroll-target="#scaling-semantic-investigation">Scaling Semantic Investigation</a></li>
  <li><a href="#teasing-apart-contributing-factors" id="toc-teasing-apart-contributing-factors" class="nav-link" data-scroll-target="#teasing-apart-contributing-factors">Teasing Apart Contributing Factors</a></li>
  <li><a href="#making-linking-hypotheses-explicit" id="toc-making-linking-hypotheses-explicit" class="nav-link" data-scroll-target="#making-linking-hypotheses-explicit">Making Linking Hypotheses Explicit</a></li>
  </ul></li>
  <li><a href="#understanding-gradience-a-taxonomy-of-uncertainty" id="toc-understanding-gradience-a-taxonomy-of-uncertainty" class="nav-link" data-scroll-target="#understanding-gradience-a-taxonomy-of-uncertainty">Understanding Gradience: A Taxonomy of Uncertainty</a>
  <ul class="collapse">
  <li><a href="#examples-of-potentially-unexpected-gradience" id="toc-examples-of-potentially-unexpected-gradience" class="nav-link" data-scroll-target="#examples-of-potentially-unexpected-gradience">Examples of Potentially Unexpected Gradience</a></li>
  <li><a href="#two-fundamental-types-of-uncertainty" id="toc-two-fundamental-types-of-uncertainty" class="nav-link" data-scroll-target="#two-fundamental-types-of-uncertainty">Two Fundamental Types of Uncertainty</a></li>
  <li><a href="#resolved-uncertainty-multiple-discrete-possibilities" id="toc-resolved-uncertainty-multiple-discrete-possibilities" class="nav-link" data-scroll-target="#resolved-uncertainty-multiple-discrete-possibilities">Resolved Uncertainty: Multiple Discrete Possibilities</a></li>
  <li><a href="#unresolved-uncertainty-gradient-within-interpretations" id="toc-unresolved-uncertainty-gradient-within-interpretations" class="nav-link" data-scroll-target="#unresolved-uncertainty-gradient-within-interpretations">Unresolved Uncertainty: Gradient Within Interpretations</a></li>
  <li><a href="#why-this-distinction-matters" id="toc-why-this-distinction-matters" class="nav-link" data-scroll-target="#why-this-distinction-matters">Why This Distinction Matters</a></li>
  </ul></li>
  <li><a href="#case-studies-testing-semantic-theory-at-scale" id="toc-case-studies-testing-semantic-theory-at-scale" class="nav-link" data-scroll-target="#case-studies-testing-semantic-theory-at-scale">Case Studies: Testing Semantic Theory at Scale</a>
  <ul class="collapse">
  <li><a href="#case-study-1-vagueness-and-gradable-adjectives" id="toc-case-study-1-vagueness-and-gradable-adjectives" class="nav-link" data-scroll-target="#case-study-1-vagueness-and-gradable-adjectives">Case Study 1: Vagueness and Gradable Adjectives</a></li>
  <li><a href="#case-study-2-factivity-and-projection" id="toc-case-study-2-factivity-and-projection" class="nav-link" data-scroll-target="#case-study-2-factivity-and-projection">Case Study 2: Factivity and Projection</a></li>
  </ul></li>
  <li><a href="#the-need-for-new-frameworks" id="toc-the-need-for-new-frameworks" class="nav-link" data-scroll-target="#the-need-for-new-frameworks">The Need for New Frameworks</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">The bridge from theory to data</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="hidden">
<p><span class="math display">\[
\newcommand{\expr}[3]{\begin{array}{c}
#1 \\
\bbox[lightblue,5px]{#2}
\end{array} ⊢ #3}
\newcommand{\ct}[1]{\bbox[font-size: 0.8em]{\mathsf{#1}}}
\newcommand{\updct}[1]{\ct{upd\_#1}}
\newcommand{\abbr}[1]{\bbox[transform: scale(0.95)]{\mathtt{#1}}}
\newcommand{\pure}[1]{\bbox[border: 1px solid orange]{\bbox[border: 4px solid transparent]{#1}}}
\newcommand{\return}[1]{\bbox[border: 1px solid black]{\bbox[border: 4px solid transparent]{#1}}}
\def\P{\mathtt{P}}
\def\Q{\mathtt{Q}}
\def\True{\ct{T}}
\def\False{\ct{F}}
\def\ite{\ct{if\_then\_else}}
\def\Do{\abbr{do}}
\]</span></p>
</div>
<p>Semantic theory has achieved remarkable success in characterizing the compositional structure of natural language meaning. Through decades of careful theoretical work, semanticists have developed elegant formal systems that capture how complex meanings arise from the systematic combination of simpler parts. These theories explain two fundamental types of judgments that speakers make: <em>acceptability judgments</em> about whether strings are well-formed, and <em>inference judgments</em> about what follows from what speakers say.</p>
<p>The field now stands at an exciting juncture. The rise of large-scale experimental methods and computational modeling opens new opportunities to test and refine these theoretical insights against rich behavioral data. The challenge—and opportunity—is to connect our elegant formal theories to the messy, gradient patterns we observe when hundreds of speakers make thousands of judgments. How can we maintain the theoretical insights that formal semantics has achieved while extending them to account for this new empirical richness?</p>
<p>Probabilistic Dynamic Semantics (PDS) aims to provide a systematic bridge between these theoretical insights and behavioral data. It takes the compositional analyses developed using traditional Montagovian methods and maps them to probabilistic models that can be quantitatively evaluated against experimental results. The goal is not to replace traditional semantics but to extend its reach, allowing us to test theoretical predictions at unprecedented scale while maintaining formal rigor.</p>
<section id="traditional-semantic-methodology-foundations-of-success" class="level2">
<h2 class="anchored" data-anchor-id="traditional-semantic-methodology-foundations-of-success">Traditional Semantic Methodology: Foundations of Success</h2>
<p>Semanticists study the systematic relationships between linguistic expressions and the inferences they support. The field’s methodology centers on two types of judgments:</p>
<p><strong>Acceptability judgments</strong> assess whether strings are well-formed relative to a language and in a particular context of use <span class="citation" data-cites="chomsky_syntactic_1957 schütze_gramaticality_2016">(<a href="#ref-chomsky_syntactic_1957" role="doc-biblioref">Chomsky 1957</a>; see <a href="#ref-schütze_gramaticality_2016" role="doc-biblioref">Schütze 2016</a>)</span>. <span id="exm-comitative-good"></span> <span id="exm-coordination-bad"></span> For example, in a context where a host asks what a guest wants with coffee, (1) is clearly acceptable, while (2) is not <span class="citation" data-cites="ross_constraints_1967">Sprouse and Villata (<a href="#ref-sprouse_island_2021" role="doc-biblioref">2021</a>)</span>:</p>
<ol class="example" type="1">
<li>What would you like with your coffee?</li>
<li>#What would you like and your coffee?</li>
</ol>
<p><strong>Inference judgments</strong> assess relationships between strings <span class="citation" data-cites="davis_semantics_2004">(see <a href="#ref-davis_semantics_2004" role="doc-biblioref">Davis and Gillon 2004</a>)</span>. <span id="exm-love-antecedent"></span> <span id="exm-veridicality-inference"></span> When speakers hear (3), they typically infer (4) <span class="citation" data-cites="white_lexically_2019">(<a href="#ref-white_lexically_2019" role="doc-biblioref">White 2019</a>)</span>:</p>
<ol start="3" class="example" type="1">
<li>Jo loved that Mo left.</li>
<li>Mo left.</li>
</ol>
<section id="observational-adequacy" class="level3">
<h3 class="anchored" data-anchor-id="observational-adequacy">Observational Adequacy</h3>
<p>A core desideratum for semantic theories is <em>observational adequacy</em> <span class="citation" data-cites="chomsky_current_1964">(<a href="#ref-chomsky_current_1964" role="doc-biblioref">Chomsky 1964</a>)</span>: for any string <span class="math inline">\(s \in \Sigma^*\)</span>, we should predict how acceptable speakers find it in context, and for acceptable strings <span class="math inline">\(s, s'\)</span>, we should predict whether speakers judge <span class="math inline">\(s'\)</span> inferable from <span class="math inline">\(s\)</span>. Achieving observational adequacy requires mapping vocabulary elements to abstractions that predict judgments parsimoniously.</p>
<p>These abstractions may be discrete or continuous, simple or richly structured. Through careful analysis of consistent inference patterns, semanticists have identified powerful generalizations. For instance, examining predicates like <em>love</em>, <em>hate</em>, <em>be surprised</em>, and <em>know</em>, theorists observed they all give rise to inferences about their complement clauses that survive under negation and questioning. This led to positing that they all share a property that predicts systematic inferential behavior across diverse predicates <span class="citation" data-cites="kiparsky_fact_1970 karttunen_observations_1971">(<a href="#ref-kiparsky_fact_1970" role="doc-biblioref">Kiparsky and Kiparsky 1970</a>; cf. <a href="#ref-karttunen_observations_1971" role="doc-biblioref">Karttunen 1971</a>)</span>.</p>
</section>
<section id="descriptive-adequacy-and-theoretical-depth" class="level3">
<h3 class="anchored" data-anchor-id="descriptive-adequacy-and-theoretical-depth">Descriptive Adequacy and Theoretical Depth</h3>
<p>Beyond observational adequacy lies <em>descriptive adequacy</em>: capturing data “in terms of significant generalizations that express underlying regularities in the language” <span class="citation" data-cites="chomsky_current_1964">(<a href="#ref-chomsky_current_1964" role="doc-biblioref">Chomsky 1964, 63</a>)</span>. This drive for deeper explanation motivates the field’s emphasis on parsimony and formal precision.</p>
<p>The history of generative syntax illustrates two approaches to achieving descriptive adequacy:</p>
<ol type="1">
<li><strong>Analysis-driven</strong>: Start with observationally adequate analyses in expressive formalisms, then extract generalizations as constraints</li>
<li><strong>Hypothesis-driven</strong>: Begin with constrained formalisms (like CCG or minimalist grammars) and test their empirical coverage</li>
</ol>
<p>The hypothesis-driven approach, which PDS adopts for semantics, aims to delineate phenomena through representational constraints. This becomes crucial when developing models that both accord with theoretical assumptions and can be evaluated quantitatively <span class="citation" data-cites="baroni_proper_2022 pavlick_symbols_2023">(<a href="#ref-baroni_proper_2022" role="doc-biblioref">Baroni 2022</a>; <a href="#ref-pavlick_symbols_2023" role="doc-biblioref">Pavlick 2023</a>)</span>.</p>
</section>
<section id="the-power-and-natural-boundaries-of-traditional-methods" class="level3">
<h3 class="anchored" data-anchor-id="the-power-and-natural-boundaries-of-traditional-methods">The Power and Natural Boundaries of Traditional Methods</h3>
<p>This methodology has yielded profound insights into semantic composition, scope phenomena, discourse dynamics, and the semantics-pragmatics interface more generally. By focusing on carefully constructed examples and native speaker intuitions, theorists have uncovered deep regularities in how meaning is constructed and interpreted.</p>
<p>Yet every methodology has natural boundaries. Traditional semantic methods excel at identifying patterns and building theories but face practical constraints when we ask:</p>
<ul>
<li>How well do our generalizations, based on examining 5-10 predicates, extend to the thousands of predicates in the lexicon?</li>
<li>What factors beyond semantic knowledge influence the judgments we observe?</li>
<li>How exactly does abstract semantic knowledge produce concrete behavioral responses?</li>
</ul>
</section>
</section>
<section id="the-experimental-turn-new-opportunities-for-semantic-theory" class="level2">
<h2 class="anchored" data-anchor-id="the-experimental-turn-new-opportunities-for-semantic-theory">The Experimental Turn: New Opportunities for Semantic Theory</h2>
<p>The traditional methodology’s success has created a foundation solid enough to support exciting new extensions. Experimental semantics brings the tools of behavioral experimentation to bear on questions about meaning, allowing us to test and refine theoretical insights at unprecedented scale.</p>
<section id="scaling-semantic-investigation" class="level3">
<h3 class="anchored" data-anchor-id="scaling-semantic-investigation">Scaling Semantic Investigation</h3>
<p>Where traditional methods might examine a handful of predicates, experimental approaches can investigate entire lexical domains. Extending our example involving the verb <em>love</em>: English has thousands of similar clause-embedding predicates, each potentially varying in its inferential properties. We can now test whether generalizations based on canonical examples extend across these vast lexicons.</p>
<p>The MegaAttitude project <span class="citation" data-cites="white_computational_2016 white_role_2018 white_lexicosyntactic_2018 white_frequency_2020 an_lexical_2020 moon_source_2020 kane_intensional_2022">(<a href="#ref-white_computational_2016" role="doc-biblioref">White and Rawlins 2016</a>, <a href="#ref-white_role_2018" role="doc-biblioref">2018</a>, <a href="#ref-white_frequency_2020" role="doc-biblioref">2020</a>; <a href="#ref-white_lexicosyntactic_2018" role="doc-biblioref">White et al. 2018</a>; <a href="#ref-an_lexical_2020" role="doc-biblioref">An and White 2020</a>; <a href="#ref-moon_source_2020" role="doc-biblioref">Moon and White 2020</a>; <a href="#ref-kane_intensional_2022" role="doc-biblioref">Kane, Gantt, and White 2022</a>)</span> is one example of this approach. This project aims to collect inference judgments for hundreds of predicates across multiple contexts and inference types. This scale reveals patterns that are very difficult to see and evaluate the quality of using traditional methods—subtle distinctions between near-synonyms, unexpected predicate clusters, and systematic variation across semantic domains.</p>
</section>
<section id="teasing-apart-contributing-factors" class="level3">
<h3 class="anchored" data-anchor-id="teasing-apart-contributing-factors">Teasing Apart Contributing Factors</h3>
<p>Experimental methods also allow us to investigate the rich array of factors that influence inference judgments:</p>
<ul>
<li><strong>Semantic knowledge</strong>: The core meanings of expressions</li>
<li><strong>World knowledge</strong>: Prior beliefs about plausibility<br>
</li>
<li><strong>Contextual factors</strong>: The discourse context and QUD</li>
<li><strong>Individual differences</strong>: Variation in how speakers interpret expressions</li>
<li><strong>Response strategies</strong>: How participants use rating scales</li>
</ul>
<p>Rather than viewing these as confounds, we can see them as windows into the cognitive processes underlying semantic interpretation. For instance, <span class="citation" data-cites="degen_prior_2021">Degen and Tonhauser (<a href="#ref-degen_prior_2021" role="doc-biblioref">2021</a>)</span> systematically manipulated world knowledge to show how prior beliefs modulate the strength of factive inferences, revealing the interplay between semantic and pragmatic factors.</p>
</section>
<section id="making-linking-hypotheses-explicit" class="level3">
<h3 class="anchored" data-anchor-id="making-linking-hypotheses-explicit">Making Linking Hypotheses Explicit</h3>
<p>Perhaps most importantly, experimental approaches force us to make explicit what traditional methods leave implicit: the link between semantic representations and behavioral responses <span class="citation" data-cites="jasbi_linking_2019 waldon_modeling_2020 phillips_theories_2021">(<a href="#ref-jasbi_linking_2019" role="doc-biblioref">Jasbi, Waldon, and Degen 2019</a>; <a href="#ref-waldon_modeling_2020" role="doc-biblioref">Waldon and Degen 2020</a>; <a href="#ref-phillips_theories_2021" role="doc-biblioref">Phillips et al. 2021</a>)</span>. When we say speakers judge that an inference follows, what cognitive processes produce that judgment? How do abstract semantic representations map onto the responses on some scale?</p>
<p>This is not merely a methodological detail—it’s a substantive theoretical question. Different linking hypotheses make different predictions about response patterns, allowing us to test not just our semantic theories but our assumptions about how those theories connect to behavior. Even if our real interest is in characterizing the semantic representations of speakers, we can’t ignore the way those representations map onto their responses in some task.</p>
</section>
</section>
<section id="understanding-gradience-a-taxonomy-of-uncertainty" class="level2">
<h2 class="anchored" data-anchor-id="understanding-gradience-a-taxonomy-of-uncertainty">Understanding Gradience: A Taxonomy of Uncertainty</h2>
<p>One of the most striking findings from experimental semantics is the pervasiveness of gradience in aggregated measures. While semanticists have long recognized the existence of gradience in some domains–e.g.&nbsp;gradable adjectives–we often assume categorical distinctions in other domains–e.g.&nbsp;factivity. And even where traditional approaches assume categorical distinctions, experimental methods often reveal continuous variation. For the reasons laid out above,understanding this gradience is crucial for developing theories that connect formal semantics to behavioral data.</p>
<section id="examples-of-potentially-unexpected-gradience" class="level3">
<h3 class="anchored" data-anchor-id="examples-of-potentially-unexpected-gradience">Examples of Potentially Unexpected Gradience</h3>
<p>The kinds of distributionally and inferentially defined properties we develop generalizations around are not always readily apparent in large-scale datasets. An example we will look at in-depth in our second case study of the course is that, when attempting to measure veridicality/factivity, we end up with more gradience than we might have expected. We can illustrate this using the MegaAttitude datasets.</p>
<p><a href="#fig-veridicality" class="quarto-xref">Figure&nbsp;1</a> shows veridicality judgments collected by <span class="citation" data-cites="white_role_2018">White and Rawlins (<a href="#ref-white_role_2018" role="doc-biblioref">2018</a>)</span> as part of their MegaVeridicality dataset.</p>
<div id="fig-veridicality" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-veridicality-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="plots/veridicality_factivity.png" class="img-fluid figure-img" width="750">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-veridicality-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Veridicality judgments collected by <span class="citation" data-cites="white_role_2018">White and Rawlins (<a href="#ref-white_role_2018" role="doc-biblioref">2018</a>)</span> as part of their MegaVeridicality dataset.
</figcaption>
</figure>
</div>
<p>One thing <span class="citation" data-cites="white_role_2018">White and Rawlins (<a href="#ref-white_role_2018" role="doc-biblioref">2018</a>)</span> note is the apparent gradience in these measures. This gradience presents a challenge if we want to use these measures to evaluate generalizations about the relationship between two properties. For instance, say we are interested in understanding the relationship betwen factivity and neg(ation)-raising. <span id="exm-negraising"></span> <span id="exm-negraising-inference"></span> A predicate is neg-raising if it gives rise to inferences of the form from (5) to (6):</p>
<ol start="5" class="example" type="1">
<li>Jo doesn’t think that Mo left.</li>
<li>Jo thinks that Mo didn’t leave.</li>
</ol>
<p>One way of deriving a factivity measure from the MegaVeridicality dataset is to take the max along both dimensions, as shown in <a href="#fig-derived-factivity" class="quarto-xref">Figure&nbsp;2</a>. The idea here is that, it will give rise to veridicality inferences with both positive and negative matrix polarity.</p>
<div id="fig-derived-factivity" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-derived-factivity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="plots/derived_factivity_measure.png" class="img-fluid figure-img" width="750">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-derived-factivity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: One way of deriving a factivity measure from the MegaVeridicality dataset.
</figcaption>
</figure>
</div>
<p>Now let’s suppose we’re interested in generalizations about the relationship between two measures. For instance, maybe want to evaluate the relationship between factivity and neg-raising, where we might tend to suspect that factives are not neg-raisers.</p>
<p><a href="#fig-negraising-factivity" class="quarto-xref">Figure&nbsp;3</a> shows a comparison of the measure of neg(ation)-raising from the MegaNegRaising dataset collected by <span class="citation" data-cites="an_lexical_2020">An and White (<a href="#ref-an_lexical_2020" role="doc-biblioref">2020</a>)</span> and the derived factivity measure from the MegaVeridicality dataset collected by <span class="citation" data-cites="white_role_2018">White and Rawlins (<a href="#ref-white_role_2018" role="doc-biblioref">2018</a>)</span>.</p>
<div id="fig-negraising-factivity" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-negraising-factivity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="plots/negraising_factivity.png" class="img-fluid figure-img" width="750">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-negraising-factivity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: A comparison of the measure of neg(ation)-raising from the MegaNegRaising dataset collected by <span class="citation" data-cites="an_lexical_2020">An and White (<a href="#ref-an_lexical_2020" role="doc-biblioref">2020</a>)</span> and the derived factivity measure from the MegaVeridicality dataset collected by <span class="citation" data-cites="white_role_2018">White and Rawlins (<a href="#ref-white_role_2018" role="doc-biblioref">2018</a>)</span>.
</figcaption>
</figure>
</div>
<p>The challenge is that, once we move to relating continuous measures, rather than categorical distinctions, we don’t know what the relationship between measures should look like in any particular case. To illustrate, let’s consider another example. <span class="citation" data-cites="anand_factivity_2014">Anand and Hacquard (<a href="#ref-anand_factivity_2014" role="doc-biblioref">2014</a>)</span> propose that, if a predicate gives rise to inferences about both beliefs and preferences, it backgrounds the belief inferences. To evaluate this hypothesis, we might try to derive a measure of belief inferences and preference inferences and then relate them.</p>
<p>To this end, we can use the MegaIntensionality dataset collected by <span class="citation" data-cites="kane_intensional_2022">Kane, Gantt, and White (<a href="#ref-kane_intensional_2022" role="doc-biblioref">2022</a>)</span>. <a href="#fig-belief" class="quarto-xref">Figure&nbsp;4</a> shows a measure of belief inferences and <a href="#fig-desire" class="quarto-xref">Figure&nbsp;5</a> shows a measure of desire inferences.</p>
<div id="fig-belief" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-belief-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="plots/belief.png" class="img-fluid figure-img" width="750">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-belief-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: A measure of belief inferences from the MegaIntensionality dataset collected by <span class="citation" data-cites="kane_intensional_2022">Kane, Gantt, and White (<a href="#ref-kane_intensional_2022" role="doc-biblioref">2022</a>)</span>.
</figcaption>
</figure>
</div>
<p>And <a href="#fig-desire-belief" class="quarto-xref">Figure&nbsp;6</a> shows a comparison of the desire and belief measures.</p>
<div id="fig-desire" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-desire-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="plots/desire.png" class="img-fluid figure-img" width="750">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-desire-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: A measure of desire inferences from the MegaIntensionality dataset collected by <span class="citation" data-cites="kane_intensional_2022">Kane, Gantt, and White (<a href="#ref-kane_intensional_2022" role="doc-biblioref">2022</a>)</span>.
</figcaption>
</figure>
</div>
<p><a href="#fig-desire-belief" class="quarto-xref">Figure&nbsp;6</a> show the relationship between these two measures.</p>
<div id="fig-desire-belief" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-desire-belief-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="plots/desire_belief.png" class="img-fluid figure-img" width="750">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-desire-belief-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: A comparison of the desire and belief measures from the MegaIntensionality dataset collected by <span class="citation" data-cites="kane_intensional_2022">Kane, Gantt, and White (<a href="#ref-kane_intensional_2022" role="doc-biblioref">2022</a>)</span>.
</figcaption>
</figure>
</div>
<p>There are two main takeaways from this example. First, the generalization proposed by@anand_factivity_2014 is indeed supported by the data. Second, the relationship between these two measures is strikingly different from the relationship we observe between the continuous measures of factivity and neg-raising. We need some way of theorizing about these continuous relationships.</p>
</section>
<section id="two-fundamental-types-of-uncertainty" class="level3">
<h3 class="anchored" data-anchor-id="two-fundamental-types-of-uncertainty">Two Fundamental Types of Uncertainty</h3>
<p>The framework we’ll explore distinguishes two general types of uncertainty that can produce gradience: <em>resolved</em> (or <em>type-level</em>) <em>uncertainty</em> and <em>unresolved</em> (or <em>token-level</em>) <em>uncertainty</em>, both of which can arise from multiple sources.</p>
<pre><code>Sources of Gradience in Inference Judgments
├── Resolved (Type-Level) Uncertainty
│   ├── Ambiguity
│   │   ├── Lexical (e.g., "run" = locomote vs. manage)
│   │   ├── Syntactic (e.g., attachment ambiguities)
│   │   └── Semantic (e.g., scope ambiguities)
│   └── Discourse Status
│       └── QUD (Question Under Discussion)
└── Unresolved (Token-Level) Uncertainty
    ├── Vagueness (e.g., height of a "tall" person)
    ├── World knowledge (e.g., likelihood that facts are true)
    └── Task effects
        ├── Response strategies
        └── Response error</code></pre>
</section>
<section id="resolved-uncertainty-multiple-discrete-possibilities" class="level3">
<h3 class="anchored" data-anchor-id="resolved-uncertainty-multiple-discrete-possibilities">Resolved Uncertainty: Multiple Discrete Possibilities</h3>
<p>Resolved uncertainty arises when speakers must choose among discrete interpretations. <span id="exm-uncle-running"></span> Consider (7):</p>
<ol start="7" class="example" type="1">
<li>My uncle is running the race.</li>
</ol>
<p>The verb <em>run</em> is ambiguous—the uncle might be a participant (locomotion) or the organizer (management). Asked “How likely is it that my uncle has good managerial skills?”, participants who interpret <em>run</em> as locomotion might respond near 0.2, while those interpreting it as management might respond near 0.8. The population average might be 0.5, but this reflects a <em>mixture</em> of discrete interpretations, not genuine gradience.</p>
<p>This uncertainty is “resolved” because once speakers fix an interpretation, the inference follows determinately. The gradience emerges from averaging across different resolutions, not from uncertainty within any single interpretation.</p>
<p>A similar phenomenon is observable with anaphora. <span id="exm-anaphora"></span> Consider (8):</p>
<ol start="8" class="example" type="1">
<li>Whenever anyone laughed, the magician scowled and their assistant smirked. They were secretly pleased.</li>
</ol>
<p>One is quite likely to infer from (8) that the magician’s assistant is secretly pleased, but not necessarily that the magician is pleased, even though, in principle, it may be that both are, or even that only the magician is. Ultimately, the ambiguity is resolved when we fix the referent.</p>
</section>
<section id="unresolved-uncertainty-gradient-within-interpretations" class="level3">
<h3 class="anchored" data-anchor-id="unresolved-uncertainty-gradient-within-interpretations">Unresolved Uncertainty: Gradient Within Interpretations</h3>
<p>Unresolved uncertainty contrasts with resolved uncertainty in that it persists even after fixing all ambiguities. <span id="exm-uncle-tall"></span> Consider (9):</p>
<ol start="9" class="example" type="1">
<li>My uncle is tall.</li>
</ol>
<p>Even with no ambiguity about <em>tall</em>’s meaning, speakers remain uncertain whether the uncle exceeds any particular height threshold. This is classic vagueness—the predicate’s application conditions are inherently gradient <span class="citation" data-cites="fine_vagueness_1975 graff_shifting_2000 kennedy_vagueness_2007 van_rooij_vagueness_2011 sorensen_vagueness_2023">(<a href="#ref-fine_vagueness_1975" role="doc-biblioref">Fine 1975</a>; <a href="#ref-graff_shifting_2000" role="doc-biblioref">Graff 2000</a>; <a href="#ref-kennedy_vagueness_2007" role="doc-biblioref">Christopher Kennedy 2007</a>; <a href="#ref-van_rooij_vagueness_2011" role="doc-biblioref">Rooij 2011</a>; <a href="#ref-sorensen_vagueness_2023" role="doc-biblioref">Sorensen 2023</a>)</span>.</p>
<p>World knowledge creates another layer: even knowing someone runs races (locomotion sense), we remain uncertain about their speed, endurance, or likelihood of finishing. These uncertainties appear within individual trials, not just across participants.</p>
</section>
<section id="why-this-distinction-matters" class="level3">
<h3 class="anchored" data-anchor-id="why-this-distinction-matters">Why This Distinction Matters</h3>
<p>The type of uncertainty has profound implications for semantic theory:</p>
<ul>
<li><strong>Resolved uncertainty</strong> suggests discrete semantic representations with probabilistic selection</li>
<li><strong>Unresolved uncertainty</strong> suggests gradient representations or probabilistic reasoning within fixed meanings</li>
</ul>
<p>Different phenomena may involve different uncertainty types. As we’ll see, vagueness seems to give rise to unresolved uncertainty (the conditions of application of <em>tall</em> seem inherently uncertain), while factivity’s gradience is perhaps more puzzling: is it resolved uncertainty from ambiguous predicates, or unresolved uncertainty in projection itself?</p>
</section>
</section>
<section id="case-studies-testing-semantic-theory-at-scale" class="level2">
<h2 class="anchored" data-anchor-id="case-studies-testing-semantic-theory-at-scale">Case Studies: Testing Semantic Theory at Scale</h2>
<p>To illustrate how PDS bridges formal semantics and experimental data, we’ll examine two case studies that exemplify different aspects of the framework.</p>
<section id="case-study-1-vagueness-and-gradable-adjectives" class="level3">
<h3 class="anchored" data-anchor-id="case-study-1-vagueness-and-gradable-adjectives">Case Study 1: Vagueness and Gradable Adjectives</h3>
<p>Vague predicates provide an ideal starting point because everyone agrees they involve gradient uncertainty. Expressions like <em>tall</em>, <em>expensive</em>, and <em>old</em> lack sharp boundaries—there’s no precise height at which someone becomes tall <span class="citation" data-cites="lakoff_hedges_1973 sadock_truth_1977 lasersohn_pragmatic_1999 krifka_approximate_2007 solt_vagueness_2015">(<a href="#ref-lakoff_hedges_1973" role="doc-biblioref">Lakoff 1973</a>; <a href="#ref-sadock_truth_1977" role="doc-biblioref">Sadock 1977</a>; <a href="#ref-lasersohn_pragmatic_1999" role="doc-biblioref">Lasersohn 1999</a>; <a href="#ref-krifka_approximate_2007" role="doc-biblioref">Krifka 2007</a>; <a href="#ref-solt_vagueness_2015" role="doc-biblioref">Solt 2015</a>)</span>.</p>
<p>Formal semantic theories have long recognized this gradience. Degree-based approaches <span class="citation" data-cites="klein_semantics_1980 bierwisch_semantics_1989 kamp_two_1975 kennedy_projecting_1999 kennedy_scale_2005 kennedy_vagueness_2007 barker_dynamics_2002">(<a href="#ref-klein_semantics_1980" role="doc-biblioref">Klein 1980</a>; <a href="#ref-bierwisch_semantics_1989" role="doc-biblioref">Bierwisch 1989</a>; <a href="#ref-kamp_two_1975" role="doc-biblioref">Kamp 1975</a>; <a href="#ref-kennedy_projecting_1999" role="doc-biblioref">Chris Kennedy 1999</a>; <a href="#ref-kennedy_scale_2005" role="doc-biblioref">Christopher Kennedy and McNally 2005</a>; <a href="#ref-kennedy_vagueness_2007" role="doc-biblioref">Christopher Kennedy 2007</a>; <a href="#ref-barker_dynamics_2002" role="doc-biblioref">Barker 2002</a>)</span> analyze gradable adjectives as expressing relations to contextual thresholds:</p>
<ul>
<li><em>tall</em> is true of <span class="math inline">\(x\)</span> if <span class="math inline">\(\ct{height}(x) \geq d_\text{tall}\)</span> (context)</li>
</ul>
<p>The threshold <span class="math inline">\(d_\text{tall}\)</span> varies with context—what counts as tall for a basketball player differs from tall for a child. But even within a fixed context, speakers show gradient judgments about borderline cases.</p>
<p>This makes vagueness ideal for demonstrating how PDS works. The framework can: - Maintain the compositional degree-based analysis from formal semantics - Add probability distributions over thresholds to capture gradient judgments - Model how context shifts these distributions - Link threshold distributions to slider scale responses</p>
<p>Recent experimental work reveals additional complexity. Different adjective types show distinct patterns: - <strong>Relative adjectives</strong> (<em>tall</em>, <em>wide</em>): Maximum gradience in positive form - <strong>Absolute adjectives</strong> (<em>clean</em>, <em>dry</em>): Different threshold distributions - <strong>Minimum vs.&nbsp;maximum standard</strong>: Asymmetric patterns of imprecision</p>
<p>These patterns both support and refine formal theories, showing how experimental data can advance theoretical understanding. Recent years have seen partial integration into computational models <span class="citation" data-cites="lassiter_context_2013 qing_gradable_2014 kao_nonliteral_2014 lassiter_adjectival_2017 bumford_rationalizing_2021">(<a href="#ref-lassiter_context_2013" role="doc-biblioref">Lassiter and Goodman 2013</a>, <a href="#ref-lassiter_adjectival_2017" role="doc-biblioref">2017</a>; <a href="#ref-qing_gradable_2014" role="doc-biblioref">Qing and Franke 2014</a>; <a href="#ref-kao_nonliteral_2014" role="doc-biblioref">Kao et al. 2014</a>; <a href="#ref-bumford_rationalizing_2021" role="doc-biblioref">Bumford and Rett 2021</a>)</span>. We’ll show that PDS allows us to synthesize and compare these different partial approaches.</p>
</section>
<section id="case-study-2-factivity-and-projection" class="level3">
<h3 class="anchored" data-anchor-id="case-study-2-factivity-and-projection">Case Study 2: Factivity and Projection</h3>
<p>While vagueness involves expected gradience, factivity presents a puzzle. Traditional theory treats factivity as discrete—predicates either trigger presuppositions or they don’t <span class="citation" data-cites="kiparsky_fact_1970 karttunen_observations_1971">(<a href="#ref-kiparsky_fact_1970" role="doc-biblioref">Kiparsky and Kiparsky 1970</a>; <a href="#ref-karttunen_observations_1971" role="doc-biblioref">Karttunen 1971</a>)</span>.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Yet experimental data reveals pervasive gradience.</p>
<p>A predicate is <em>factive</em> if it triggers inferences about its complement that project through entailment-canceling operators. <span id="exm-love-positive"></span> <span id="exm-love-negative"></span> <span id="exm-love-question"></span> <em>Love</em> appears factive because <em>Mo left</em> is inferrable from the standard family of sentences in (10)–(12):</p>
<ol start="10" class="example" type="1">
<li>Jo loves that Mo left.</li>
<li>Jo doesn’t love that Mo left.<br>
</li>
<li>Does Jo love that Mo left?</li>
</ol>
<p>But when <span class="citation" data-cites="white_role_2018">White and Rawlins (<a href="#ref-white_role_2018" role="doc-biblioref">2018</a>)</span> (discussed above) and <span class="citation" data-cites="degen_are_2022">Degen and Tonhauser (<a href="#ref-degen_are_2022" role="doc-biblioref">2022</a>)</span> collected projection judgments at scale, they found continuous variation <span class="citation" data-cites="xue_correlation_2011 smith_projection_2011 djarv_prosodic_2017">(<a href="#ref-xue_correlation_2011" role="doc-biblioref">Xue and Onea 2011</a>; <a href="#ref-smith_projection_2011" role="doc-biblioref">Smith and Hall 2011</a>; <a href="#ref-djarv_prosodic_2017" role="doc-biblioref">Djärv and Bacovcin 2017</a> also observe similar patterns)</span>. Qualitatively, <span class="citation" data-cites="degen_are_2022">Degen and Tonhauser (<a href="#ref-degen_are_2022" role="doc-biblioref">2022</a>)</span> argue that there is no clear line separates factive from non-factive predicates. Mean projection ratings vary continuously from <em>pretend</em> (lowest) to <em>be annoyed</em> (highest).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="plots/projection_no_fact_means.pdf" class="img-fluid" width="750"></p>
<figcaption>Aggregate factivity measures from <span class="citation" data-cites="degen_are_2022">Degen and Tonhauser (<a href="#ref-degen_are_2022" role="doc-biblioref">2022</a>)</span>, showing continuous variation in projection ratings across predicates under questioning.</figcaption>
</figure>
</div>
<p>This gradience poses a theoretical challenge <span class="citation" data-cites="simons_observations_2007 simons_what_2010 simons_best_2017 tonhauser_how_2018">(<a href="#ref-simons_observations_2007" role="doc-biblioref">Simons 2007</a>; <a href="#ref-simons_what_2010" role="doc-biblioref">Simons et al. 2010</a>, <a href="#ref-simons_best_2017" role="doc-biblioref">2017</a>; <a href="#ref-tonhauser_how_2018" role="doc-biblioref">Tonhauser, Beaver, and Degen 2018</a>)</span>.</p>
<p><span class="citation" data-cites="kane_intensional_2022">Kane, Gantt, and White (<a href="#ref-kane_intensional_2022" role="doc-biblioref">2022</a>)</span> later showed that this gradience is likely due to task effects. They demonstrate that when one applies a clustering model to these data that accounts for noise due to various factors, many of the standard subclasses of factives pop out. Some of these subclasses–e.g.&nbsp;the cognitive factives, which <span class="citation" data-cites="karttunen_observations_1971">Karttunen (<a href="#ref-karttunen_observations_1971" role="doc-biblioref">1971</a>)</span> observes to not always give rise factivity–appear to themselves be associated with non-necessary factive inferences.</p>
<p>In this case study, we’ll focus on understanding what gives rise to this gradience. We’ll consider two hypotheses that PDS allows us to state precisely and test against the data collected by <span class="citation" data-cites="degen_prior_2021">Degen and Tonhauser (<a href="#ref-degen_prior_2021" role="doc-biblioref">2021</a>)</span>, which uses the same experimental paradigm as <span class="citation" data-cites="degen_are_2022">Degen and Tonhauser (<a href="#ref-degen_are_2022" role="doc-biblioref">2022</a>)</span>:</p>
<p><strong>The Fundamental Discreteness Hypothesis</strong>: Factivity remains discrete; gradience reflects: - Multiple predicate senses (factive and non-factive variants) - Structural ambiguity affecting projection <span class="citation" data-cites="varlokosta_issues_1994 giannakidou_polarity_1998 giannakidou_affective_1999 giannakidou_dependency_2009 roussou_selecting_2010 farudi_antisymmetric_2007 abrusan_predicting_2011 kastner_factivity_2015 ozyildiz_attitude_2017">(<a href="#ref-varlokosta_issues_1994" role="doc-biblioref">Varlokosta 1994</a>; <a href="#ref-giannakidou_polarity_1998" role="doc-biblioref">Giannakidou 1998</a>, <a href="#ref-giannakidou_affective_1999" role="doc-biblioref">1999</a>, <a href="#ref-giannakidou_dependency_2009" role="doc-biblioref">2009</a>; <a href="#ref-roussou_selecting_2010" role="doc-biblioref">Roussou 2010</a>; <a href="#ref-farudi_antisymmetric_2007" role="doc-biblioref">Farudi 2007</a>; <a href="#ref-abrusan_predicting_2011" role="doc-biblioref">Abrusán 2011</a>; <a href="#ref-kastner_factivity_2015" role="doc-biblioref">Kastner 2015</a>; <a href="#ref-ozyildiz_attitude_2017" role="doc-biblioref">Ozyildiz 2017</a>)</span> - Contextual variation in whether complements are at-issue <span class="citation" data-cites="simons_best_2017 roberts_preconditions_2024 qing_rational_2016">(<a href="#ref-simons_best_2017" role="doc-biblioref">Simons et al. 2017</a>; <a href="#ref-roberts_preconditions_2024" role="doc-biblioref">Roberts and Simons 2024</a>; <a href="#ref-qing_rational_2016" role="doc-biblioref">Qing, Goodman, and Lassiter 2016</a>)</span></p>
<p><strong>The Fundamental Gradience Hypothesis</strong>: No discrete factivity property exists. Gradient patterns reflect different degrees to which predicates support complement truth inferences <span class="citation" data-cites="tonhauser_how_2018">(<a href="#ref-tonhauser_how_2018" role="doc-biblioref">Tonhauser, Beaver, and Degen 2018</a>)</span>.</p>
<p>PDS allows us to implement both hypotheses formally and test their predictions against fine-grained response distributions—not just means, but entire judgment patterns including multimodality that might indicate mixture distributions. We’ll show how this approach can be applied to judgment data aimed at capturing factivity using various experimental paradigms <span class="citation" data-cites="tonhauser_prosodic_2016 djarv_prosodic_2017 djarv_cognitive_2018 white_role_2018 white_lexicosyntactic_2018 white_believing_2021 degen_prior_2021 degen_are_2022 jeong_prosodically-conditioned_2021 kane_intensional_2022">(<a href="#ref-tonhauser_prosodic_2016" role="doc-biblioref">Tonhauser 2016</a>; <a href="#ref-djarv_prosodic_2017" role="doc-biblioref">Djärv and Bacovcin 2017</a>; <a href="#ref-djarv_cognitive_2018" role="doc-biblioref">Djärv, Zehr, and Schwarz 2018</a>; <a href="#ref-white_role_2018" role="doc-biblioref">White and Rawlins 2018</a>; <a href="#ref-white_lexicosyntactic_2018" role="doc-biblioref">White et al. 2018</a>; <a href="#ref-white_believing_2021" role="doc-biblioref">White 2021</a>; <a href="#ref-degen_prior_2021" role="doc-biblioref">Degen and Tonhauser 2021</a>, <a href="#ref-degen_are_2022" role="doc-biblioref">2022</a>; <a href="#ref-jeong_prosodically-conditioned_2021" role="doc-biblioref">Jeong 2021</a>; <a href="#ref-kane_intensional_2022" role="doc-biblioref">Kane, Gantt, and White 2022</a>)</span>.</p>
</section>
</section>
<section id="the-need-for-new-frameworks" class="level2">
<h2 class="anchored" data-anchor-id="the-need-for-new-frameworks">The Need for New Frameworks</h2>
<p>These case studies illustrate what we need from a framework connecting formal semantics to experimental data:</p>
<p><strong>Maintain Compositionality</strong>: Theories must derive complex meanings compositionally, preserving insights from decades of formal semantic research. We cannot abandon compositionality just because judgments are gradient.</p>
<p><strong>Model Uncertainty Explicitly</strong>: The framework must represent both types of uncertainty—resolved ambiguities and unresolved gradience—and show how they interact during interpretation.</p>
<p><strong>Make Linking Hypotheses Precise</strong>: We need explicit theories of how semantic representations produce behavioral responses. What cognitive processes intervene between computing a meaning and moving a slider?</p>
<p><strong>Enable Quantitative Evaluation</strong>: Theories must make testable predictions about response distributions, not just average ratings. Different theories should be comparable using standard statistical metrics.</p>
<p>As we’ll see in the next section, existing computational approaches like Rational Speech Act (RSA) models attempt to bridge formal semantics with probabilistic reasoning <span class="citation" data-cites="frank_predicting_2012 goodman_knowledge_2013">(<a href="#ref-frank_predicting_2012" role="doc-biblioref">Frank and Goodman 2012</a>; <a href="#ref-goodman_knowledge_2013" role="doc-biblioref">Goodman and Stuhlmüller 2013</a>)</span>. While valuable, these approaches face challenges in maintaining the modularity that makes formal semantic theories powerful. This motivates the development of Probabilistic Dynamic Semantics—a framework that preserves semantic insights while adding the probabilistic tools needed to model gradient behavioral data.</p>


<!-- -->


</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-abrusan_predicting_2011" class="csl-entry" role="listitem">
Abrusán, Márta. 2011. <span>“Predicting the Presuppositions of Soft Triggers.”</span> <em>Linguistics and Philosophy</em> 34 (6): 491–535.
</div>
<div id="ref-an_lexical_2020" class="csl-entry" role="listitem">
An, Hannah, and Aaron White. 2020. <span>“The Lexical and Grammatical Sources of Neg-Raising Inferences.”</span> <em>Proceedings of the Society for Computation in Linguistics</em> 3 (1): 220–33. https://doi.org/<a href="https://doi.org/10.7275/yts0-q989">https://doi.org/10.7275/yts0-q989</a>.
</div>
<div id="ref-anand_factivity_2014" class="csl-entry" role="listitem">
Anand, Pranav, and Valentine Hacquard. 2014. <span>“Factivity, <span>Belief</span> and <span>Discourse</span>.”</span> In <em>The <span>Art</span> and <span>Craft</span> of <span>Semantics</span>: <span>A</span> <span>Festschrift</span> for <span>Irene</span> <span>Heim</span></em>, edited by Luka Crni\v{c} and Uli Sauerland, 1:69–90. <span>MITWPL</span> 70. MITWPL. <a href="https://semanticsarchive.net/Archive/jZiNmM4N/">https://semanticsarchive.net/Archive/jZiNmM4N/</a>.
</div>
<div id="ref-barker_dynamics_2002" class="csl-entry" role="listitem">
Barker, Chris. 2002. <span>“The <span>Dynamics</span> of <span>Vagueness</span>.”</span> <em>Linguistics and Philosophy</em> 25 (1): 1–36. <a href="https://doi.org/10.1023/A:1014346114955">https://doi.org/10.1023/A:1014346114955</a>.
</div>
<div id="ref-baroni_proper_2022" class="csl-entry" role="listitem">
Baroni, Marco. 2022. <span>“On the <span>Proper</span> <span>Role</span> of <span>Linguistically</span> <span>Oriented</span> <span>Deep</span> <span>Net</span> <span>Analysis</span> in <span>Linguistic</span> <span>Theorising</span>.”</span> In <em>Algebraic <span>Structures</span> in <span>Natural</span> <span>Language</span></em>. CRC Press.
</div>
<div id="ref-bierwisch_semantics_1989" class="csl-entry" role="listitem">
Bierwisch, Manfred. 1989. <span>“The Semantics of Gradation.”</span> In <em>Dimensional Adjectives</em>, edited by Manfred Bierwisch and Ewald Lang, 71–261. Berlin: Springer-Verlag.
</div>
<div id="ref-bumford_rationalizing_2021" class="csl-entry" role="listitem">
Bumford, Dylan, and Jessica Rett. 2021. <span>“Rationalizing Evaluativity.”</span> <em>Proceedings of Sinn Und Bedeutung</em> 25 (September): 187–204. <a href="https://doi.org/10.18148/sub/2021.v25i0.931">https://doi.org/10.18148/sub/2021.v25i0.931</a>.
</div>
<div id="ref-chomsky_syntactic_1957" class="csl-entry" role="listitem">
Chomsky, Noam. 1957. <em>Syntactic <span>Structures</span></em>. The Hague/Paris: Mouton &amp; Co.
</div>
<div id="ref-chomsky_current_1964" class="csl-entry" role="listitem">
———. 1964. <span>“Current Issues in Linguistic Theory.”</span> In <em>The Structure of Language</em>, edited by J. Fodor and J. Katz, 50–118. New York: Prentice Hall.
</div>
<div id="ref-davis_semantics_2004" class="csl-entry" role="listitem">
Davis, Steven, and Brendan S Gillon. 2004. <em>Semantics: A Reader</em>. New York: Oxford University Press.
</div>
<div id="ref-degen_prior_2021" class="csl-entry" role="listitem">
Degen, Judith, and Judith Tonhauser. 2021. <span>“Prior <span>Beliefs</span> <span>Modulate</span> <span>Projection</span>.”</span> <em>Open Mind</em> 5 (September): 59–70. <a href="https://doi.org/10.1162/opmi_a_00042">https://doi.org/10.1162/opmi_a_00042</a>.
</div>
<div id="ref-degen_are_2022" class="csl-entry" role="listitem">
———. 2022. <span>“Are There Factive Predicates? <span>An</span> Empirical Investigation.”</span> <em>Language</em> 98 (3): 552–91. <a href="https://doi.org/10.1353/lan.0.0271">https://doi.org/10.1353/lan.0.0271</a>.
</div>
<div id="ref-djarv_prosodic_2017" class="csl-entry" role="listitem">
Djärv, Kajsa, and Hezekiah Akiva Bacovcin. 2017. <span>“Prosodic <span>Effects</span> on <span>Factive</span> <span>Presupposition</span> <span>Projection</span>.”</span> <em>Semantics and Linguistic Theory</em> 27 (0): 116–33. <a href="https://doi.org/10.3765/salt.v27i0.4134">https://doi.org/10.3765/salt.v27i0.4134</a>.
</div>
<div id="ref-djarv_cognitive_2018" class="csl-entry" role="listitem">
Djärv, Kajsa, Jérémy Zehr, and Florian Schwarz. 2018. <span>“Cognitive Vs. Emotive Factives: <span>An</span> Experimental Differentiation.”</span> In <em>Proceedings of <span>Sinn</span> Und <span>Bedeutung</span></em>, 21:367–86. <a href="https://ojs.ub.uni-konstanz.de/sub/index.php/sub/article/view/143">https://ojs.ub.uni-konstanz.de/sub/index.php/sub/article/view/143</a>.
</div>
<div id="ref-farudi_antisymmetric_2007" class="csl-entry" role="listitem">
Farudi, Annahita. 2007. <span>“An Antisymmetric Approach to <span>Persian</span> Clausal Complements.”</span> <em>Ms., University of Massachusetts, Amherst</em>.
</div>
<div id="ref-fine_vagueness_1975" class="csl-entry" role="listitem">
Fine, Kit. 1975. <span>“Vagueness, <span>Truth</span> and <span>Logic</span>.”</span> <em>Synthese</em> 30 (3/4): 265–300. <a href="https://www.jstor.org/stable/20115033">https://www.jstor.org/stable/20115033</a>.
</div>
<div id="ref-frank_predicting_2012" class="csl-entry" role="listitem">
Frank, Michael C., and Noah D. Goodman. 2012. <span>“Predicting <span>Pragmatic</span> <span>Reasoning</span> in <span>Language</span> <span>Games</span>.”</span> <em>Science</em> 336 (6084): 998–98. <a href="https://doi.org/10.1126/science.1218633">https://doi.org/10.1126/science.1218633</a>.
</div>
<div id="ref-giannakidou_polarity_1998" class="csl-entry" role="listitem">
Giannakidou, Anastasia. 1998. <em>Polarity Sensitivity as (Non) Veridical Dependency</em>. Vol. 23. John Benjamins Publishing.
</div>
<div id="ref-giannakidou_affective_1999" class="csl-entry" role="listitem">
———. 1999. <span>“Affective Dependencies.”</span> <em>Linguistics and Philosophy</em> 22 (4): 367–421.
</div>
<div id="ref-giannakidou_dependency_2009" class="csl-entry" role="listitem">
———. 2009. <span>“The Dependency of the Subjunctive Revisited: <span>Temporal</span> Semantics and Polarity.”</span> <em>Lingua</em> 119 (12): 1883–1908.
</div>
<div id="ref-goodman_knowledge_2013" class="csl-entry" role="listitem">
Goodman, Noah D., and Andreas Stuhlmüller. 2013. <span>“Knowledge and Implicature: Modeling Language Understanding as Social Cognition.”</span> <em>Topics in Cognitive Science</em> 5 (1): 173–84. <a href="https://doi.org/10.1111/tops.12007">https://doi.org/10.1111/tops.12007</a>.
</div>
<div id="ref-graff_shifting_2000" class="csl-entry" role="listitem">
Graff, Delia. 2000. <span>“Shifting <span>Sands</span>: <span>An</span> <span>Interest</span>-<span>Relative</span> <span>Theory</span> of <span>Vagueness</span>.”</span> <em>Philosophical Topics</em> 28 (1): 45–81. <a href="https://www.jstor.org/stable/43154331">https://www.jstor.org/stable/43154331</a>.
</div>
<div id="ref-jasbi_linking_2019" class="csl-entry" role="listitem">
Jasbi, Masoud, Brandon Waldon, and Judith Degen. 2019. <span>“Linking <span>Hypothesis</span> and <span>Number</span> of <span>Response</span> <span>Options</span> <span>Modulate</span> <span>Inferred</span> <span>Scalar</span> <span>Implicature</span> <span>Rate</span>.”</span> <em>Frontiers in Psychology</em> 10 (February). <a href="https://doi.org/10.3389/fpsyg.2019.00189">https://doi.org/10.3389/fpsyg.2019.00189</a>.
</div>
<div id="ref-jeong_prosodically-conditioned_2021" class="csl-entry" role="listitem">
Jeong, Sunwoo. 2021. <span>“Prosodically-Conditioned Factive Inferences in <span>Korean</span>: <span>An</span> Experimental Study.”</span> <em>Semantics and Linguistic Theory</em> 30 (0): 1–21. <a href="https://doi.org/10.3765/salt.v30i0.4798">https://doi.org/10.3765/salt.v30i0.4798</a>.
</div>
<div id="ref-kamp_two_1975" class="csl-entry" role="listitem">
Kamp, J. A. W. 1975. <span>“Two Theories about Adjectives.”</span> In <em>Formal <span>Semantics</span> of <span>Natural</span> <span>Language</span></em>, edited by Edward L. Keenan, 123–55. Cambridge: Cambridge University Press. <a href="https://doi.org/10.1017/CBO9780511897696.011">https://doi.org/10.1017/CBO9780511897696.011</a>.
</div>
<div id="ref-kane_intensional_2022" class="csl-entry" role="listitem">
Kane, Benjamin, Will Gantt, and Aaron Steven White. 2022. <span>“Intensional <span>Gaps</span>: <span>Relating</span> Veridicality, Factivity, Doxasticity, Bouleticity, and Neg-Raising.”</span> <em>Semantics and Linguistic Theory</em> 31 (0): 570–605. <a href="https://doi.org/10.3765/salt.v31i0.5137">https://doi.org/10.3765/salt.v31i0.5137</a>.
</div>
<div id="ref-kao_nonliteral_2014" class="csl-entry" role="listitem">
Kao, Justine T., Jean Y. Wu, Leon Bergen, and Noah D. Goodman. 2014. <span>“Nonliteral Understanding of Number Words.”</span> <em>Proceedings of the National Academy of Sciences</em> 111 (33): 12002–7. <a href="https://doi.org/10.1073/pnas.1407479111">https://doi.org/10.1073/pnas.1407479111</a>.
</div>
<div id="ref-karttunen_observations_1971" class="csl-entry" role="listitem">
Karttunen, Lauri. 1971. <span>“Some Observations on Factivity.”</span> <em>Paper in Linguistics</em> 4 (1): 55–69. <a href="https://doi.org/10.1080/08351817109370248">https://doi.org/10.1080/08351817109370248</a>.
</div>
<div id="ref-kastner_factivity_2015" class="csl-entry" role="listitem">
Kastner, Itamar. 2015. <span>“Factivity Mirrors Interpretation: <span>The</span> Selectional Requirements of Presuppositional Verbs.”</span> <em>Lingua</em> 164: 156–88.
</div>
<div id="ref-kennedy_projecting_1999" class="csl-entry" role="listitem">
Kennedy, Chris. 1999. <em>Projecting the Adjective: The Syntax and Semantics of Gradability and Comparison</em>. New York: Garland.
</div>
<div id="ref-kennedy_vagueness_2007" class="csl-entry" role="listitem">
Kennedy, Christopher. 2007. <span>“Vagueness and Grammar: The Semantics of Relative and Absolute Gradable Adjectives.”</span> <em>Linguistics and Philosophy</em> 30 (1): 1–45. <a href="https://doi.org/10.1007/s10988-006-9008-0">https://doi.org/10.1007/s10988-006-9008-0</a>.
</div>
<div id="ref-kennedy_scale_2005" class="csl-entry" role="listitem">
Kennedy, Christopher, and Louise McNally. 2005. <span>“Scale <span>Structure</span>, <span>Degree</span> <span>Modification</span>, and the <span>Semantics</span> of <span>Gradable</span> <span>Predicates</span>.”</span> <em>Language</em> 81 (2): 345–81. <a href="https://doi.org/10.1353/lan.2005.0071">https://doi.org/10.1353/lan.2005.0071</a>.
</div>
<div id="ref-kiparsky_fact_1970" class="csl-entry" role="listitem">
Kiparsky, Paul, and Carol Kiparsky. 1970. <span>“<span>FACT</span>.”</span> In <em>Progress in <span>Linguistics</span></em>, 143–73. De Gruyter Mouton. <a href="https://doi.org/10.1515/9783111350219.143">https://doi.org/10.1515/9783111350219.143</a>.
</div>
<div id="ref-klein_semantics_1980" class="csl-entry" role="listitem">
Klein, Ewan. 1980. <span>“A Semantics for Positive and Comparative Adjectives.”</span> <em>Linguistics and Philosophy</em> 4 (1): 1–45. <a href="https://doi.org/10.1007/BF00351812">https://doi.org/10.1007/BF00351812</a>.
</div>
<div id="ref-krifka_approximate_2007" class="csl-entry" role="listitem">
Krifka, Manfred. 2007. <span>“Approximate Interpretation of Number Words: <span>A</span> Case for Strategic Communication.”</span> In <em>Cognitive <span>Foundations</span> of <span>Interpretation</span></em>, edited by Gerlof Bouma, Irene Krämer, and Joost Zwartz, 111–26. Amsterdam: Koninklijke Nederlandse Akademie van Wetenschapen. <a href="https://doi.org/10.18452/9508">https://doi.org/10.18452/9508</a>.
</div>
<div id="ref-lakoff_hedges_1973" class="csl-entry" role="listitem">
Lakoff, George. 1973. <span>“Hedges: <span>A</span> Study in Meaning Criteria and the Logic of Fuzzy Concepts.”</span> <em>Journal of Philosophical Logic</em> 2 (4): 458–508. <a href="https://doi.org/10.1007/BF00262952">https://doi.org/10.1007/BF00262952</a>.
</div>
<div id="ref-lasersohn_pragmatic_1999" class="csl-entry" role="listitem">
Lasersohn, Peter. 1999. <span>“Pragmatic <span>Halos</span>.”</span> <em>Language</em> 75 (3): 522–51. <a href="https://doi.org/10.2307/417059">https://doi.org/10.2307/417059</a>.
</div>
<div id="ref-lassiter_context_2013" class="csl-entry" role="listitem">
Lassiter, Daniel, and Noah D. Goodman. 2013. <span>“Context, Scale Structure, and Statistics in the Interpretation of Positive-Form Adjectives.”</span> <em>Semantics and Linguistic Theory</em> 23 (0): 587–610. <a href="https://doi.org/10.3765/salt.v23i0.2658">https://doi.org/10.3765/salt.v23i0.2658</a>.
</div>
<div id="ref-lassiter_adjectival_2017" class="csl-entry" role="listitem">
———. 2017. <span>“Adjectival Vagueness in a <span>Bayesian</span> Model of Interpretation.”</span> <em>Synthese</em> 194 (10): 3801–36. <a href="https://doi.org/10.1007/s11229-015-0786-1">https://doi.org/10.1007/s11229-015-0786-1</a>.
</div>
<div id="ref-moon_source_2020" class="csl-entry" role="listitem">
Moon, Ellise, and Aaron White. 2020. <span>“The Source of Nonfinite Temporal Interpretation.”</span> In <em>Proceedings of the 50th <span>Annual</span> <span>Meeting</span> of the <span>North</span> <span>East</span> <span>Linguistic</span> <span>Society</span></em>, edited by Mariam Asatryan, Yixiao Song, and Ayana Whitmal, 3:11–24. Amherst: GLSA Publications.
</div>
<div id="ref-ozyildiz_attitude_2017" class="csl-entry" role="listitem">
Ozyildiz, Deniz. 2017. <span>“Attitude Reports with and Without True Belief.”</span> In <em>Semantics and <span>Linguistic</span> <span>Theory</span></em>, edited by Dan Burgdorf, Jacob Collard, Sireemas Maspong, and Brynhildur Stefánsdóttir, 27:397–417. Linguistic Society of America.
</div>
<div id="ref-pavlick_symbols_2023" class="csl-entry" role="listitem">
Pavlick, Ellie. 2023. <span>“Symbols and Grounding in Large Language Models.”</span> <em>Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</em> 381 (2251). <a href="https://doi.org/10.1098/rsta.2022.0041">https://doi.org/10.1098/rsta.2022.0041</a>.
</div>
<div id="ref-phillips_theories_2021" class="csl-entry" role="listitem">
Phillips, Colin, Phoebe Gaston, Nick Huang, and Hanna Muller. 2021. <span>“Theories <span>All</span> the <span>Way</span> <span>Down</span>: <span>Remarks</span> on <span>‘<span>Theoretical</span>’</span> and <span>‘<span>Experimental</span>’</span> <span>Linguistics</span>.”</span> In <em>The <span>Cambridge</span> <span>Handbook</span> of <span>Experimental</span> <span>Syntax</span></em>, edited by Grant Goodall, 587–616. Cambridge <span>Handbooks</span> in <span>Language</span> and <span>Linguistics</span>. Cambridge: Cambridge University Press. <a href="https://doi.org/10.1017/9781108569620.023">https://doi.org/10.1017/9781108569620.023</a>.
</div>
<div id="ref-qing_gradable_2014" class="csl-entry" role="listitem">
Qing, Ciyang, and Michael Franke. 2014. <span>“Gradable Adjectives, Vagueness, and Optimal Language Use: <span>A</span> Speaker-Oriented Model.”</span> <em>Semantics and Linguistic Theory</em>, August, 23–41. <a href="https://doi.org/10.3765/salt.v24i0.2412">https://doi.org/10.3765/salt.v24i0.2412</a>.
</div>
<div id="ref-qing_rational_2016" class="csl-entry" role="listitem">
Qing, Ciyang, Noah D. Goodman, and Daniel Lassiter. 2016. <span>“A Rational Speech-Act Model of Projective Content.”</span> In <em>Proceedings of the 38th <span>Annual</span> <span>Meeting</span> of the <span>Cognitive</span> <span>Science</span> <span>Society</span>: <span>Recognising</span> and Representing Events</em>, 1110–15. The Cognitive Science Society. <a href="https://www.research.ed.ac.uk/en/publications/a-rational-speech-act-model-of-projective-content">https://www.research.ed.ac.uk/en/publications/a-rational-speech-act-model-of-projective-content</a>.
</div>
<div id="ref-roberts_preconditions_2024" class="csl-entry" role="listitem">
Roberts, Craige, and Mandy Simons. 2024. <span>“Preconditions and Projection: <span>Explaining</span> Non-Anaphoric Presupposition.”</span> <em>Linguistics and Philosophy</em> 47 (4): 703–48. <a href="https://doi.org/10.1007/s10988-024-09413-9">https://doi.org/10.1007/s10988-024-09413-9</a>.
</div>
<div id="ref-van_rooij_vagueness_2011" class="csl-entry" role="listitem">
Rooij, Robert van. 2011. <span>“Vagueness and <span>Linguistics</span>.”</span> In <em>Vagueness: <span>A</span> <span>Guide</span></em>, edited by Giuseppina Ronzitti, 123–70. Dordrecht: Springer Netherlands. <a href="https://doi.org/10.1007/978-94-007-0375-9_6">https://doi.org/10.1007/978-94-007-0375-9_6</a>.
</div>
<div id="ref-ross_constraints_1967" class="csl-entry" role="listitem">
Ross, John Robert. 1967. <span>“Constraints on Variables in Syntax.”</span> PhD thesis, Massachusetts Institute of Technology.
</div>
<div id="ref-roussou_selecting_2010" class="csl-entry" role="listitem">
Roussou, Anna. 2010. <span>“Selecting Complementizers.”</span> <em>Lingua</em> 120 (3): 582–603.
</div>
<div id="ref-sadock_truth_1977" class="csl-entry" role="listitem">
Sadock, Jerrold M. 1977. <span>“Truth and <span>Approximations</span>.”</span> <em>Annual Meeting of the Berkeley Linguistics Society</em>, September, 430–39. <a href="https://doi.org/10.3765/bls.v3i0.2268">https://doi.org/10.3765/bls.v3i0.2268</a>.
</div>
<div id="ref-schütze_gramaticality_2016" class="csl-entry" role="listitem">
Schütze, Carson T. 2016. <em>The Empirical Base of Linguistics</em>. Classics in Linguistics 2. Berlin: Language Science Press. <a href="https://doi.org/10.17169/langsci.b89.100">https://doi.org/10.17169/langsci.b89.100</a>.
</div>
<div id="ref-simons_observations_2007" class="csl-entry" role="listitem">
Simons, Mandy. 2007. <span>“Observations on Embedding Verbs, Evidentiality, and Presupposition.”</span> <em>Lingua</em> 117 (6): 1034–56. <a href="https://doi.org/10.1016/j.lingua.2006.05.006">https://doi.org/10.1016/j.lingua.2006.05.006</a>.
</div>
<div id="ref-simons_best_2017" class="csl-entry" role="listitem">
Simons, Mandy, David Beaver, Craige Roberts, and Judith Tonhauser. 2017. <span>“The <span>Best</span> <span>Question</span>: <span>Explaining</span> the <span>Projection</span> <span>Behavior</span> of <span>Factives</span>.”</span> <em>Discourse Processes</em> 54 (3): 187–206.
</div>
<div id="ref-simons_what_2010" class="csl-entry" role="listitem">
Simons, Mandy, Judith Tonhauser, David Beaver, and Craige Roberts. 2010. <span>“What Projects and Why.”</span> In <em>Semantics and <span>Linguistic</span> <span>Theory</span></em>, edited by Nan Li and David Lutz, 20:309–27. University of British Columbia; Simon Fraser University: Linguistic Society of America. <a href="https://doi.org/10.3765/salt.v20i0.2584">https://doi.org/10.3765/salt.v20i0.2584</a>.
</div>
<div id="ref-smith_projection_2011" class="csl-entry" role="listitem">
Smith, E. Allyn, and Kathleen Currie Hall. 2011. <span>“Projection Diversity: <span>Experimental</span> Evidence.”</span> In <em>Proceedings of the <span>ESSLLI</span> 2011 <span>Workshop</span> on <span>Projective</span> <span>Content</span></em>.
</div>
<div id="ref-solt_vagueness_2015" class="csl-entry" role="listitem">
Solt, Stephanie. 2015. <span>“Vagueness and <span>Imprecision</span>: <span>Empirical</span> <span>Foundations</span>.”</span> <em>Annual Review of Linguistics</em> 1 (Volume 1, 2015): 107–27. <a href="https://doi.org/10.1146/annurev-linguist-030514-125150">https://doi.org/10.1146/annurev-linguist-030514-125150</a>.
</div>
<div id="ref-sorensen_vagueness_2023" class="csl-entry" role="listitem">
Sorensen, Roy. 2023. <span>“Vagueness.”</span> In <em>The <span>Stanford</span> <span>Encyclopedia</span> of <span>Philosophy</span></em>, edited by Edward N. Zalta and Uri Nodelman, Winter 2023. Metaphysics Research Lab, Stanford University. <a href="https://plato.stanford.edu/archives/win2023/entries/vagueness/">https://plato.stanford.edu/archives/win2023/entries/vagueness/</a>.
</div>
<div id="ref-sprouse_island_2021" class="csl-entry" role="listitem">
Sprouse, Jon, and Sandra Villata. 2021. <span>“Island Effects.”</span> In <em>The Cambridge Handbook of Experimental Syntax</em>, edited by Grant Goodall, 227–57. Cambridge Handbooks in Language and Linguistics. Cambridge University Press. <a href="https://doi.org/10.1017/9781108569620.010">https://doi.org/10.1017/9781108569620.010</a>.
</div>
<div id="ref-tonhauser_prosodic_2016" class="csl-entry" role="listitem">
Tonhauser, Judith. 2016. <span>“Prosodic Cues to Presupposition Projection.”</span> <em>Semantics and Linguistic Theory</em> 26 (0): 934–60. <a href="https://doi.org/10.3765/salt.v26i0.3788">https://doi.org/10.3765/salt.v26i0.3788</a>.
</div>
<div id="ref-tonhauser_how_2018" class="csl-entry" role="listitem">
Tonhauser, Judith, David I. Beaver, and Judith Degen. 2018. <span>“How <span>Projective</span> Is <span>Projective</span> <span>Content</span>? <span>Gradience</span> in <span>Projectivity</span> and <span>At</span>-Issueness.”</span> <em>Journal of Semantics</em> 35 (3): 495–542. <a href="https://doi.org/10.1093/jos/ffy007">https://doi.org/10.1093/jos/ffy007</a>.
</div>
<div id="ref-varlokosta_issues_1994" class="csl-entry" role="listitem">
Varlokosta, Spyridoula. 1994. <span>“Issues in <span>Modern</span> <span>Greek</span> <span>Sentential</span> <span>Complementation</span>.”</span> PhD thesis, University of Maryland, College Park.
</div>
<div id="ref-waldon_modeling_2020" class="csl-entry" role="listitem">
Waldon, Brandon, and Judith Degen. 2020. <span>“Modeling <span>Behavior</span> in <span>Truth</span> <span>Value</span> <span>Judgment</span> <span>Task</span> <span>Experiments</span>.”</span> In <em>Proceedings of the <span>Society</span> for <span>Computation</span> in <span>Linguistics</span> 2020</em>, edited by Allyson Ettinger, Gaja Jarosz, and Joe Pater, 238–47. New York, New York: Association for Computational Linguistics. <a href="https://aclanthology.org/2020.scil-1.29/">https://aclanthology.org/2020.scil-1.29/</a>.
</div>
<div id="ref-white_lexically_2019" class="csl-entry" role="listitem">
White, Aaron Steven. 2019. <span>“Lexically Triggered Veridicality Inferences.”</span> In <em>Handbook of <span>Pragmatics</span></em>, 22:115–48. John Benjamins Publishing Company. <a href="https://doi.org/10.1075/hop.22.lex4">https://doi.org/10.1075/hop.22.lex4</a>.
</div>
<div id="ref-white_believing_2021" class="csl-entry" role="listitem">
———. 2021. <span>“On Believing and Hoping Whether.”</span> <em>Semantics and Pragmatics</em> 14 (6): 1–18. <a href="https://doi.org/10.3765/sp.14.6">https://doi.org/10.3765/sp.14.6</a>.
</div>
<div id="ref-white_computational_2016" class="csl-entry" role="listitem">
White, Aaron Steven, and Kyle Rawlins. 2016. <span>“A Computational Model of <span>S</span>-Selection.”</span> <em>Semantics and Linguistic Theory</em> 26 (0): 641–63. <a href="https://doi.org/10.3765/salt.v26i0.3819">https://doi.org/10.3765/salt.v26i0.3819</a>.
</div>
<div id="ref-white_role_2018" class="csl-entry" role="listitem">
———. 2018. <span>“The Role of Veridicality and Factivity in Clause Selection.”</span> In <em><span>NELS</span> 48: <span>Proceedings</span> of the <span>Forty</span>-<span>Eighth</span> <span>Annual</span> <span>Meeting</span> of the <span>North</span> <span>East</span> <span>Linguistic</span> <span>Society</span></em>, edited by Sherry Hucklebridge and Max Nelson, 48:221–34. University of Iceland: GLSA (Graduate Linguistics Student Association), Department of Linguistics, University of Massachusetts.
</div>
<div id="ref-white_frequency_2020" class="csl-entry" role="listitem">
———. 2020. <span>“Frequency, Acceptability, and Selection: <span>A</span> Case Study of Clause-Embedding.”</span> <em>Glossa: A Journal of General Linguistics</em> 5 (1). <a href="https://doi.org/10.5334/gjgl.1001">https://doi.org/10.5334/gjgl.1001</a>.
</div>
<div id="ref-white_lexicosyntactic_2018" class="csl-entry" role="listitem">
White, Aaron Steven, Rachel Rudinger, Kyle Rawlins, and Benjamin Van Durme. 2018. <span>“Lexicosyntactic <span>Inference</span> in <span>Neural</span> <span>Models</span>.”</span> In <em>Proceedings of the 2018 <span>Conference</span> on <span>Empirical</span> <span>Methods</span> in <span>Natural</span> <span>Language</span> <span>Processing</span></em>, 4717–24. Brussels, Belgium: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/D18-1501">https://doi.org/10.18653/v1/D18-1501</a>.
</div>
<div id="ref-xue_correlation_2011" class="csl-entry" role="listitem">
Xue, Jingyang, and Edgar Onea. 2011. <span>“Correlation Between <span>Presupposition</span> <span>Projection</span> and <span>At</span>-Issueness: <span>An</span> <span>Empirical</span> <span>Study</span>.”</span> In <em>Proceedings of the <span>ESSLLI</span> 2011 <span>Workshop</span> on <span>Projective</span> <span>Content</span></em>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>We’ll spend a lot of time on Day 4 saying exactly what we mean by discrete here. <span class="citation" data-cites="karttunen_observations_1971">Karttunen (<a href="#ref-karttunen_observations_1971" role="doc-biblioref">1971</a>)</span>, of course, classically argues that there are predicates that sometimes trigger presuppositions and sometimes don’t. For our purposes, we’ll say that this behavior is discrete in the sense that it’s more like ambiguity than vagueness. That is, we’ll show that uncertainty around factivity displays the hallmarks of resolved uncertainty.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb2" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "The bridge from theory to data"</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> ../../pds.bib</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">    css: ../styles.css</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">    html-math-method: mathjax</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co">    mathjax-config:</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co">      loader: {load: ['[tex]/bussproofs','[tex]/bbox','[tex]/colorbox']}</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co">      tex:</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co">        packages: {'[+]': ['bussproofs','bbox','colorbox']}</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>::: {.hidden}</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>\newcommand{\expr}<span class="co">[</span><span class="ot">3</span><span class="co">]</span>{\begin{array}{c}</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>#1 <span class="sc">\\</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>\bbox<span class="co">[</span><span class="ot">lightblue,5px</span><span class="co">]</span>{#2}</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>\end{array} ⊢ #3}</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>\newcommand{\ct}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\bbox<span class="co">[</span><span class="ot">font-size: 0.8em</span><span class="co">]</span>{\mathsf{#1}}}</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>\newcommand{\updct}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\ct{upd<span class="sc">\_</span>#1}}</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>\newcommand{\abbr}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\bbox<span class="co">[</span><span class="ot">transform: scale(0.95)</span><span class="co">]</span>{\mathtt{#1}}}</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>\newcommand{\pure}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\bbox<span class="co">[</span><span class="ot">border: 1px solid orange</span><span class="co">]</span>{\bbox<span class="co">[</span><span class="ot">border: 4px solid transparent</span><span class="co">]</span>{#1}}}</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>\newcommand{\return}<span class="co">[</span><span class="ot">1</span><span class="co">]</span>{\bbox<span class="co">[</span><span class="ot">border: 1px solid black</span><span class="co">]</span>{\bbox<span class="co">[</span><span class="ot">border: 4px solid transparent</span><span class="co">]</span>{#1}}}</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>\def\P{\mathtt{P}}</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>\def\Q{\mathtt{Q}}</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>\def\True{\ct{T}}</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>\def\False{\ct{F}}</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>\def\ite{\ct{if<span class="sc">\_</span>then<span class="sc">\_</span>else}}</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>\def\Do{\abbr{do}}</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>Semantic theory has achieved remarkable success in characterizing the compositional structure of natural language meaning. Through decades of careful theoretical work, semanticists have developed elegant formal systems that capture how complex meanings arise from the systematic combination of simpler parts. These theories explain two fundamental types of judgments that speakers make: *acceptability judgments* about whether strings are well-formed, and *inference judgments* about what follows from what speakers say.</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>The field now stands at an exciting juncture. The rise of large-scale experimental methods and computational modeling opens new opportunities to test and refine these theoretical insights against rich behavioral data. The challenge—and opportunity—is to connect our elegant formal theories to the messy, gradient patterns we observe when hundreds of speakers make thousands of judgments. How can we maintain the theoretical insights that formal semantics has achieved while extending them to account for this new empirical richness?</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>Probabilistic Dynamic Semantics (PDS) aims to provide a systematic bridge between these theoretical insights and behavioral data. It takes the compositional analyses developed using traditional Montagovian methods and maps them to probabilistic models that can be quantitatively evaluated against experimental results. The goal is not to replace traditional semantics but to extend its reach, allowing us to test theoretical predictions at unprecedented scale while maintaining formal rigor.</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a><span class="fu">## Traditional Semantic Methodology: Foundations of Success</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>Semanticists study the systematic relationships between linguistic expressions and the inferences they support. The field's methodology centers on two types of judgments:</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>**Acceptability judgments** assess whether strings are well-formed relative to a language and in a particular context of use <span class="co">[</span><span class="ot">@chomsky_syntactic_1957; see @schütze_gramaticality_2016</span><span class="co">]</span>. []{#exm-comitative-good} []{#exm-coordination-bad} For example, in a context where a host asks what a guest wants with coffee, (@exm-comitative-good) is clearly acceptable, while (@exm-coordination-bad) is not <span class="co">[</span><span class="ot">@ross_constraints_1967, see @sprouse_island_2021</span><span class="co">]</span>:</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>(@exm-comitative-good) What would you like with your coffee?</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>(@exm-coordination-bad) #What would you like and your coffee?</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>**Inference judgments** assess relationships between strings <span class="co">[</span><span class="ot">see @davis_semantics_2004</span><span class="co">]</span>. []{#exm-love-antecedent} []{#exm-veridicality-inference}  When speakers hear (@exm-love-antecedent), they typically infer (@exm-veridicality-inference) <span class="co">[</span><span class="ot">@white_lexically_2019</span><span class="co">]</span>:</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>(@exm-love-antecedent) Jo loved that Mo left.</span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>(@exm-veridicality-inference) Mo left.</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a><span class="fu">### Observational Adequacy</span></span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>A core desideratum for semantic theories is *observational adequacy* [@chomsky_current_1964]: for any string $s \in \Sigma^*$, we should predict how acceptable speakers find it in context, and for acceptable strings $s, s'$, we should predict whether speakers judge $s'$ inferable from $s$.</span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>Achieving observational adequacy requires mapping vocabulary elements to abstractions that predict judgments parsimoniously. </span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>These abstractions may be discrete or continuous, simple or richly structured. Through careful analysis of consistent inference patterns, semanticists have identified powerful generalizations.</span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a>For instance, examining predicates like *love*, *hate*, *be surprised*, and *know*, theorists observed they all give rise to inferences about their complement clauses that survive under negation and questioning. This led to positing that they all share a property that predicts systematic inferential behavior across diverse predicates <span class="co">[</span><span class="ot">@kiparsky_fact_1970; cf. @karttunen_observations_1971</span><span class="co">]</span>.</span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a><span class="fu">### Descriptive Adequacy and Theoretical Depth</span></span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a>Beyond observational adequacy lies *descriptive adequacy*: capturing data "in terms of significant generalizations that express underlying regularities in the language" <span class="co">[</span><span class="ot">@chomsky_current_1964, p. 63</span><span class="co">]</span>. This drive for deeper explanation motivates the field's emphasis on parsimony and formal precision.</span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a>The history of generative syntax illustrates two approaches to achieving descriptive adequacy:</span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Analysis-driven**: Start with observationally adequate analyses in expressive formalisms, then extract generalizations as constraints</span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Hypothesis-driven**: Begin with constrained formalisms (like CCG or minimalist grammars) and test their empirical coverage</span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a>The hypothesis-driven approach, which PDS adopts for semantics, aims to delineate phenomena through representational constraints. This becomes crucial when developing models that both accord with theoretical assumptions and can be evaluated quantitatively <span class="co">[</span><span class="ot">@baroni_proper_2022; @pavlick_symbols_2023</span><span class="co">]</span>.</span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Power and Natural Boundaries of Traditional Methods</span></span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-75"><a href="#cb2-75" aria-hidden="true" tabindex="-1"></a>This methodology has yielded profound insights into semantic composition, scope phenomena, discourse dynamics, and the semantics-pragmatics interface more generally. By focusing on carefully constructed examples and native speaker intuitions, theorists have uncovered deep regularities in how meaning is constructed and interpreted.</span>
<span id="cb2-76"><a href="#cb2-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-77"><a href="#cb2-77" aria-hidden="true" tabindex="-1"></a>Yet every methodology has natural boundaries. Traditional semantic methods excel at identifying patterns and building theories but face practical constraints when we ask: </span>
<span id="cb2-78"><a href="#cb2-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-79"><a href="#cb2-79" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>How well do our generalizations, based on examining 5-10 predicates, extend to the thousands of predicates in the lexicon? </span>
<span id="cb2-80"><a href="#cb2-80" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>What factors beyond semantic knowledge influence the judgments we observe? </span>
<span id="cb2-81"><a href="#cb2-81" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>How exactly does abstract semantic knowledge produce concrete behavioral responses?</span>
<span id="cb2-82"><a href="#cb2-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-83"><a href="#cb2-83" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Experimental Turn: New Opportunities for Semantic Theory</span></span>
<span id="cb2-84"><a href="#cb2-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-85"><a href="#cb2-85" aria-hidden="true" tabindex="-1"></a>The traditional methodology's success has created a foundation solid enough to support exciting new extensions. Experimental semantics brings the tools of behavioral experimentation to bear on questions about meaning, allowing us to test and refine theoretical insights at unprecedented scale.</span>
<span id="cb2-86"><a href="#cb2-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-87"><a href="#cb2-87" aria-hidden="true" tabindex="-1"></a><span class="fu">### Scaling Semantic Investigation</span></span>
<span id="cb2-88"><a href="#cb2-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-89"><a href="#cb2-89" aria-hidden="true" tabindex="-1"></a>Where traditional methods might examine a handful of predicates, experimental approaches can investigate entire lexical domains. Extending our example involving the verb *love*: English has thousands of similar clause-embedding predicates, each potentially varying in its inferential properties. We can now test whether generalizations based on canonical examples extend across these vast lexicons.</span>
<span id="cb2-90"><a href="#cb2-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-91"><a href="#cb2-91" aria-hidden="true" tabindex="-1"></a>The MegaAttitude project <span class="co">[</span><span class="ot">@white_computational_2016; @white_role_2018; @white_lexicosyntactic_2018; @white_frequency_2020; @an_lexical_2020; @moon_source_2020; @kane_intensional_2022</span><span class="co">]</span> is one example of this approach. This project aims to collect inference judgments for hundreds of predicates across multiple contexts and inference types. This scale reveals patterns that are very difficult to see and evaluate the quality of using traditional methods—subtle distinctions between near-synonyms, unexpected predicate clusters, and systematic variation across semantic domains.</span>
<span id="cb2-92"><a href="#cb2-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-93"><a href="#cb2-93" aria-hidden="true" tabindex="-1"></a><span class="fu">### Teasing Apart Contributing Factors</span></span>
<span id="cb2-94"><a href="#cb2-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-95"><a href="#cb2-95" aria-hidden="true" tabindex="-1"></a>Experimental methods also allow us to investigate the rich array of factors that influence inference judgments:</span>
<span id="cb2-96"><a href="#cb2-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-97"><a href="#cb2-97" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Semantic knowledge**: The core meanings of expressions</span>
<span id="cb2-98"><a href="#cb2-98" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**World knowledge**: Prior beliefs about plausibility  </span>
<span id="cb2-99"><a href="#cb2-99" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Contextual factors**: The discourse context and QUD</span>
<span id="cb2-100"><a href="#cb2-100" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Individual differences**: Variation in how speakers interpret expressions</span>
<span id="cb2-101"><a href="#cb2-101" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Response strategies**: How participants use rating scales</span>
<span id="cb2-102"><a href="#cb2-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-103"><a href="#cb2-103" aria-hidden="true" tabindex="-1"></a>Rather than viewing these as confounds, we can see them as windows into the cognitive processes underlying semantic interpretation. For instance, @degen_prior_2021 systematically manipulated world knowledge to show how prior beliefs modulate the strength of factive inferences, revealing the interplay between semantic and pragmatic factors.</span>
<span id="cb2-104"><a href="#cb2-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-105"><a href="#cb2-105" aria-hidden="true" tabindex="-1"></a><span class="fu">### Making Linking Hypotheses Explicit</span></span>
<span id="cb2-106"><a href="#cb2-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-107"><a href="#cb2-107" aria-hidden="true" tabindex="-1"></a>Perhaps most importantly, experimental approaches force us to make explicit what traditional methods leave implicit: the link between semantic representations and behavioral responses <span class="co">[</span><span class="ot">@jasbi_linking_2019; @waldon_modeling_2020; @phillips_theories_2021</span><span class="co">]</span>. When we say speakers judge that an inference follows, what cognitive processes produce that judgment? How do abstract semantic representations map onto the responses on some scale?</span>
<span id="cb2-108"><a href="#cb2-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-109"><a href="#cb2-109" aria-hidden="true" tabindex="-1"></a>This is not merely a methodological detail—it's a substantive theoretical question. Different linking hypotheses make different predictions about response patterns, allowing us to test not just our semantic theories but our assumptions about how those theories connect to behavior. Even if our real interest is in characterizing the semantic representations of speakers, we can't ignore the way those representations map onto their responses in some task.</span>
<span id="cb2-110"><a href="#cb2-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-111"><a href="#cb2-111" aria-hidden="true" tabindex="-1"></a><span class="fu">## Understanding Gradience: A Taxonomy of Uncertainty</span></span>
<span id="cb2-112"><a href="#cb2-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-113"><a href="#cb2-113" aria-hidden="true" tabindex="-1"></a>One of the most striking findings from experimental semantics is the pervasiveness of gradience in aggregated measures. While semanticists have long recognized the existence of gradience in some domains–e.g. gradable adjectives–we often assume categorical distinctions in other domains–e.g. factivity. And even where traditional approaches assume categorical distinctions, experimental methods often reveal continuous variation. For the reasons laid out above,understanding this gradience is crucial for developing theories that connect formal semantics to behavioral data.</span>
<span id="cb2-114"><a href="#cb2-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-115"><a href="#cb2-115" aria-hidden="true" tabindex="-1"></a><span class="fu">### Examples of Potentially Unexpected Gradience</span></span>
<span id="cb2-116"><a href="#cb2-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-117"><a href="#cb2-117" aria-hidden="true" tabindex="-1"></a>The kinds of distributionally and inferentially defined properties we develop generalizations around are not always readily apparent in large-scale datasets.</span>
<span id="cb2-118"><a href="#cb2-118" aria-hidden="true" tabindex="-1"></a>An example we will look at in-depth in our second case study of the course is that, when attempting to measure veridicality/factivity, we end up with more gradience than we might have expected.</span>
<span id="cb2-119"><a href="#cb2-119" aria-hidden="true" tabindex="-1"></a>We can illustrate this using the MegaAttitude datasets.</span>
<span id="cb2-120"><a href="#cb2-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-121"><a href="#cb2-121" aria-hidden="true" tabindex="-1"></a>@fig-veridicality shows veridicality judgments collected by @white_role_2018 as part of their MegaVeridicality dataset.</span>
<span id="cb2-122"><a href="#cb2-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-123"><a href="#cb2-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-124"><a href="#cb2-124" aria-hidden="true" tabindex="-1"></a><span class="al">![Veridicality judgments collected by @white_role_2018 as part of their MegaVeridicality dataset.](plots/veridicality_factivity.png)</span>{#fig-veridicality width=750}</span>
<span id="cb2-125"><a href="#cb2-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-126"><a href="#cb2-126" aria-hidden="true" tabindex="-1"></a>One thing @white_role_2018 note is the apparent gradience in these measures.</span>
<span id="cb2-127"><a href="#cb2-127" aria-hidden="true" tabindex="-1"></a>This gradience presents a challenge if we want to use these measures to evaluate generalizations about the relationship between two properties.</span>
<span id="cb2-128"><a href="#cb2-128" aria-hidden="true" tabindex="-1"></a>For instance, say we are interested in understanding the relationship betwen factivity and neg(ation)-raising.</span>
<span id="cb2-129"><a href="#cb2-129" aria-hidden="true" tabindex="-1"></a>[]{#exm-negraising} []{#exm-negraising-inference} A predicate is neg-raising if it gives rise to inferences of the form from (@exm-negraising) to (@exm-negraising-inference):</span>
<span id="cb2-130"><a href="#cb2-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-131"><a href="#cb2-131" aria-hidden="true" tabindex="-1"></a>(@exm-negraising) Jo doesn't think that Mo left.</span>
<span id="cb2-132"><a href="#cb2-132" aria-hidden="true" tabindex="-1"></a>(@exm-negraising-inference) Jo thinks that Mo didn't leave.</span>
<span id="cb2-133"><a href="#cb2-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-134"><a href="#cb2-134" aria-hidden="true" tabindex="-1"></a>One way of deriving a factivity measure from the MegaVeridicality dataset is to take the max along both dimensions, as shown in @fig-derived-factivity.</span>
<span id="cb2-135"><a href="#cb2-135" aria-hidden="true" tabindex="-1"></a>The idea here is that, it will give rise to veridicality inferences with both positive and negative matrix polarity.</span>
<span id="cb2-136"><a href="#cb2-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-137"><a href="#cb2-137" aria-hidden="true" tabindex="-1"></a><span class="al">![One way of deriving a factivity measure from the MegaVeridicality dataset.](plots/derived_factivity_measure.png)</span>{#fig-derived-factivity width=750}</span>
<span id="cb2-138"><a href="#cb2-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-139"><a href="#cb2-139" aria-hidden="true" tabindex="-1"></a>Now let's suppose we're interested in generalizations about the relationship between two measures.</span>
<span id="cb2-140"><a href="#cb2-140" aria-hidden="true" tabindex="-1"></a>For instance, maybe want to evaluate the relationship between factivity and neg-raising, where we might tend to suspect that factives are not neg-raisers.</span>
<span id="cb2-141"><a href="#cb2-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-142"><a href="#cb2-142" aria-hidden="true" tabindex="-1"></a>@fig-negraising-factivity shows a comparison of the measure of neg(ation)-raising from the MegaNegRaising dataset collected by @an_lexical_2020 and the derived factivity measure from the MegaVeridicality dataset collected by @white_role_2018.</span>
<span id="cb2-143"><a href="#cb2-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-144"><a href="#cb2-144" aria-hidden="true" tabindex="-1"></a><span class="al">![A comparison of the measure of neg(ation)-raising from the MegaNegRaising dataset collected by @an_lexical_2020 and the derived factivity measure from the MegaVeridicality dataset collected by @white_role_2018.](plots/negraising_factivity.png)</span>{#fig-negraising-factivity width=750}</span>
<span id="cb2-145"><a href="#cb2-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-146"><a href="#cb2-146" aria-hidden="true" tabindex="-1"></a>The challenge is that, once we move to relating continuous measures, rather than categorical distinctions, we don't know what the relationship between measures should look like in any particular case.</span>
<span id="cb2-147"><a href="#cb2-147" aria-hidden="true" tabindex="-1"></a>To illustrate, let's consider another example.</span>
<span id="cb2-148"><a href="#cb2-148" aria-hidden="true" tabindex="-1"></a>@anand_factivity_2014 propose that, if a predicate gives rise to inferences about both beliefs and preferences, it backgrounds the belief inferences.</span>
<span id="cb2-149"><a href="#cb2-149" aria-hidden="true" tabindex="-1"></a>To evaluate this hypothesis, we might try to derive a measure of belief inferences and preference inferences and then relate them.</span>
<span id="cb2-150"><a href="#cb2-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-151"><a href="#cb2-151" aria-hidden="true" tabindex="-1"></a>To this end, we can use the MegaIntensionality dataset collected by @kane_intensional_2022.</span>
<span id="cb2-152"><a href="#cb2-152" aria-hidden="true" tabindex="-1"></a>@fig-belief shows a measure of belief inferences and @fig-desire shows a measure of desire inferences.</span>
<span id="cb2-153"><a href="#cb2-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-154"><a href="#cb2-154" aria-hidden="true" tabindex="-1"></a><span class="al">![A measure of belief inferences from the MegaIntensionality dataset collected by @kane_intensional_2022.](plots/belief.png)</span>{#fig-belief width=750}</span>
<span id="cb2-155"><a href="#cb2-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-156"><a href="#cb2-156" aria-hidden="true" tabindex="-1"></a>And @fig-desire-belief shows a comparison of the desire and belief measures.</span>
<span id="cb2-157"><a href="#cb2-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-158"><a href="#cb2-158" aria-hidden="true" tabindex="-1"></a><span class="al">![A measure of desire inferences from the MegaIntensionality dataset collected by @kane_intensional_2022.](plots/desire.png)</span>{#fig-desire width=750}</span>
<span id="cb2-159"><a href="#cb2-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-160"><a href="#cb2-160" aria-hidden="true" tabindex="-1"></a>@fig-desire-belief show the relationship between these two measures.</span>
<span id="cb2-161"><a href="#cb2-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-162"><a href="#cb2-162" aria-hidden="true" tabindex="-1"></a><span class="al">![A comparison of the desire and belief measures from the MegaIntensionality dataset collected by @kane_intensional_2022.](plots/desire_belief.png)</span>{#fig-desire-belief width=750}</span>
<span id="cb2-163"><a href="#cb2-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-164"><a href="#cb2-164" aria-hidden="true" tabindex="-1"></a>There are two main takeaways from this example.</span>
<span id="cb2-165"><a href="#cb2-165" aria-hidden="true" tabindex="-1"></a>First, the generalization proposed by@anand_factivity_2014 is indeed supported by the data.</span>
<span id="cb2-166"><a href="#cb2-166" aria-hidden="true" tabindex="-1"></a>Second, the relationship between these two measures is strikingly different from the relationship we observe between the continuous measures of factivity and neg-raising.</span>
<span id="cb2-167"><a href="#cb2-167" aria-hidden="true" tabindex="-1"></a>We need some way of theorizing about these continuous relationships.</span>
<span id="cb2-168"><a href="#cb2-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-169"><a href="#cb2-169" aria-hidden="true" tabindex="-1"></a><span class="fu">### Two Fundamental Types of Uncertainty</span></span>
<span id="cb2-170"><a href="#cb2-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-171"><a href="#cb2-171" aria-hidden="true" tabindex="-1"></a>The framework we'll explore distinguishes two general types of uncertainty that can produce gradience: *resolved* (or *type-level*) *uncertainty* and *unresolved* (or *token-level*) *uncertainty*, both of which can arise from multiple sources.</span>
<span id="cb2-172"><a href="#cb2-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-173"><a href="#cb2-173" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb2-174"><a href="#cb2-174" aria-hidden="true" tabindex="-1"></a><span class="in">Sources of Gradience in Inference Judgments</span></span>
<span id="cb2-175"><a href="#cb2-175" aria-hidden="true" tabindex="-1"></a><span class="in">├── Resolved (Type-Level) Uncertainty</span></span>
<span id="cb2-176"><a href="#cb2-176" aria-hidden="true" tabindex="-1"></a><span class="in">│   ├── Ambiguity</span></span>
<span id="cb2-177"><a href="#cb2-177" aria-hidden="true" tabindex="-1"></a><span class="in">│   │   ├── Lexical (e.g., "run" = locomote vs. manage)</span></span>
<span id="cb2-178"><a href="#cb2-178" aria-hidden="true" tabindex="-1"></a><span class="in">│   │   ├── Syntactic (e.g., attachment ambiguities)</span></span>
<span id="cb2-179"><a href="#cb2-179" aria-hidden="true" tabindex="-1"></a><span class="in">│   │   └── Semantic (e.g., scope ambiguities)</span></span>
<span id="cb2-180"><a href="#cb2-180" aria-hidden="true" tabindex="-1"></a><span class="in">│   └── Discourse Status</span></span>
<span id="cb2-181"><a href="#cb2-181" aria-hidden="true" tabindex="-1"></a><span class="in">│       └── QUD (Question Under Discussion)</span></span>
<span id="cb2-182"><a href="#cb2-182" aria-hidden="true" tabindex="-1"></a><span class="in">└── Unresolved (Token-Level) Uncertainty</span></span>
<span id="cb2-183"><a href="#cb2-183" aria-hidden="true" tabindex="-1"></a><span class="in">    ├── Vagueness (e.g., height of a "tall" person)</span></span>
<span id="cb2-184"><a href="#cb2-184" aria-hidden="true" tabindex="-1"></a><span class="in">    ├── World knowledge (e.g., likelihood that facts are true)</span></span>
<span id="cb2-185"><a href="#cb2-185" aria-hidden="true" tabindex="-1"></a><span class="in">    └── Task effects</span></span>
<span id="cb2-186"><a href="#cb2-186" aria-hidden="true" tabindex="-1"></a><span class="in">        ├── Response strategies</span></span>
<span id="cb2-187"><a href="#cb2-187" aria-hidden="true" tabindex="-1"></a><span class="in">        └── Response error</span></span>
<span id="cb2-188"><a href="#cb2-188" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb2-189"><a href="#cb2-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-190"><a href="#cb2-190" aria-hidden="true" tabindex="-1"></a><span class="fu">### Resolved Uncertainty: Multiple Discrete Possibilities</span></span>
<span id="cb2-191"><a href="#cb2-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-192"><a href="#cb2-192" aria-hidden="true" tabindex="-1"></a>Resolved uncertainty arises when speakers must choose among discrete interpretations. []{#exm-uncle-running} Consider (@exm-uncle-running):</span>
<span id="cb2-193"><a href="#cb2-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-194"><a href="#cb2-194" aria-hidden="true" tabindex="-1"></a>(@exm-uncle-running) My uncle is running the race.</span>
<span id="cb2-195"><a href="#cb2-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-196"><a href="#cb2-196" aria-hidden="true" tabindex="-1"></a>The verb *run* is ambiguous—the uncle might be a participant (locomotion) or the organizer (management). Asked "How likely is it that my uncle has good managerial skills?", participants who interpret *run* as locomotion might respond near 0.2, while those interpreting it as management might respond near 0.8. The population average might be 0.5, but this reflects a *mixture* of discrete interpretations, not genuine gradience.</span>
<span id="cb2-197"><a href="#cb2-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-198"><a href="#cb2-198" aria-hidden="true" tabindex="-1"></a>This uncertainty is "resolved" because once speakers fix an interpretation, the inference follows determinately. The gradience emerges from averaging across different resolutions, not from uncertainty within any single interpretation.</span>
<span id="cb2-199"><a href="#cb2-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-200"><a href="#cb2-200" aria-hidden="true" tabindex="-1"></a>A similar phenomenon is observable with anaphora. []{#exm-anaphora} Consider (@exm-anaphora):</span>
<span id="cb2-201"><a href="#cb2-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-202"><a href="#cb2-202" aria-hidden="true" tabindex="-1"></a>(@exm-anaphora) Whenever anyone laughed, the magician scowled and their assistant smirked. They were secretly pleased.</span>
<span id="cb2-203"><a href="#cb2-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-204"><a href="#cb2-204" aria-hidden="true" tabindex="-1"></a>One is quite likely to infer from (@exm-anaphora) that the magician’s assistant is secretly pleased, but not necessarily that the magician is pleased, even though, in principle, it may be that both are, or even that only the magician is. </span>
<span id="cb2-205"><a href="#cb2-205" aria-hidden="true" tabindex="-1"></a>Ultimately, the ambiguity is resolved when we fix the referent.</span>
<span id="cb2-206"><a href="#cb2-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-207"><a href="#cb2-207" aria-hidden="true" tabindex="-1"></a><span class="fu">### Unresolved Uncertainty: Gradient Within Interpretations</span></span>
<span id="cb2-208"><a href="#cb2-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-209"><a href="#cb2-209" aria-hidden="true" tabindex="-1"></a>Unresolved uncertainty contrasts with resolved uncertainty in that it persists even after fixing all ambiguities. []{#exm-uncle-tall} Consider (@exm-uncle-tall):</span>
<span id="cb2-210"><a href="#cb2-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-211"><a href="#cb2-211" aria-hidden="true" tabindex="-1"></a>(@exm-uncle-tall) My uncle is tall.</span>
<span id="cb2-212"><a href="#cb2-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-213"><a href="#cb2-213" aria-hidden="true" tabindex="-1"></a>Even with no ambiguity about *tall*'s meaning, speakers remain uncertain whether the uncle exceeds any particular height threshold. This is classic vagueness—the predicate's application conditions are inherently gradient <span class="co">[</span><span class="ot">@fine_vagueness_1975; @graff_shifting_2000; @kennedy_vagueness_2007; @van_rooij_vagueness_2011; @sorensen_vagueness_2023</span><span class="co">]</span>.</span>
<span id="cb2-214"><a href="#cb2-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-215"><a href="#cb2-215" aria-hidden="true" tabindex="-1"></a>World knowledge creates another layer: even knowing someone runs races (locomotion sense), we remain uncertain about their speed, endurance, or likelihood of finishing. These uncertainties appear within individual trials, not just across participants.</span>
<span id="cb2-216"><a href="#cb2-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-217"><a href="#cb2-217" aria-hidden="true" tabindex="-1"></a><span class="fu">### Why This Distinction Matters</span></span>
<span id="cb2-218"><a href="#cb2-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-219"><a href="#cb2-219" aria-hidden="true" tabindex="-1"></a>The type of uncertainty has profound implications for semantic theory:</span>
<span id="cb2-220"><a href="#cb2-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-221"><a href="#cb2-221" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Resolved uncertainty** suggests discrete semantic representations with probabilistic selection</span>
<span id="cb2-222"><a href="#cb2-222" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Unresolved uncertainty** suggests gradient representations or probabilistic reasoning within fixed meanings</span>
<span id="cb2-223"><a href="#cb2-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-224"><a href="#cb2-224" aria-hidden="true" tabindex="-1"></a>Different phenomena may involve different uncertainty types. As we'll see, vagueness seems to give rise to unresolved uncertainty (the conditions of application of *tall* seem inherently uncertain), while factivity's gradience is perhaps more puzzling: is it resolved uncertainty from ambiguous predicates, or unresolved uncertainty in projection itself?</span>
<span id="cb2-225"><a href="#cb2-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-226"><a href="#cb2-226" aria-hidden="true" tabindex="-1"></a><span class="fu">## Case Studies: Testing Semantic Theory at Scale</span></span>
<span id="cb2-227"><a href="#cb2-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-228"><a href="#cb2-228" aria-hidden="true" tabindex="-1"></a>To illustrate how PDS bridges formal semantics and experimental data, we'll examine two case studies that exemplify different aspects of the framework.</span>
<span id="cb2-229"><a href="#cb2-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-230"><a href="#cb2-230" aria-hidden="true" tabindex="-1"></a><span class="fu">### Case Study 1: Vagueness and Gradable Adjectives</span></span>
<span id="cb2-231"><a href="#cb2-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-232"><a href="#cb2-232" aria-hidden="true" tabindex="-1"></a>Vague predicates provide an ideal starting point because everyone agrees they involve gradient uncertainty. Expressions like *tall*, *expensive*, and *old* lack sharp boundaries—there's no precise height at which someone becomes tall <span class="co">[</span><span class="ot">@lakoff_hedges_1973; @sadock_truth_1977; @lasersohn_pragmatic_1999; @krifka_approximate_2007; @solt_vagueness_2015</span><span class="co">]</span>.</span>
<span id="cb2-233"><a href="#cb2-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-234"><a href="#cb2-234" aria-hidden="true" tabindex="-1"></a>Formal semantic theories have long recognized this gradience. Degree-based approaches <span class="co">[</span><span class="ot">@klein_semantics_1980; @bierwisch_semantics_1989; @kamp_two_1975; @kennedy_projecting_1999; @kennedy_scale_2005; @kennedy_vagueness_2007; @barker_dynamics_2002</span><span class="co">]</span> analyze gradable adjectives as expressing relations to contextual thresholds:</span>
<span id="cb2-235"><a href="#cb2-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-236"><a href="#cb2-236" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>*tall* is true of $x$ if $\ct{height}(x) \geq d_\text{tall}$ (context)</span>
<span id="cb2-237"><a href="#cb2-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-238"><a href="#cb2-238" aria-hidden="true" tabindex="-1"></a>The threshold $d_\text{tall}$ varies with context—what counts as tall for a basketball player differs from tall for a child. But even within a fixed context, speakers show gradient judgments about borderline cases.</span>
<span id="cb2-239"><a href="#cb2-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-240"><a href="#cb2-240" aria-hidden="true" tabindex="-1"></a>This makes vagueness ideal for demonstrating how PDS works. The framework can:</span>
<span id="cb2-241"><a href="#cb2-241" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Maintain the compositional degree-based analysis from formal semantics</span>
<span id="cb2-242"><a href="#cb2-242" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Add probability distributions over thresholds to capture gradient judgments</span>
<span id="cb2-243"><a href="#cb2-243" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Model how context shifts these distributions</span>
<span id="cb2-244"><a href="#cb2-244" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Link threshold distributions to slider scale responses</span>
<span id="cb2-245"><a href="#cb2-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-246"><a href="#cb2-246" aria-hidden="true" tabindex="-1"></a>Recent experimental work reveals additional complexity. Different adjective types show distinct patterns:</span>
<span id="cb2-247"><a href="#cb2-247" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Relative adjectives** (*tall*, *wide*): Maximum gradience in positive form</span>
<span id="cb2-248"><a href="#cb2-248" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Absolute adjectives** (*clean*, *dry*): Different threshold distributions</span>
<span id="cb2-249"><a href="#cb2-249" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Minimum vs. maximum standard**: Asymmetric patterns of imprecision</span>
<span id="cb2-250"><a href="#cb2-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-251"><a href="#cb2-251" aria-hidden="true" tabindex="-1"></a>These patterns both support and refine formal theories, showing how experimental data can advance theoretical understanding. Recent years have seen partial integration into computational models <span class="co">[</span><span class="ot">@lassiter_context_2013; @qing_gradable_2014; @kao_nonliteral_2014; @lassiter_adjectival_2017; @bumford_rationalizing_2021</span><span class="co">]</span>. We'll show that PDS allows us to synthesize and compare these different partial approaches.</span>
<span id="cb2-252"><a href="#cb2-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-253"><a href="#cb2-253" aria-hidden="true" tabindex="-1"></a><span class="fu">### Case Study 2: Factivity and Projection</span></span>
<span id="cb2-254"><a href="#cb2-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-255"><a href="#cb2-255" aria-hidden="true" tabindex="-1"></a>While vagueness involves expected gradience, factivity presents a puzzle. Traditional theory treats factivity as discrete—predicates either trigger presuppositions or they don't <span class="co">[</span><span class="ot">@kiparsky_fact_1970; @karttunen_observations_1971</span><span class="co">]</span>.^<span class="co">[</span><span class="ot">We'll spend a lot of time on Day 4 saying exactly what we mean by discrete here. @karttunen_observations_1971, of course, classically argues that there are predicates that sometimes trigger presuppositions and sometimes don't. For our purposes, we'll say that this behavior is discrete in the sense that it's more like ambiguity than vagueness. That is, we'll show that uncertainty around factivity displays the hallmarks of resolved uncertainty.</span><span class="co">]</span> Yet experimental data reveals pervasive gradience.</span>
<span id="cb2-256"><a href="#cb2-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-257"><a href="#cb2-257" aria-hidden="true" tabindex="-1"></a>A predicate is *factive* if it triggers inferences about its complement that project through entailment-canceling operators. []{#exm-love-positive} []{#exm-love-negative} []{#exm-love-question} *Love* appears factive because *Mo left* is inferrable from the standard family of sentences in (@exm-love-positive)–(@exm-love-question):</span>
<span id="cb2-258"><a href="#cb2-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-259"><a href="#cb2-259" aria-hidden="true" tabindex="-1"></a>(@exm-love-positive) Jo loves that Mo left.</span>
<span id="cb2-260"><a href="#cb2-260" aria-hidden="true" tabindex="-1"></a>(@exm-love-negative) Jo doesn't love that Mo left.  </span>
<span id="cb2-261"><a href="#cb2-261" aria-hidden="true" tabindex="-1"></a>(@exm-love-question) Does Jo love that Mo left?</span>
<span id="cb2-262"><a href="#cb2-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-263"><a href="#cb2-263" aria-hidden="true" tabindex="-1"></a>But when @white_role_2018 (discussed above) and @degen_are_2022 collected projection judgments at scale, they found continuous variation <span class="co">[</span><span class="ot">@xue_correlation_2011; @smith_projection_2011; @djarv_prosodic_2017 also observe similar patterns</span><span class="co">]</span>. Qualitatively, @degen_are_2022 argue that there is no clear line separates factive from non-factive predicates. Mean projection ratings vary continuously from *pretend* (lowest) to *be annoyed* (highest).</span>
<span id="cb2-264"><a href="#cb2-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-265"><a href="#cb2-265" aria-hidden="true" tabindex="-1"></a><span class="al">![Aggregate factivity measures from @degen_are_2022, showing continuous variation in projection ratings across predicates under questioning.](plots/projection_no_fact_means.pdf)</span>{width=750}</span>
<span id="cb2-266"><a href="#cb2-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-267"><a href="#cb2-267" aria-hidden="true" tabindex="-1"></a>This gradience poses a theoretical challenge <span class="co">[</span><span class="ot">@simons_observations_2007; @simons_what_2010; @simons_best_2017; @tonhauser_how_2018</span><span class="co">]</span>. </span>
<span id="cb2-268"><a href="#cb2-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-269"><a href="#cb2-269" aria-hidden="true" tabindex="-1"></a>@kane_intensional_2022 later showed that this gradience is likely due to task effects. They demonstrate that when one applies a clustering model to these data that accounts for noise due to various factors, many of the standard subclasses of factives pop out. Some of these subclasses–e.g. the cognitive factives, which @karttunen_observations_1971 observes to not always give rise factivity–appear to themselves be associated with non-necessary factive inferences. </span>
<span id="cb2-270"><a href="#cb2-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-271"><a href="#cb2-271" aria-hidden="true" tabindex="-1"></a>In this case study, we'll focus on understanding what gives rise to this gradience. We'll consider two hypotheses that PDS allows us to state precisely and test against the data collected by @degen_prior_2021, which uses the same experimental paradigm as @degen_are_2022:</span>
<span id="cb2-272"><a href="#cb2-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-273"><a href="#cb2-273" aria-hidden="true" tabindex="-1"></a>**The Fundamental Discreteness Hypothesis**: Factivity remains discrete; gradience reflects:</span>
<span id="cb2-274"><a href="#cb2-274" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Multiple predicate senses (factive and non-factive variants)</span>
<span id="cb2-275"><a href="#cb2-275" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Structural ambiguity affecting projection <span class="co">[</span><span class="ot">@varlokosta_issues_1994; @giannakidou_polarity_1998; @giannakidou_affective_1999; @giannakidou_dependency_2009; @roussou_selecting_2010; @farudi_antisymmetric_2007; @abrusan_predicting_2011; @kastner_factivity_2015; @ozyildiz_attitude_2017</span><span class="co">]</span></span>
<span id="cb2-276"><a href="#cb2-276" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Contextual variation in whether complements are at-issue <span class="co">[</span><span class="ot">@simons_best_2017; @roberts_preconditions_2024; @qing_rational_2016</span><span class="co">]</span></span>
<span id="cb2-277"><a href="#cb2-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-278"><a href="#cb2-278" aria-hidden="true" tabindex="-1"></a>**The Fundamental Gradience Hypothesis**: No discrete factivity property exists. Gradient patterns reflect different degrees to which predicates support complement truth inferences <span class="co">[</span><span class="ot">@tonhauser_how_2018</span><span class="co">]</span>.</span>
<span id="cb2-279"><a href="#cb2-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-280"><a href="#cb2-280" aria-hidden="true" tabindex="-1"></a>PDS allows us to implement both hypotheses formally and test their predictions against fine-grained response distributions—not just means, but entire judgment patterns including multimodality that might indicate mixture distributions. We'll show how this approach can be applied to judgment data aimed at capturing factivity using various experimental paradigms <span class="co">[</span><span class="ot">@tonhauser_prosodic_2016; @djarv_prosodic_2017; @djarv_cognitive_2018; @white_role_2018; @white_lexicosyntactic_2018; @white_believing_2021; @degen_prior_2021; @degen_are_2022; @jeong_prosodically-conditioned_2021; @kane_intensional_2022</span><span class="co">]</span>.</span>
<span id="cb2-281"><a href="#cb2-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-282"><a href="#cb2-282" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Need for New Frameworks</span></span>
<span id="cb2-283"><a href="#cb2-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-284"><a href="#cb2-284" aria-hidden="true" tabindex="-1"></a>These case studies illustrate what we need from a framework connecting formal semantics to experimental data:</span>
<span id="cb2-285"><a href="#cb2-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-286"><a href="#cb2-286" aria-hidden="true" tabindex="-1"></a>**Maintain Compositionality**: Theories must derive complex meanings compositionally, preserving insights from decades of formal semantic research. We cannot abandon compositionality just because judgments are gradient.</span>
<span id="cb2-287"><a href="#cb2-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-288"><a href="#cb2-288" aria-hidden="true" tabindex="-1"></a>**Model Uncertainty Explicitly**: The framework must represent both types of uncertainty—resolved ambiguities and unresolved gradience—and show how they interact during interpretation.</span>
<span id="cb2-289"><a href="#cb2-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-290"><a href="#cb2-290" aria-hidden="true" tabindex="-1"></a>**Make Linking Hypotheses Precise**: We need explicit theories of how semantic representations produce behavioral responses. What cognitive processes intervene between computing a meaning and moving a slider?</span>
<span id="cb2-291"><a href="#cb2-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-292"><a href="#cb2-292" aria-hidden="true" tabindex="-1"></a>**Enable Quantitative Evaluation**: Theories must make testable predictions about response distributions, not just average ratings. Different theories should be comparable using standard statistical metrics.</span>
<span id="cb2-293"><a href="#cb2-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-294"><a href="#cb2-294" aria-hidden="true" tabindex="-1"></a>As we'll see in the next section, existing computational approaches like Rational Speech Act (RSA) models attempt to bridge formal semantics with probabilistic reasoning <span class="co">[</span><span class="ot">@frank_predicting_2012; @goodman_knowledge_2013</span><span class="co">]</span>. While valuable, these approaches face challenges in maintaining the modularity that makes formal semantic theories powerful. This motivates the development of Probabilistic Dynamic Semantics—a framework that preserves semantic insights while adding the probabilistic tools needed to model gradient behavioral data.</span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>