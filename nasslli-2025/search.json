[
  {
    "objectID": "qud/index.html",
    "href": "qud/index.html",
    "title": "Notes",
    "section": "",
    "text": "Note\n\n\n\nThese notes will become available on June 27."
  },
  {
    "objectID": "pds-intro/constants.html",
    "href": "pds-intro/constants.html",
    "title": "Constants",
    "section": "",
    "text": "\\[\n\\newcommand{\\expr}[3]{\\begin{array}{c}\n#1 \\\\\n\\bbox[lightblue,5px]{#2}\n\\end{array} ⊢ #3}\n\\newcommand{\\ct}[1]{\\bbox[font-size: 0.8em]{\\mathsf{#1}}}\n\\newcommand{\\updct}[1]{\\ct{upd\\_#1}}\n\\newcommand{\\abbr}[1]{\\bbox[transform: scale(0.95)]{\\mathtt{#1}}}\n\\newcommand{\\pure}[1]{\\bbox[border: 1px solid orange]{\\bbox[border: 4px solid transparent]{#1}}}\n\\newcommand{\\return}[1]{\\bbox[border: 1px solid black]{\\bbox[border: 4px solid transparent]{#1}}}\n\\def\\P{\\mathtt{P}}\n\\def\\Q{\\mathtt{Q}}\n\\def\\True{\\ct{T}}\n\\def\\False{\\ct{F}}\n\\def\\ite{\\ct{if\\_then\\_else}}\n\\def\\Do{\\abbr{do}}\n\\]\n\nHere we provide a bit more information about the types of constants, as they are encoded in Haskell. The constants provided here are not exhaustive, but it should be more or less clear from these examples how to generalize the typing scheme to others.\n\nLogical constants\nFirst, it is useful to have logical constants (e.g., to encode basic meanings for things):\n-- | Logical constants.\ntauLogical :: Sig\ntauLogical = \\case\n  Left \"∀\"   -&gt; Just ((α :→ t) :→ t)\n  Left \"∃\"   -&gt; Just ((α :→ t) :→ t)\n  Left \"(∧)\" -&gt; Just (t :→ t :→ t)\n  Left \"(∨)\" -&gt; Just (t :→ t :→ t)\n  Left \"(⇒)\" -&gt; Just (t :→ t :→ t)\n  Left \"¬\"   -&gt; Just (t :→ t)\n  Left \"T\"   -&gt; Just t\n  Left \"F\"   -&gt; Just t\n  _          -&gt; Nothing\nNote that the universal and existential quantifiers are typed to be polymorphic in the variable they quantify over.\n\n\nNon-logical constants\nSecond, non-logical constants, e.g., \\(\\ct{ling}\\), \\(\\ct{j}\\), etc.:\n-- | Some non-logical constants.\ntauNonLogical :: Sig\ntauNonLogical = \\case\n  Left \"upd_ling\" -&gt; Just ((e :→ t) :→ ι :→ ι)\n  Left \"ling\"     -&gt; Just (ι :→ e :→ t)\n  Left \"j\"        -&gt; Just e\n  Left \"b\"        -&gt; Just e\n  Left \"@\"        -&gt; Just ι -- the starting index\n  _               -&gt; Nothing\nFollowing the discussion here, constants which are intensional have corresponding constants for updating their values.\n\n\nMetalinguistc parameters\nFollowing the disccusion here, we should encode constants that access metalinguistic parameters, i.e., components of the state:\n-- | Some metalinguistic parameters.\ntauMetalinguistic :: Sig\ntauMetalinguistic = \\case\n  Left \"upd_CG\"  -&gt; Just (P ι :→ σ :→ σ)\n  Left \"CG\"      -&gt; Just (σ :→ P ι)\n  Left \"upd_QUD\" -&gt; Just ((κ :→ ι :→ t) :→ σ :→ Q ι κ σ)\n  Left \"QUD\"     -&gt; Just (Q ι κ σ :→ κ :→ ι :→ t)\n  Left \"ϵ\"       -&gt; Just σ -- the starting state\n  _              -&gt; Nothing\n\n\n“Built-in” distributions\nSome constants can be used to represent probability (e.g., Bernoulli and normal) distributions, and standard ways of manipulating them:\n-- | Some probability distributions (and certain ways of manipulating them).\ntauDistributions ::Sig\ntauDistributions = \\case\n  Left \"Bernoulli\" -&gt; Just (r :→ P t)\n  Left \"Normal\"    -&gt; Just (r :× r :→ P r)\n  Left \"Truncate\"  -&gt; Just (r :× r :→ P r :→ P r)\n  Left \"#\"         -&gt; Just (P α) -- undefined distributions\n  _                -&gt; Nothing\nThe third constant, for example, can be used to represent the truncation of some distribution to values within a specified range. Note also the fourth constant, which encodes “undefined” probability distributions.\n\n\nComputing with numbers and truth values\nOther constants can be used to do computations with, e.g., truth values and real numbers:\n-- | Some basic data types (e.g., truth values and reals) and ways of computing with them.\ntauBasicStuff :: Sig\ntauBasicStuff = \\case\n  Left  \"if_then_else\" -&gt; Just (t :× α :× α :→ α) -- compute /if then else/\n  Left  \"𝟙\"            -&gt; Just (t :→ r)           -- the indicator function\n  Left  \"mult\"         -&gt; Just (r :× r :→ r)      -- multiply two numbers\n  Left  \"add\"          -&gt; Just (r :× r :→ r)      -- add two numbers\n  Left  \"neg\"          -&gt; Just (r :→ r)           -- add a minus sign\n  Left  \"(≥)\"          -&gt; Just (r :→ r :→ t)      -- compare two numbers\n  Left  \"max\"          -&gt; Just ((r :→ t) :→ r)    -- take the maximum number from a set\n  Right _              -&gt; Just r                  -- real numbers are constants\n  _                    -&gt; Nothing\n\n\nMore probabilistic stuff\nOther constants for, e.g., factoring, making observations, and computing probabilities.\n-- | The probability operator, /factor/, and /observe/.\ntauProbabilities :: Sig\ntauProbabilities = \\case\n  Left \"Pr\"      -&gt; Just (P t :→ r)\n  Left \"factor\"  -&gt; Just (r :→ P Unit)\n  Left \"observe\" -&gt; Just (t :→ P Unit)\n  _              -&gt; Nothing\n\n\nCombining signatures\nIt would be convenient to have a way, given any two signatures, to combine them. In Haskell, we can accomplish this with the following function that combines values inhabiting types that instantiate the Alternative class:\n(&lt;||&gt;) :: Alternative m =&gt; (a -&gt; m b) -&gt; (a -&gt; m b) -&gt; a -&gt; m b\nf &lt;||&gt; g = \\x -&gt; f x &lt;|&gt; g x\nBecause Maybe is an instance of Alternative, we can combine signatures using such a function. For example, if we want to combine the signature tauLogical with the signature tauNonLogical, we can do:\ntauLogicalNonLogical :: Sig\ntauLogicalNonLogical = tauLogical &lt;||&gt; tauNonLogical\nIndeed, we can combine as many signatures as we want in this way, using (&lt;||&gt;). The resulting signature will type all of the constants that the component signatures type, with signatures listed further to the left taking precedence in case there is any overlap.",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Constants"
    ]
  },
  {
    "objectID": "pds-intro/expressions-and-discourses.html",
    "href": "pds-intro/expressions-and-discourses.html",
    "title": "Expressions and discourses",
    "section": "",
    "text": "\\[\n\\newcommand{\\expr}[3]{\\begin{array}{c}\n#1 \\\\\n\\bbox[lightblue,5px]{#2}\n\\end{array} ⊢ #3}\n\\newcommand{\\ct}[1]{\\bbox[font-size: 0.8em]{\\mathsf{#1}}}\n\\newcommand{\\updct}[1]{\\ct{upd\\_#1}}\n\\newcommand{\\abbr}[1]{\\bbox[transform: scale(0.95)]{\\mathtt{#1}}}\n\\newcommand{\\pure}[1]{\\bbox[border: 1px solid orange]{\\bbox[border: 4px solid transparent]{#1}}}\n\\newcommand{\\return}[1]{\\bbox[border: 1px solid black]{\\bbox[border: 4px solid transparent]{#1}}}\n\\def\\P{\\mathtt{P}}\n\\def\\Q{\\mathtt{Q}}\n\\def\\True{\\ct{T}}\n\\def\\False{\\ct{F}}\n\\def\\ite{\\ct{if\\_then\\_else}}\n\\def\\Do{\\abbr{do}}\n\\]\nWe now turn to discourse states. These, like indices, are understood in terms of a theory of states and locations (and similarly, as having some polymorphic type \\(σ\\)). We generally refer to the values stored in discourse states as metalinguistic parameters. These include, e.g., the common ground and the QUD, along with other conversationally relevant features of discourse (e.g., representations of the entities to which pronouns can refer, the available antecedents for ellipsis, etc.). One can view a discourse state as akin to the context state of Farkas and Bruce (2010), though the type of state we employ is in principle less constrained, insofar as the type of individual parameters is open ended. Since discourse states provide access to the common ground and the QUD, they are associated with constants and equations like the following:\nThough we haven’t yet discussed the types we take to be associated with QUDs, note that \\(\\ct{CG}\\) and \\(\\updct{CG}\\) ought to have the following types:\nFinally, as for indices, we provide a constant \\(\\ct{ϵ}\\) representing a “starting” state:",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Expressions and discourses"
    ]
  },
  {
    "objectID": "pds-intro/expressions-and-discourses.html#expression-meanings",
    "href": "pds-intro/expressions-and-discourses.html#expression-meanings",
    "title": "Expressions and discourses",
    "section": "Expression meanings",
    "text": "Expression meanings\nWe regard expressions’ probabilistic semantic values as functions of type \\(σ → \\P (α × σ^{\\prime})\\), where \\(σ\\) and \\(σ^{\\prime}\\) should be understood to represent the types of discourse states. We abbreviate this type as \\(ℙ^{σ}_{σ^{\\prime}} α\\):\n\n\\[\nℙ^{σ}_{σ^{\\prime}} α ≝ σ → \\P (α × σ^{\\prime})\n\\]\n\nThus given an input state \\(s : σ\\), the semantic value of an expression produces a probability distribution over pairs of ordinary semantic values of type \\(α\\) and possible output states \\(s^{\\prime} : σ^{\\prime}\\). An expression of category \\(np\\), for instance, now has the probabilistic type \\(ℙ^{σ}_{σ^{\\prime}}(⟦np⟧) \\,\\, = \\,\\, ℙ^{σ}_{σ^{\\prime}} e \\,\\, = \\,\\, σ → \\P (e × σ^{\\prime})\\).\nBuilding on this view of expressions, we regard an ongoing discourse as a function of type \\(ℙ^{σ}_{σ^{\\prime}} ⋄\\). The effects that both expressions and discourses have are therefore stateful-probabilistic: they map input states to probability distributions over output states. Discourses differ from expressions in that the value discourses compute is trivial: it is invariably the empty tuple \\(⋄\\), as determined by its type. Thus while expressions produce both stateful-probabilistic effects and values, discourses have only effects, i.e., they merely update the state.\n\nProgram composition via parameterized monads\nThe setup we have introduced allows for the possibility that the state parameter \\(σ\\) changes in the course of evaluating an expression’s probabilistic semantic value. Such a value may map an input state \\(s : σ\\) onto a probability distribution over outputs states of type \\(σ^{\\prime}\\) (\\(σ^{\\prime} ≠ σ\\)). This flexibility is useful to capture the changing nature of certain components of the discourse state. For example, the QUDs stored in a state may consist of questions of different types—e.g., degree questions, individual questions, etc. Thus whenever an utterance functions to add a QUD to the state, the input state’s type may not match the output state’s type.\nTo countenance such type-level flexibility, we view the types \\(ℙ^{σ}_{σ^{\\prime}} α\\) as arising from a parameterized State.Probability monad, given the set \\(\\mathcal{T}_{A}\\) of types as the relevant collection of parameters.1 Parameterized monads are associated with their own definitions of (parameterized) return and bind. To increase clarity, while distinguishing the notations for parameterized and vanilla monads, we present the bind statements of a parameterized monad \\(ℙ\\) using Haskell’s \\(\\Do\\)-notation.\n\nGiven a collection \\(\\mathcal{S}\\) of parameters, a parameterized monad is a map \\(ℙ\\) from triples consisting of two parameters and a type onto types (i.e., given parameters \\(p, q ∈ \\mathcal{S}\\) and a type \\(α\\), \\(ℙ^{p}_{q} α\\) is some new type), equipped with two operators satisfying the parameterized monad laws in (6). \\[\n\\begin{align*}\n\\return{(·)}_{p}\\ \\ &:\\ \\ α → ℙ^{p}_{p} α \\tag{`return'} \\\\\n\\begin{array}{rl}\n\\Do_{p, q, r} & x ← \\_\\_ \\\\\n& \\_\\_(x)\n\\end{array}\\ \\\n&:\\ \\ ℙ^{p}_{q} α → (α → ℙ^{q}_{r} β) → ℙ^{p}_{r} β \\tag{`bind'}\n\\end{align*}\n\\]\n\nThe parameterized monad laws themselves appear formally identical to the ordinary monad laws (see (6)); the crucial difference is their implicit manipulation of parameters moving from the left-hand side of each equality to the right-hand side.\n\n\\[\n\\begin{array}{c}\n\\textit{Left identity} & \\textit{Right identity} \\\\[1mm]\n\\begin{array}{rl}\n\\Do_{p, p, q} & x ← \\return{v}_{p} \\\\\n& k(x)\n\\end{array}\\ \\ =\\ \\ \\ k(v)\n& \\begin{array}{rl}\n\\Do_{p, q, q} & x ← m \\\\\n& \\return{x}_{q}\n\\end{array} \\ \\ =\\ \\ \\ m\n\\end{array}\n\\] \\[\n\\begin{array}{c}\n\\textit{Associativity} \\\\[1mm]\n\\begin{array}{rl}\n\\Do_{p, r, s} & y ← \\left(\\begin{array}{rl}\n\\Do_{p, q, r} & x ← m \\\\\n& n(x)\n\\end{array}\\right) \\\\\n& o(y)\n\\end{array}\\ \\ =\\ \\ \\begin{array}{rl}\n\\Do_{p, q, s} & x ← m \\\\\n& \\begin{array}{rl}\n    \\Do_{q, r, s} & y ← n(x) \\\\\n    & o(y)\n\\end{array}\n\\end{array}\n\\end{array}\n\\]\n\nThe \\(\\Do\\)-notation in the above should be read as saying, “first bind the variable \\(x\\) to the program \\(m\\), and then do \\(k(x)\\)’’. Indeed, this statement gives an intuitive summary of what the definition of State.Probability accomplishes: to bind \\(m\\) to the continuation \\(k\\), one must abstract over an input state \\(s\\) and feed it to \\(m\\), sample a value \\(x\\) paired with an output state \\(s^{\\prime}\\) from the result, and finally, feed \\(x\\), along with \\(s^{\\prime}\\), to \\(k\\).\nIn practice, we will leave the parameters implicit when we use this notation. We also suppress superfluous uses of \\(\\Do\\)-notation, writing\n\\[\n\\begin{array}{rl}\n\\Do & x ← m \\\\\n    & y → m \\\\\n    & n\n\\end{array}\n\\]\nfor\n\\[\n\\begin{array}{rl}\n\\Do & x ← m \\\\\n    & \\begin{array}{rl}\n    \\Do & y → m \\\\\n    & n\n    \\end{array}\n\\end{array}\n\\]\nWe will also sometimes use a “bracket” notation, writing one-liners such as\n\\[\n\\Do \\{x ← m; n\\}\n\\]\ninstead of\n\\[\n\\begin{array}{rl}\n\\Do & x ← m \\\\\n    & n\n\\end{array}\n\\]\nto save space.\n\n\nState.Probability\nThe particular parameterized monad we employ is State.Probability, where the relevant collection of parameters is \\(\\mathcal{T}_{A}\\).\n\n\\[\n\\begin{align*}\nℙ^{σ}_{σ^{\\prime}} α\\ \\ &=\\ \\ σ → \\P (α × σ^{\\prime}) \\\\[2mm]\n\\return{v}_{σ}\\ \\ &=\\ \\ λs.\\pure{⟨v, s⟩} \\\\[2mm]\n\\begin{array}{rl}\n\\Do_{σ, σ^{\\prime}, σ^{\\prime\\prime}} & x ← m \\\\\n& k(x)\n\\end{array}\\ \\\n&=\\ \\ λs.\\left(\\begin{array}{l}\n⟨x, s^{\\prime}⟩ ∼ m(s) \\\\\nk(x)(s^{\\prime})\n\\end{array}\\right)\n\\end{align*}\n\\]\n\nThese definitions can be encoded in Haskell as functions that manipulate terms (ensuring that fresh variables are used when necessary):\n-- | ** Some convience functions\n\n-- | Variable names are represented by strings.\ntype VarName = String\n\n-- | Generate an infinite list of variable names fresh for some list of terms.\nfresh :: [Term] -&gt; [VarName]\n\n-- | Smart(-ish) constructor for abstractions.\nlam :: Term -&gt; Term -&gt; Term\nlam (Var v) = Lam v\n\n-- | Smart(-ish) constructor for bind.\nlet' :: Term -&gt; Term -&gt; Term -&gt; Term\nlet' (Var v) = Let v\n\n-- | Paramterized return.\npurePP :: Term -&gt; Term\npurePP t = lam fr (Return (t & fr))\n  where fr:esh = map Var $ fresh [t]\n\n-- | Parameterized bind.\n(&gt;&gt;&gt;=) :: Term -&gt; Term -&gt; Term\nt &gt;&gt;&gt;= u = lam fr (let' e (t @@ fr) (u @@ Pi1 e @@ Pi2 e))\n  where fr:e:sh = map Var $ fresh [t, u]\nIn general, it will be useful to have access to a couple of basic operations for retrieving (\\(\\abbr{get}\\)) and updating (\\(\\abbr{put}\\)) the state of an ongoing discourse:\n\n\\[\n\\begin{align*}\n\\abbr{get} &: ℙ^{σ}_{σ} σ \\\\\n\\abbr{get} &= λs.\\pure{⟨s, s⟩} \\\\[2mm]\n\\abbr{put} &: σ^{\\prime} → ℙ^{σ}_{σ^{\\prime}} \\\\\n\\abbr{put}(s^{\\prime}) &= λs.\\pure{⟨⋄, s^{\\prime}⟩}\n\\end{align*}\n\\]\n\nNow, the current state of a given discourse can be retrieved (as \\(s\\)) by writing the statement \\(s ← \\abbr{get}\\) inside of a \\(\\Do\\)-block; meanwhile, writing the statement \\(\\abbr{put}(s)\\) updates this state so that it becomes \\(s\\).\nThese two operators can also be given the following Haskell encodings getPP and putPP:\ngetPP :: Term\ngetPP = lam' s (Return (s & s))\n\nputPP :: Term -&gt; Term\nputPP s = Lam fr (Return (TT & s))\n  where fr:esh = fresh [s]",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Expressions and discourses"
    ]
  },
  {
    "objectID": "pds-intro/expressions-and-discourses.html#pds-rules",
    "href": "pds-intro/expressions-and-discourses.html#pds-rules",
    "title": "Expressions and discourses",
    "section": "PDS Rules",
    "text": "PDS Rules\nWe provide our probabilistic CCG rule schemata in (9). These schemata mimic the definitions of ordinary CCG rules, but now semantic values are considered to be of type \\(ℙ^{σ}_{σ^{\\prime}} α\\) now, rather than simply of type \\(α\\). Thus rather than apply CCG operations to semantic values directly, we must bind these semantic values to variables of type \\(α\\) and apply the operations to those.\n\n\\[ \\small\n\\begin{array}{c}\n\\begin{prooftree}\n\\AxiomC{$\\expr{s_{1}}{M_{1}}{c/ b}$}\n\\AxiomC{$\\expr{s_{2}}{M_{2}}{b∣_{n}a_{n}\\,\\,⋯∣_{1}a_{1}}$}\n\\RightLabel{${&gt;}\\textbf{B}_{n}$}\\BinaryInfC{\\(\\expr{s_{1}\\,s_{2}}{\n\\begin{array}{rl}\n\\Do & \\{\\,m_{1} ← M_{1};\\,m_{2} ← M_{2}; \\\\\n& \\return{λx_{1}, …, x_{n}.m_{1}(m_{2}(x_{1})…(x_{n}))}\\,\\}\n\\end{array}\n}{c∣_{n}a_{n}\\,\\,⋯∣_{1}a_{1}}\\)}\n\\end{prooftree} \\\\[50pt]\n\\begin{prooftree}\n\\AxiomC{$\\expr{s_{1}}{m_{1}}{b∣_{n}a_{n}\\,\\,⋯∣_{1}a_{1}}$}\n\\AxiomC{$\\expr{s_{1}}{m_{2}}{c\\backslash b}$}\n\\RightLabel{${&lt;}\\textbf{B}_{n}$}\\BinaryInfC{\\(\\expr{s_{1}\\,s_{2}}{\n\\begin{array}{rl}\n\\Do & \\{\\,m_{1} ← M_{1};\\,m_{2} ← M_{2}; \\\\\n& \\return{λx_{1}, …, x_{n}.m_{2}(m_{1}(x_{1})…(x_{n}))}\\,\\}\n\\end{array}\n}{c∣_{n}a_{n}\\,\\,⋯∣_{1}a_{1}}\\)}\n\\end{prooftree} \\\\[50pt]\n\\begin{prooftree}\n\\AxiomC{$\\expr{s_{1}}{M_{1}}{b∣_{n}a_{n}\\,\\,⋯∣_{1}a_{1}}$}\n\\AxiomC{$\\expr{s_{2}}{M_{2}}{c\\backslash b∣_{n}a_{n}\\,\\,⋯∣_{1}a_{1}⋯∣_{1}a_{1}}$}\n\\RightLabel{${&lt;}\\textbf{S}_{n}$}\\BinaryInfC{\\(\\expr{s_{1}\\,s_{2}}{\n\\begin{array}{rl}\n\\Do & \\{\\,m_{1} ← M_{1};\\,m_{2} ← M_{2}; \\\\\n& \\return{λx_{1}, …, x_{n}.m_{1}(x_{1})…(x_{n})(m_{2}(x_{1})…(x_{n}))}\\,\\}\n\\end{array}\n}{c∣_{n}a_{n}\\,\\,⋯∣_{1}a_{1}}\\)}\n\\end{prooftree} \\\\[50pt]\n\\begin{prooftree}\n\\AxiomC{$\\expr{s_{1}}{M_{1}}{c/ b∣_{n}a_{n}\\,\\,⋯∣_{1}a_{1}}$}\n\\AxiomC{$\\expr{s_{2}}{M_{2}}{b∣_{n}a_{n}\\,\\,⋯∣_{1}a_{1}}$}\n\\RightLabel{${&gt;}\\textbf{S}_{n}$}\\BinaryInfC{\\(\\expr{s_{1}\\,s_{2}}{\n\\begin{array}{rl}\n\\Do & \\{\\,m_{1} ← M_{1};\\,m_{2} ← M_{2}; \\\\\n& \\return{λx_{1}, …, x_{n}.m_{2}(x_{1})…(x_{n})(m_{1}(x_{1})…(x_{n}))}\\,\\}\n\\end{array}\n}{c∣_{n}a_{n}\\,\\,⋯∣_{1}a_{1}}\\)}\n\\end{prooftree}\n\\end{array}\n\\]\n\nThe upshot is that, while an expression’s syntactic type continues to determine its compositional properties, its probabilistic, dynamic effects can be stated fairly independently.",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Expressions and discourses"
    ]
  },
  {
    "objectID": "pds-intro/expressions-and-discourses.html#making-an-assertion",
    "href": "pds-intro/expressions-and-discourses.html#making-an-assertion",
    "title": "Expressions and discourses",
    "section": "Making an assertion",
    "text": "Making an assertion\nRecall that we represent the meanings of expressions as functions of type \\(ℙ^{σ}_{σ^{\\prime}}\\): given an input state of type \\(σ\\), the meaning of an expression produces a probability distribution over pairs of ordinary meanings of type \\(α\\) and possible output states of type \\(σ^{\\prime}\\). Furthermore, given a sentence whose probabilistic dynamic meaning \\(φ\\) is of type \\(ℙ^{σ}_{σ^{\\prime}} (ι → t)\\), we can represent an assertion of that sentence as a discourse which updates the common ground. Specifically, we have a function \\(\\abbr{assert}\\):\n\n\\[\n\\begin{align*}\n  \\abbr{assert} &: ℙ^{σ}_{σ^{\\prime}} (ι → t) → ℙ^{σ}_{σ^{\\prime}} ⋄ \\\\\n  \\abbr{assert}(φ) &= \\begin{array}[t]{rl}\n\\Do & p ← φ \\\\\n    & s ← \\abbr{get} \\\\\n    & c ← \\return{\\ct{CG}(s)} \\\\\n    & c^{\\prime} ← \\return{\\left(\\begin{array}{l}\n    i ∼ c \\\\\n    \\ct{observe}(p(i)) \\\\\n    \\pure{i}\n    \\end{array}\\right)} \\\\\n    & \\abbr{put}(\\updct{CG}(c^{\\prime})(s))\n\\end{array}\n\\end{align*}\n\\]\n\nGiven such a \\(φ\\), \\(\\abbr{assert}(φ)\\) is a discourse of type \\(\\P^{σ}_{σ^{\\prime}} ⋄\\) representing an assertion of \\(φ\\). In plain English, \\(\\abbr{assert}(φ\\)) samples a proposition \\(p\\), given \\(φ\\), and then updates the common ground of the current state with \\(p\\). Ultimately, assertions modify an ongoing discourse so that its probability distribution over output states involves common grounds in which the proposition returned by \\(φ\\) has been observed to hold true.\nUsing a few new convenience functions, along with some new short-hands for named variables, \\(\\abbr{assert}\\) can be encoded in Haskell:\nassert :: Term\nassert = lam φ (φ &gt;&gt;&gt;= lam p (getPP &gt;&gt;&gt;= lam s (purePP (cg s) &gt;&gt;&gt;= lam c (purePP (let' i c (let' _' (observe (p @@ i)) (Return i))) &gt;&gt;&gt;= lam d (putPP (upd_CG d s))))))",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Expressions and discourses"
    ]
  },
  {
    "objectID": "pds-intro/expressions-and-discourses.html#asking-a-question",
    "href": "pds-intro/expressions-and-discourses.html#asking-a-question",
    "title": "Expressions and discourses",
    "section": "Asking a question",
    "text": "Asking a question\nWe follow a categorial tradition by analyzing questions as denoting—given an index—sets of true short answer meanings (see R. Hausser and Zaefferer 1978; R. R. Hausser 1983; Xiang 2021; cf. Karttunen 1977; Groenendijk and Stokhof 1984). Given some type \\(α\\) as the type of the short answer, a question therefore has a probabilistic dynamic meaning of type \\(ℙ^{σ}_{σ^{\\prime}} (α → ι → t)\\).\nAsking a question is a matter of pushing a question meaning onto the QUD stack (Ginzburg 1996; Farkas and Bruce 2010). Reflecting this, we recruit another operation, \\(\\abbr{ask}\\): \\[\\begin{align*}\n  \\abbr{ask} &: ℙ^{σ}_{σ^{\\prime}} (α → ι → t) → ℙ^{σ}_{\\Q ι α σ^{\\prime}} ⋄ \\\\\n  \\abbr{ask}(κ) &= \\begin{array}[t]{rl}\n    \\Do & q ← κ \\\\\n        & s ← \\abbr{get} \\\\\n        & \\abbr{put}(\\updct{QUD}(q)(s))\n    \\end{array}\n\\end{align*}\\] Given a probabilistic dynamic question meaning \\(κ\\), \\(\\abbr{ask}(κ)\\) samples a question meaning \\(q : α → ι → t\\), given \\(κ\\), and then adds \\(q\\) as a new QUD to the outgoing state. Note the type of the output state that \\(\\abbr{ask}\\) returns: \\(\\Q ι α σ^{\\prime}\\). \\(\\Q\\) is a new map from types to types which, like \\(\\P\\), we leave abstract; given a state type \\(σ^{\\prime}\\), the meaning of \\(\\Q ι α σ^{\\prime}\\) is the type of a new state with a question of type \\(α → ι → t\\) added to the QUD stack. Thus the type of \\(\\updct{QUD}\\) should be as in (11).\n\n\\[\n\\begin{align*}\n\\updct{QUD} : (α → ι → t) → σ → \\Q ι α σ\n\\end{align*}\n\\]\n\nIndeed, we should update the set of types in our Haskell encoding to accommodate the new operator:\n-- | Arrows, products, and probabilistic types, as well as (a) abstract types\n-- representing the addition of a new Q, and (b) type variables for encoding\n-- polymorphism.\ndata Type = At Atom\n          | Type :→ Type\n          | Unit\n          | Type :× Type\n          | P Type\n          | Q Type Type Type\n          | TyVar String\n  deriving (Eq)\nFinally, we can also provide an implementation of \\(\\abbr{ask}\\):\nask :: Term\nask = lam κ' (κ' &gt;&gt;&gt;= lam q (getPP &gt;&gt;&gt;= lam s (putPP (upd_QUD q s))))",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Expressions and discourses"
    ]
  },
  {
    "objectID": "pds-intro/expressions-and-discourses.html#responding-to-a-question",
    "href": "pds-intro/expressions-and-discourses.html#responding-to-a-question",
    "title": "Expressions and discourses",
    "section": "Responding to a question",
    "text": "Responding to a question\nPDS also models responses to questions; at any point in an ongoing discourse, one can respond to the QUD at the top of the current QUD stack based on one’s prior knowledge. Concretely, a given responder has some background knowledge \\(bg : \\P σ\\) constituting a prior distribution over starting states. The responder uses this prior, in conjuction with the interim updates to the discourse, to derive a probability distribution over answers to the QUD. If the set of possible answers are real numbers (e.g., representing degrees of likelihood), this answer distribution is gotten by retrieving the QUD of any given state \\(s^{\\prime}\\)—resulting in a distribution over QUDs—and then taking the maximum value of which it is true at an index sampled from the common ground—resulting, finally, in a distribution over real numbers.\n\nLinking assumptions\nIn practice (e.g., in the setting of a formal experiment), an answer needs to be given using a particular testing instrument. We assume that a given testing instrument may be modeled by a family \\(f\\) of distributions representing the likelihood, which is then fixed by a collection \\(Φ\\) of nuisance parameters. For the purposes of the implementation, we assume answers to the current QUD are real numbers, so that for fixed likelihood \\(f_{Φ}\\), \\(f_{Φ} : r → \\P ρ\\), for the type \\(ρ\\) of responses; this is not necessary, however, and the types of such functions could be generalized.\nThus we may define a family of response functions, parametric in the testing instrument (i.e., likelihood function), each of which takes a distribution \\(bg\\) representing one’s background knowledge, along with an ongoing discourse \\(m\\): \\[\\begin{align*}\n  \\abbr{respond}^{f_Φ : r → \\P ρ} &: \\P σ → ℙ^{σ}_{\\Q ι r σ^{\\prime}} ⋄ → \\P ρ \\\\\n  \\abbr{respond}^{f_Φ : r → \\P ρ}(bg)(m) &= \\begin{array}[t]{l}\n    s ∼ bg \\\\\n    ⟨⋄, s^{\\prime}⟩ ∼ m(s) \\\\\n    i ∼ \\ct{CG}(s^{\\prime}) \\\\\n    f(\\ct{max}(λd.\\ct{QUD}(s)(d)(i)), Φ)\n    \\end{array}\n\\end{align*}\\] For a fixed likelihood function \\(f_{Φ}\\) mapping any given real number answer onto a distribution over possible responses of type \\(ρ\\) (for some \\(ρ\\)), the response function takes a distribution representing background knowledge and a discourse to produce a response distribution. It does this by composing the discourse with background knowledge, as above, and then obtaining the maximum degree (i.e., real number) answer to the current QUD, before applying the likelihood function \\(f_{Φ}\\) to this degree.\nThe testing instrument employed in the studies we describe in the next few days, for example, is always a slider scale that records responses on the unit interval \\([0, 1]\\). A suitable likelihood might therefore be a truncated normal distribution: \\(f(x, Φ) = \\mathcal{N}(x, σ)\\,\\ct{T}[0, 1]\\) (so that \\(f = \\mathcal{N}\\) and \\(Φ = σ\\)). This likelihood—which Grove and White (2024) employ in their models of factivity—can be viewed as allowing some distribution of response errors, given the intended target response (i.e., the answer to the question).\nBefore moving onto some further implementation details, we can also show the Haskell encoding of \\(\\abbr{respond}\\), which follows the description above:\nrespond :: Term\nrespond = lam f (lam bg (lam m (let' s bg m')))\n  where m'          = let' _s' (m @@ s) (let' i (cg (Pi2 _s')) (f @@ max' (lam x (qud (Pi2 _s') @@ x @@ i))))\n        s:_s':i:x:_ = map Var $ fresh [bg, m]",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Expressions and discourses"
    ]
  },
  {
    "objectID": "pds-intro/expressions-and-discourses.html#footnotes",
    "href": "pds-intro/expressions-and-discourses.html#footnotes",
    "title": "Expressions and discourses",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n See Atkey (2009) on the parameterized State monad and parameterized monads more generally. The current parameterized monad can be viewed as applying a parameterized State monad transformer to the underlying probability monad \\(\\P\\); see Liang, Hudak, and Jones (1995) on monad transformers.↩︎",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Expressions and discourses"
    ]
  },
  {
    "objectID": "pds-intro/ccg.html",
    "href": "pds-intro/ccg.html",
    "title": "Combinatory Categorial Grammar",
    "section": "",
    "text": "\\[\n\\newcommand{\\expr}[3]{\\begin{array}{c}\n#1 \\\\\n\\bbox[lightblue,5px]{#2}\n\\end{array} ⊢ #3}\n\\newcommand{\\ct}[1]{\\bbox[font-size: 0.8em]{\\mathsf{#1}}}\n\\newcommand{\\updct}[1]{\\ct{upd\\_#1}}\n\\newcommand{\\abbr}[1]{\\bbox[transform: scale(0.95)]{\\mathtt{#1}}}\n\\newcommand{\\pure}[1]{\\bbox[border: 1px solid orange]{\\bbox[border: 4px solid transparent]{#1}}}\n\\newcommand{\\return}[1]{\\bbox[border: 1px solid black]{\\bbox[border: 4px solid transparent]{#1}}}\n\\def\\P{\\mathtt{P}}\n\\def\\Q{\\mathtt{Q}}\n\\def\\True{\\ct{T}}\n\\def\\False{\\ct{F}}\n\\def\\ite{\\ct{if\\_then\\_else}}\n\\def\\Do{\\abbr{do}}\n\\]\nThe syntactic and semantic substrate we employ is Combinatory Categorial Grammar (CGG). CCG is a highly lexicalized grammar formalism, in which expressions are equipped with syntactic types—i.e., categories. Syntactic types in CCG encode an expression’s selectional and distributional properties. A noun phrase such as a race, for example, may be given the type \\(np\\), while a determiner—something which, in English, occurs to the left of a noun in order to form a noun phrase—may be given the type \\(np / n\\). Thus the forward direction of the slash indicates that a noun should occur to the right of the determiner.\nWe use CCG in our presentation of PDS because one of our goals is to write semantic grammar fragments which produce analyses of a given collection of probabilistic semantic phenomena. Having a grammar fragment (e.g., one which generates the stimuli about which inference judgments are experimentally collected to create some linguistic dataset) allows one to implement an unbroken chain that connects the semantic analysis of some phenomenon to a probabilistic model of judgments about expressions featuring the phenomenon. CCG is likely to be sufficiently expressive to capture most (if not all) of the kinds of syntactic dependencies found in natural languages (Joshi 1985; Vijay-Shanker and Weir 1994 et seq.; cf. Kobele 2006). Meanwhile, because it is semantically transparent, it makes writing such grammar fragments relatively straightforward.\nFor current purposes, we can assume the following small set of atomic syntactic types. \\[\n\\begin{align*}\n\\mathcal{A} &\\Coloneqq np ∣ n ∣ s\n\\end{align*}\n\\] Here we have the usual categories for noun phrases (\\(np\\)), nouns (\\(n\\)), and sentences (\\(s\\)). \\[\n\\begin{align*}\n\\mathcal{C}_{\\mathcal{A}} &\\Coloneqq \\mathcal{A} ∣ \\mathcal{C}_{\\mathcal{A}}/\\mathcal{C}_{\\mathcal{A}} ∣ \\mathcal{C}_{\\mathcal{A}}\\backslash\\mathcal{C}_{\\mathcal{A}}\n\\end{align*}\n\\] Thus following , \\(\\mathcal{C}_{\\mathcal{A}}\\) includes the five elements of \\(\\mathcal{A}\\), as well as \\[\\begin{align*}\n  s/np, s\\backslash np, np/n, (np\\backslash n)/ np, (s\\backslash s)/s,\n\\end{align*}\\] and so on. Any complex syntactic type in \\(\\mathcal{C}_{\\mathcal{A}}\\) features slashes, which indicate on which side an expression of that type takes its argument. Thus an expression of type \\(b/ a\\) (for some two types \\(a\\) and \\(b\\)) occurs with an expression of type \\(a\\) on its right in order to form an expression of type \\(b\\), while an expression of type \\(b\\backslash a\\) occurs with an expression of type \\(a\\) on its left in order to form an expression of type \\(b\\). We adopt the convention of notating syntactic types without parentheses when possible, under the assumption that they are left-associative; i.e., \\(a∣_{1}b∣_{2}c ≝ (a∣_{1}b)∣_{2}a\\) (where \\(∣_{1}\\) and \\(∣_{2}\\) are either forward or backward slashes). Thus for example, the type \\(s\\backslash(np/ np)\\) continues to be written as such, while the type \\((s\\backslash np)/ np\\) may be shortened to ‘\\(s\\backslash np/ np\\)’.\nIn Haskell, we can introduce a single data type to encode both atomic categories and categories featuring slashes.\nTo write CCG expressions, we use the notation \\[\\begin{align*}\n  \\expr{s}{m}{c}\n\\end{align*}\\] which is to be read as stating that string \\(s\\) has category \\(c\\) and semantic value \\(m\\). We assume \\(s\\) to be a string over some alphabet \\(Σ\\) (i.e., \\(s ∈ Σ^{*}\\)), which we regard as a finite set; e.g., the set of ``morphemes of English’’. Meanwhile, we assume \\(m\\) to be a typed λ-term. We leave somewhat open the question of what types of λ-terms may be used to define semantic values, but we adopt at least the typing rules in . Assuming that all semantic values are closed terms, we therefore have abstractions (\\(λx.t\\)), applications (\\(t(u)\\)), and \\(n\\)-ary tuples (\\(⟨t_{1}, ⋯, t_{n}⟩\\)), along with the empty tuple \\(⋄\\). We additionally assume that λ-terms can feature constants, drawn from some countable set.\nAs for the semantic types themselves, we can assume that there are the following atomic types, where \\(e\\) is the type of entities, and \\(t\\) is the type of the truth values \\(\\True\\) and \\(\\False\\).\n\\[\\begin{align*}\nA \\Coloneqq e ∣ t\n\\end{align*}\\]\nThe full set of types over \\(A\\) (\\(\\mathcal{T}_{A}\\)) is then defined as follows:\n\\[\\begin{align*}\n   \\mathcal{T}_{A} \\Coloneqq A ∣ \\mathcal{T}_{A} → \\mathcal{T}_{A} ∣ \\mathcal{T}_{A} × \\mathcal{T}_{A} ∣ ⋄\n\\end{align*}\\]\nTypes can be encoded in Haskell via two data types for atomic and complex types, respectively:\nNote that the Haskell encoding allows types to be polymorphic, by allowing type variables (TyVar String). Our use of polymorphism is fairly restricted, however, in that any type variable may only be quantified at the top level. Thus functions and values may themselves be polymorphic—their types can be underspecified—but functions may not take polymorphic values as arguments; any ambiguity about the type of an argument must be global. This means that while an expression such as \\(λx.x\\) has the polymoprhic type \\(α → α\\), the expression \\(λf.f(λy.y)(f(λx, y.x))\\), where \\(f\\) must have two distinct types in each of its bound occurrences, will not receive a type. Including such limited polymorphism is useful because it allows for the inclusion of certain kinds of polymorphic constants, e.g., the universal quantifier \\(∀ : (α → t) → t\\), which we may wish to be able to quantify not only over entities, but other types of objects (e.g., real numbers, or even functions).\nJust as with complex syntactic types, we adopt the convention of notating complex semantic types without parentheses when possible. Unlike syntactic types, we assume semantic types are right-associative.^[ These conventions mirror each other in the sense that the input type of a function type is assumed to be atomic unless otherwise specified by the use of parentheses. Typing rules for typed λ-terms may then be given as follows:\n\\[ \\small\n\\begin{array}{c}\n\\begin{prooftree}\n\\AxiomC{}\n\\RightLabel{$\\mathtt{Ax}$}\\UnaryInfC{$Γ, x : α ⊢ x : α$}\n\\end{prooftree}\n& \\begin{prooftree}\n\\AxiomC{$Γ, x : α ⊢ t : β$}\n\\RightLabel{${→}\\mathtt{I}$}\\UnaryInfC{$Γ ⊢ λx.t : α → β$}\n\\end{prooftree}\n& \\begin{prooftree}\n\\AxiomC{$Γ ⊢ t : α → β$}\n\\AxiomC{$Γ ⊢ u : α$}\n\\RightLabel{${→}\\mathtt{E}$}\\BinaryInfC{$Γ ⊢ t(u) : β$}\n\\end{prooftree} \\\\[2mm]\n\\begin{prooftree}\n\\AxiomC{}\n\\RightLabel{$⋄\\mathtt{I}$}\\UnaryInfC{$Γ ⊢ ⋄ : ⋄$}\n\\end{prooftree}\n& \\begin{prooftree}\n\\AxiomC{$Γ ⊢ t : α$}\n\\AxiomC{$Γ ⊢ u : β$}\n\\RightLabel{$×\\mathtt{I}$}\\BinaryInfC{$Γ ⊢ ⟨t, u⟩ : α × β$}\n\\end{prooftree}\n& \\begin{prooftree}\n\\AxiomC{$Γ ⊢ t : α_1 × α_2$}\n\\RightLabel{$×\\mathtt{E}_{j}$}\\UnaryInfC{$Γ ⊢ π_{j}(t) : α_{j}$}\n\\end{prooftree}\n\\end{array}\n\\]\nThese cover λ-abstractions, applications, the unit type \\(⋄\\) (which is inhabited by the empty tuple \\(⋄\\)), pairing, and projections.\nWe provide an untyped implementation of λ-terms in Haskell; meanwhile, we provide a separate mechanism for doing type inference for these terms.1\nThis implementation of the λ-calculus allows it to feature constants. We allow for both the Haskell Double type to be encoded as constants, as well as the String type. Allowing doubles to be constants will make, e.g., arithmetic computations more straightforward as the system is further developed.\nAlthough we employ atomic types only for entities and truth values, we will make use of a form of intensionality in our semantic fragments, so that meanings will generally depend on an index of evaluation (which we typically denote ‘\\(i\\)’). However, we make no commitments about its type, thus allowing expressions’ meanings to be polymorphic—this choice will be justified later on in these notes, when we introduce the full system. Meanwhile, we’ll provide the polymorphic types of such meanings using Greek letters to represent type variables (e.g., \\(ι\\) for \\(i\\)), while retaining Latin letters for atomic types.\nIn CCG, expressions are combined to form new expressions using application rules, as well as composition (\\(\\textbf{B}\\)) rules and (often) type-raising (\\(\\textbf{T}\\)) and substitution (\\(\\textbf{S}\\)) rules (see, e.g., Steedman 2000). The string every linguist can be derived by right application from expressions for the strings every and linguist, for example.\nThe resulting expression has the syntactic type of a quantifier; in this case, it takes on its right an expression which takes a noun phrase on its left to form a sentence, and it forms a sentence with that expression. This type—\\(s/(s\\backslash np)\\)—is mirrored by the type of the λ-term which is the expression’s semantic value: \\((e → ι → t) → ι → t\\). Indeed, the two are related by a type homomorphism; i.e., a map from syntactic types to semantic types that preserves certain structure—here, the structure of syntactic types formed via slashes (\\(/\\) and \\(\\backslash\\)), which get turned into semantic types formed via arrows (\\(→\\)). We may codify the behavior of this homomorphism on atomic syntactic types.\nThe CCG derivation given in (1) tacitly assumes that noun phrases denote entities, that nouns denote functions from entities to propositions (i.e., functions of type \\(ι → t\\)), and that sentences denote propositions.\nCrucially, every CCG rule is analogous to the application rules in that it preserves the structure of syntactic types in the types of semantic values via the type homomorphism. For another example, the rightward composition rule can be used to combine every linguist with saw.\nHere, the resulting type—\\(s/ np\\)—is mapped to \\(⟦np⟧ → ⟦s⟧ = e → ι → t\\), which is precisely the type of the resulting semantic value.",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Combinatory Categorial Grammar"
    ]
  },
  {
    "objectID": "pds-intro/ccg.html#footnotes",
    "href": "pds-intro/ccg.html#footnotes",
    "title": "Combinatory Categorial Grammar",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n Our λ-terms are thus Curry-typed, so that operations on terms need only attend to their syntax. The alternative, Church-typing, makes types an inherent part of the terms themselves.↩︎",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Combinatory Categorial Grammar"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site contains materials for a course on Probabilistic dynamic semantics given by Julian Grove and Aaron Steven White at NASSLLI 2025, held at the University of Washington from June 23–27, 2025.",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "about.html#about-the-instructors",
    "href": "about.html#about-the-instructors",
    "title": "About",
    "section": "About the instructors",
    "text": "About the instructors\nJulian Grove is a postdoctoral researcher in Linguistics at the University of Rochester and a member of the Formal and Computational Semantics lab (FACTS.lab). He is interested in combining computational tools from Bayesian data analysis and programming language theory and bringing them to semantics. He will be an Assistant Professor of Semantics and Computational Linguistics at the University of Florida starting in August, 2025.\nAaron Steven White is an Associate Professor of Linguistics and Computer Science at the University of Rochester, where he directs the Center for Language Sciences and the Formal and Computational Semantics lab (FACTS.lab). His research investigates the relationship between linguistic expressions and conceptual categories that undergird the human ability to convey information about possible past, present, and future configurations of things in the world.",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "about.html#about-the-site",
    "href": "about.html#about-the-site",
    "title": "About",
    "section": "About the site",
    "text": "About the site\nThe site itself is built using Quarto. The source files for this site are available on github at juliangrove/pds-2025.",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "about.html#acknowledgments",
    "href": "about.html#acknowledgments",
    "title": "About",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThe materials for Module 3 were developed partly in collaboration with Helena Aparicio.",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "about.html#license",
    "href": "about.html#license",
    "title": "About",
    "section": "License ",
    "text": "License \nProbabilistic dynamic semantics by Julian Grove and Aaron Steven White is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. Based on work at https://github.com/juliangrove/pds-2025.",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "background/understanding-gradience.html",
    "href": "background/understanding-gradience.html",
    "title": "Understanding gradience",
    "section": "",
    "text": "\\[\n\\newcommand{\\expr}[3]{\\begin{array}{c}\n#1 \\\\\n\\bbox[lightblue,5px]{#2}\n\\end{array} ⊢ #3}\n\\newcommand{\\ct}[1]{\\bbox[font-size: 0.8em]{\\mathsf{#1}}}\n\\newcommand{\\updct}[1]{\\ct{upd\\_#1}}\n\\newcommand{\\abbr}[1]{\\bbox[transform: scale(0.95)]{\\mathtt{#1}}}\n\\newcommand{\\pure}[1]{\\bbox[border: 1px solid orange]{\\bbox[border: 4px solid transparent]{#1}}}\n\\newcommand{\\return}[1]{\\bbox[border: 1px solid black]{\\bbox[border: 4px solid transparent]{#1}}}\n\\def\\P{\\mathtt{P}}\n\\def\\Q{\\mathtt{Q}}\n\\def\\True{\\ct{T}}\n\\def\\False{\\ct{F}}\n\\def\\ite{\\ct{if\\_then\\_else}}\n\\def\\Do{\\abbr{do}}\n\\]\nOne of the most striking findings from experimental semantics and pragmatics is the pervasiveness of gradience in aggregated measures.1 While semanticists have long recognized the existence of gradience in some domains–e.g. gradable adjectives–we often assume categorical distinctions in other domains–e.g. factivity. And even where traditional approaches assume categorical distinctions, experimental methods often reveal continuous variation. For the reasons laid out above, understanding this gradience is crucial for developing theories that connect formal semantics to behavioral data.",
    "crumbs": [
      "Background",
      "Understanding gradience"
    ]
  },
  {
    "objectID": "background/understanding-gradience.html#footnotes",
    "href": "background/understanding-gradience.html#footnotes",
    "title": "Understanding gradience",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn this course, we will focus mainly on gradience in aggregated inference judgments, but there is a deep literature on gradience in acceptability judgments within the experimental syntax literature (Bard, Robertson, and Sorace 1996; Keller 2000; Sorace and Keller 2005; Sprouse 2007, 2011; Featherston 2005, 2007; Gibson and Fedorenko 2010, 2013; Sprouse and Almeida 2013; Sprouse, Schütze, and Almeida 2013; Schütze and Sprouse 2014; Lau, Clark, and Lappin 2017; Sprouse et al. 2018).↩︎",
    "crumbs": [
      "Background",
      "Understanding gradience"
    ]
  },
  {
    "objectID": "background/theory-to-data.html",
    "href": "background/theory-to-data.html",
    "title": "The bridge from theory to data",
    "section": "",
    "text": "\\[\n\\newcommand{\\expr}[3]{\\begin{array}{c}\n#1 \\\\\n\\bbox[lightblue,5px]{#2}\n\\end{array} ⊢ #3}\n\\newcommand{\\ct}[1]{\\bbox[font-size: 0.8em]{\\mathsf{#1}}}\n\\newcommand{\\updct}[1]{\\ct{upd\\_#1}}\n\\newcommand{\\abbr}[1]{\\bbox[transform: scale(0.95)]{\\mathtt{#1}}}\n\\newcommand{\\pure}[1]{\\bbox[border: 1px solid orange]{\\bbox[border: 4px solid transparent]{#1}}}\n\\newcommand{\\return}[1]{\\bbox[border: 1px solid black]{\\bbox[border: 4px solid transparent]{#1}}}\n\\def\\P{\\mathtt{P}}\n\\def\\Q{\\mathtt{Q}}\n\\def\\True{\\ct{T}}\n\\def\\False{\\ct{F}}\n\\def\\ite{\\ct{if\\_then\\_else}}\n\\def\\Do{\\abbr{do}}\n\\]\nSemantic theory has achieved remarkable success in characterizing the compositional structure of natural language meaning. Through decades of careful theoretical work, semanticists have developed elegant formal systems that capture how complex meanings arise from the systematic combination of simpler parts. These theories explain two fundamental types of judgments that speakers make: acceptability judgments about whether strings are well-formed, and inference judgments about what follows from what speakers say.\nThe field now stands at an exciting juncture. The rise of large-scale experimental methods and computational modeling opens new opportunities to test and refine these theoretical insights against rich behavioral data. The challenge—and opportunity—is to connect our elegant formal theories to the messy, gradient patterns we observe when hundreds of speakers make thousands of judgments. How can we maintain the theoretical insights that formal semantics has achieved while extending them to account for this new empirical richness?\nProbabilistic Dynamic Semantics (PDS) aims to provide a systematic bridge between these theoretical insights and behavioral data. It takes the compositional analyses developed using traditional Montagovian methods and maps them to probabilistic models that can be quantitatively evaluated against experimental results. The goal is not to replace traditional semantics but to extend its reach, allowing us to test theoretical predictions at unprecedented scale while maintaining formal rigor."
  },
  {
    "objectID": "background/theory-to-data.html#traditional-semantic-methodology-foundations-of-success",
    "href": "background/theory-to-data.html#traditional-semantic-methodology-foundations-of-success",
    "title": "The bridge from theory to data",
    "section": "Traditional Semantic Methodology: Foundations of Success",
    "text": "Traditional Semantic Methodology: Foundations of Success\nSemanticists study the systematic relationships between linguistic expressions and the inferences they support. The field’s methodology centers on two types of judgments:\nAcceptability judgments assess whether strings are well-formed relative to a language and in a particular context of use (Chomsky 1957; see Schütze 2016).   For example, in a context where a host asks what a guest wants with coffee, (1) is clearly acceptable, while (2) is not Sprouse and Villata (2021):\n\nWhat would you like with your coffee?\n#What would you like and your coffee?\n\nInference judgments assess relationships between strings (see Davis and Gillon 2004).   When speakers hear (3), they typically infer (4) (White 2019):\n\nJo loved that Mo left.\nMo left.\n\n\nObservational Adequacy\nA core desideratum for semantic theories is observational adequacy (Chomsky 1964): for any string \\(s \\in \\Sigma^*\\), we should predict how acceptable speakers find it in context, and for acceptable strings \\(s, s'\\), we should predict whether speakers judge \\(s'\\) inferable from \\(s\\). Achieving observational adequacy requires mapping vocabulary elements to abstractions that predict judgments parsimoniously.\nThese abstractions may be discrete or continuous, simple or richly structured. Through careful analysis of consistent inference patterns, semanticists have identified powerful generalizations. For instance, examining predicates like love, hate, be surprised, and know, theorists observed they all give rise to inferences about their complement clauses that survive under negation and questioning. This led to positing that they all share a property that predicts systematic inferential behavior across diverse predicates (Kiparsky and Kiparsky 1970; cf. Karttunen 1971).\n\n\nDescriptive Adequacy and Theoretical Depth\nBeyond observational adequacy lies descriptive adequacy: capturing data “in terms of significant generalizations that express underlying regularities in the language” (Chomsky 1964, 63). This drive for deeper explanation motivates the field’s emphasis on parsimony and formal precision.\nThe history of generative syntax illustrates two approaches to achieving descriptive adequacy:\n\nAnalysis-driven: Start with observationally adequate analyses in expressive formalisms, then extract generalizations as constraints\nHypothesis-driven: Begin with constrained formalisms (like CCG or minimalist grammars) and test their empirical coverage\n\nThe hypothesis-driven approach, which PDS adopts for semantics, aims to delineate phenomena through representational constraints. This becomes crucial when developing models that both accord with theoretical assumptions and can be evaluated quantitatively (Baroni 2022; Pavlick 2023).\n\n\nThe Power and Natural Boundaries of Traditional Methods\nThis methodology has yielded profound insights into semantic composition, scope phenomena, discourse dynamics, and the semantics-pragmatics interface more generally. By focusing on carefully constructed examples and native speaker intuitions, theorists have uncovered deep regularities in how meaning is constructed and interpreted.\nYet every methodology has natural boundaries. Traditional semantic methods excel at identifying patterns and building theories but face practical constraints when we ask:\n\nHow well do our generalizations, based on examining 5-10 predicates, extend to the thousands of predicates in the lexicon?\nWhat factors beyond semantic knowledge influence the judgments we observe?\nHow exactly does abstract semantic knowledge produce concrete behavioral responses?"
  },
  {
    "objectID": "background/theory-to-data.html#the-experimental-turn-new-opportunities-for-semantic-theory",
    "href": "background/theory-to-data.html#the-experimental-turn-new-opportunities-for-semantic-theory",
    "title": "The bridge from theory to data",
    "section": "The Experimental Turn: New Opportunities for Semantic Theory",
    "text": "The Experimental Turn: New Opportunities for Semantic Theory\nThe traditional methodology’s success has created a foundation solid enough to support exciting new extensions. Experimental semantics brings the tools of behavioral experimentation to bear on questions about meaning, allowing us to test and refine theoretical insights at unprecedented scale.\n\nScaling Semantic Investigation\nWhere traditional methods might examine a handful of predicates, experimental approaches can investigate entire lexical domains. Extending our example involving the verb love: English has thousands of similar clause-embedding predicates, each potentially varying in its inferential properties. We can now test whether generalizations based on canonical examples extend across these vast lexicons.\nThe MegaAttitude project (White and Rawlins 2016, 2018, 2020; White et al. 2018; An and White 2020; Moon and White 2020; Kane, Gantt, and White 2022) is one example of this approach. This project aims to collect inference judgments for hundreds of predicates across multiple contexts and inference types. This scale reveals patterns that are very difficult to see and evaluate the quality of using traditional methods—subtle distinctions between near-synonyms, unexpected predicate clusters, and systematic variation across semantic domains.\n\n\nTeasing Apart Contributing Factors\nExperimental methods also allow us to investigate the rich array of factors that influence inference judgments:\n\nSemantic knowledge: The core meanings of expressions\nWorld knowledge: Prior beliefs about plausibility\n\nContextual factors: The discourse context and QUD\nIndividual differences: Variation in how speakers interpret expressions\nResponse strategies: How participants use rating scales\n\nRather than viewing these as confounds, we can see them as windows into the cognitive processes underlying semantic interpretation. For instance, Degen and Tonhauser (2021) systematically manipulated world knowledge to show how prior beliefs modulate the strength of factive inferences, revealing the interplay between semantic and pragmatic factors.\n\n\nMaking Linking Hypotheses Explicit\nPerhaps most importantly, experimental approaches force us to make explicit what traditional methods leave implicit: the link between semantic representations and behavioral responses (Jasbi, Waldon, and Degen 2019; Waldon and Degen 2020; Phillips et al. 2021). When we say speakers judge that an inference follows, what cognitive processes produce that judgment? How do abstract semantic representations map onto the responses on some scale?\nThis is not merely a methodological detail—it’s a substantive theoretical question. Different linking hypotheses make different predictions about response patterns, allowing us to test not just our semantic theories but our assumptions about how those theories connect to behavior. Even if our real interest is in characterizing the semantic representations of speakers, we can’t ignore the way those representations map onto their responses in some task."
  },
  {
    "objectID": "background/theory-to-data.html#understanding-gradience-a-taxonomy-of-uncertainty",
    "href": "background/theory-to-data.html#understanding-gradience-a-taxonomy-of-uncertainty",
    "title": "The bridge from theory to data",
    "section": "Understanding Gradience: A Taxonomy of Uncertainty",
    "text": "Understanding Gradience: A Taxonomy of Uncertainty\nOne of the most striking findings from experimental semantics is the pervasiveness of gradience in aggregated measures. While semanticists have long recognized the existence of gradience in some domains–e.g. gradable adjectives–we often assume categorical distinctions in other domains–e.g. factivity. And even where traditional approaches assume categorical distinctions, experimental methods often reveal continuous variation. For the reasons laid out above,understanding this gradience is crucial for developing theories that connect formal semantics to behavioral data.\n\nExamples of Potentially Unexpected Gradience\nThe kinds of distributionally and inferentially defined properties we develop generalizations around are not always readily apparent in large-scale datasets. An example we will look at in-depth in our second case study of the course is that, when attempting to measure veridicality/factivity, we end up with more gradience than we might have expected. We can illustrate this using the MegaAttitude datasets.\nFigure 1 shows veridicality judgments collected by White and Rawlins (2018) as part of their MegaVeridicality dataset.\n\n\n\n\n\n\nFigure 1: Veridicality judgments collected by White and Rawlins (2018) as part of their MegaVeridicality dataset.\n\n\n\nOne thing White and Rawlins (2018) note is the apparent gradience in these measures. This gradience presents a challenge if we want to use these measures to evaluate generalizations about the relationship between two properties. For instance, say we are interested in understanding the relationship betwen factivity and neg(ation)-raising.   A predicate is neg-raising if it gives rise to inferences of the form from (5) to (6):\n\nJo doesn’t think that Mo left.\nJo thinks that Mo didn’t leave.\n\nOne way of deriving a factivity measure from the MegaVeridicality dataset is to take the max along both dimensions, as shown in Figure 2. The idea here is that, it will give rise to veridicality inferences with both positive and negative matrix polarity.\n\n\n\n\n\n\nFigure 2: One way of deriving a factivity measure from the MegaVeridicality dataset.\n\n\n\nNow let’s suppose we’re interested in generalizations about the relationship between two measures. For instance, maybe want to evaluate the relationship between factivity and neg-raising, where we might tend to suspect that factives are not neg-raisers.\nFigure 3 shows a comparison of the measure of neg(ation)-raising from the MegaNegRaising dataset collected by An and White (2020) and the derived factivity measure from the MegaVeridicality dataset collected by White and Rawlins (2018).\n\n\n\n\n\n\nFigure 3: A comparison of the measure of neg(ation)-raising from the MegaNegRaising dataset collected by An and White (2020) and the derived factivity measure from the MegaVeridicality dataset collected by White and Rawlins (2018).\n\n\n\nThe challenge is that, once we move to relating continuous measures, rather than categorical distinctions, we don’t know what the relationship between measures should look like in any particular case. To illustrate, let’s consider another example. Anand and Hacquard (2014) propose that, if a predicate gives rise to inferences about both beliefs and preferences, it backgrounds the belief inferences. To evaluate this hypothesis, we might try to derive a measure of belief inferences and preference inferences and then relate them.\nTo this end, we can use the MegaIntensionality dataset collected by Kane, Gantt, and White (2022). Figure 4 shows a measure of belief inferences and Figure 5 shows a measure of desire inferences.\n\n\n\n\n\n\nFigure 4: A measure of belief inferences from the MegaIntensionality dataset collected by Kane, Gantt, and White (2022).\n\n\n\nAnd Figure 6 shows a comparison of the desire and belief measures.\n\n\n\n\n\n\nFigure 5: A measure of desire inferences from the MegaIntensionality dataset collected by Kane, Gantt, and White (2022).\n\n\n\nFigure 6 show the relationship between these two measures.\n\n\n\n\n\n\nFigure 6: A comparison of the desire and belief measures from the MegaIntensionality dataset collected by Kane, Gantt, and White (2022).\n\n\n\nThere are two main takeaways from this example. First, the generalization proposed by@anand_factivity_2014 is indeed supported by the data. Second, the relationship between these two measures is strikingly different from the relationship we observe between the continuous measures of factivity and neg-raising. We need some way of theorizing about these continuous relationships.\n\n\nTwo Fundamental Types of Uncertainty\nThe framework we’ll explore distinguishes two general types of uncertainty that can produce gradience: resolved (or type-level) uncertainty and unresolved (or token-level) uncertainty, both of which can arise from multiple sources.\nSources of Gradience in Inference Judgments\n├── Resolved (Type-Level) Uncertainty\n│   ├── Ambiguity\n│   │   ├── Lexical (e.g., \"run\" = locomote vs. manage)\n│   │   ├── Syntactic (e.g., attachment ambiguities)\n│   │   └── Semantic (e.g., scope ambiguities)\n│   └── Discourse Status\n│       └── QUD (Question Under Discussion)\n└── Unresolved (Token-Level) Uncertainty\n    ├── Vagueness (e.g., height of a \"tall\" person)\n    ├── World knowledge (e.g., likelihood that facts are true)\n    └── Task effects\n        ├── Response strategies\n        └── Response error\n\n\nResolved Uncertainty: Multiple Discrete Possibilities\nResolved uncertainty arises when speakers must choose among discrete interpretations.  Consider (7):\n\nMy uncle is running the race.\n\nThe verb run is ambiguous—the uncle might be a participant (locomotion) or the organizer (management). Asked “How likely is it that my uncle has good managerial skills?”, participants who interpret run as locomotion might respond near 0.2, while those interpreting it as management might respond near 0.8. The population average might be 0.5, but this reflects a mixture of discrete interpretations, not genuine gradience.\nThis uncertainty is “resolved” because once speakers fix an interpretation, the inference follows determinately. The gradience emerges from averaging across different resolutions, not from uncertainty within any single interpretation.\nA similar phenomenon is observable with anaphora.  Consider (8):\n\nWhenever anyone laughed, the magician scowled and their assistant smirked. They were secretly pleased.\n\nOne is quite likely to infer from (8) that the magician’s assistant is secretly pleased, but not necessarily that the magician is pleased, even though, in principle, it may be that both are, or even that only the magician is. Ultimately, the ambiguity is resolved when we fix the referent.\n\n\nUnresolved Uncertainty: Gradient Within Interpretations\nUnresolved uncertainty contrasts with resolved uncertainty in that it persists even after fixing all ambiguities.  Consider (9):\n\nMy uncle is tall.\n\nEven with no ambiguity about tall’s meaning, speakers remain uncertain whether the uncle exceeds any particular height threshold. This is classic vagueness—the predicate’s application conditions are inherently gradient (Fine 1975; Graff 2000; Christopher Kennedy 2007; Rooij 2011; Sorensen 2023).\nWorld knowledge creates another layer: even knowing someone runs races (locomotion sense), we remain uncertain about their speed, endurance, or likelihood of finishing. These uncertainties appear within individual trials, not just across participants.\n\n\nWhy This Distinction Matters\nThe type of uncertainty has profound implications for semantic theory:\n\nResolved uncertainty suggests discrete semantic representations with probabilistic selection\nUnresolved uncertainty suggests gradient representations or probabilistic reasoning within fixed meanings\n\nDifferent phenomena may involve different uncertainty types. As we’ll see, vagueness seems to give rise to unresolved uncertainty (the conditions of application of tall seem inherently uncertain), while factivity’s gradience is perhaps more puzzling: is it resolved uncertainty from ambiguous predicates, or unresolved uncertainty in projection itself?"
  },
  {
    "objectID": "background/theory-to-data.html#case-studies-testing-semantic-theory-at-scale",
    "href": "background/theory-to-data.html#case-studies-testing-semantic-theory-at-scale",
    "title": "The bridge from theory to data",
    "section": "Case Studies: Testing Semantic Theory at Scale",
    "text": "Case Studies: Testing Semantic Theory at Scale\nTo illustrate how PDS bridges formal semantics and experimental data, we’ll examine two case studies that exemplify different aspects of the framework.\n\nCase Study 1: Vagueness and Gradable Adjectives\nVague predicates provide an ideal starting point because everyone agrees they involve gradient uncertainty. Expressions like tall, expensive, and old lack sharp boundaries—there’s no precise height at which someone becomes tall (Lakoff 1973; Sadock 1977; Lasersohn 1999; Krifka 2007; Solt 2015).\nFormal semantic theories have long recognized this gradience. Degree-based approaches (Klein 1980; Bierwisch 1989; Kamp 1975; Chris Kennedy 1999; Christopher Kennedy and McNally 2005; Christopher Kennedy 2007; Barker 2002) analyze gradable adjectives as expressing relations to contextual thresholds:\n\ntall is true of \\(x\\) if \\(\\ct{height}(x) \\geq d_\\text{tall}\\) (context)\n\nThe threshold \\(d_\\text{tall}\\) varies with context—what counts as tall for a basketball player differs from tall for a child. But even within a fixed context, speakers show gradient judgments about borderline cases.\nThis makes vagueness ideal for demonstrating how PDS works. The framework can: - Maintain the compositional degree-based analysis from formal semantics - Add probability distributions over thresholds to capture gradient judgments - Model how context shifts these distributions - Link threshold distributions to slider scale responses\nRecent experimental work reveals additional complexity. Different adjective types show distinct patterns: - Relative adjectives (tall, wide): Maximum gradience in positive form - Absolute adjectives (clean, dry): Different threshold distributions - Minimum vs. maximum standard: Asymmetric patterns of imprecision\nThese patterns both support and refine formal theories, showing how experimental data can advance theoretical understanding. Recent years have seen partial integration into computational models (Lassiter and Goodman 2013, 2017; Qing and Franke 2014; Kao et al. 2014; Bumford and Rett 2021). We’ll show that PDS allows us to synthesize and compare these different partial approaches.\n\n\nCase Study 2: Factivity and Projection\nWhile vagueness involves expected gradience, factivity presents a puzzle. Traditional theory treats factivity as discrete—predicates either trigger presuppositions or they don’t (Kiparsky and Kiparsky 1970; Karttunen 1971).1 Yet experimental data reveals pervasive gradience.\nA predicate is factive if it triggers inferences about its complement that project through entailment-canceling operators.    Love appears factive because Mo left is inferrable from the standard family of sentences in (10)–(12):\n\nJo loves that Mo left.\nJo doesn’t love that Mo left.\n\nDoes Jo love that Mo left?\n\nBut when White and Rawlins (2018) (discussed above) and Degen and Tonhauser (2022) collected projection judgments at scale, they found continuous variation (Xue and Onea 2011; Smith and Hall 2011; Djärv and Bacovcin 2017 also observe similar patterns). Qualitatively, Degen and Tonhauser (2022) argue that there is no clear line separates factive from non-factive predicates. Mean projection ratings vary continuously from pretend (lowest) to be annoyed (highest).\n\n\n\nAggregate factivity measures from Degen and Tonhauser (2022), showing continuous variation in projection ratings across predicates under questioning.\n\n\nThis gradience poses a theoretical challenge (Simons 2007; Simons et al. 2010, 2017; Tonhauser, Beaver, and Degen 2018).\nKane, Gantt, and White (2022) later showed that this gradience is likely due to task effects. They demonstrate that when one applies a clustering model to these data that accounts for noise due to various factors, many of the standard subclasses of factives pop out. Some of these subclasses–e.g. the cognitive factives, which Karttunen (1971) observes to not always give rise factivity–appear to themselves be associated with non-necessary factive inferences.\nIn this case study, we’ll focus on understanding what gives rise to this gradience. We’ll consider two hypotheses that PDS allows us to state precisely and test against the data collected by Degen and Tonhauser (2021), which uses the same experimental paradigm as Degen and Tonhauser (2022):\nThe Fundamental Discreteness Hypothesis: Factivity remains discrete; gradience reflects: - Multiple predicate senses (factive and non-factive variants) - Structural ambiguity affecting projection (Varlokosta 1994; Giannakidou 1998, 1999, 2009; Roussou 2010; Farudi 2007; Abrusán 2011; Kastner 2015; Ozyildiz 2017) - Contextual variation in whether complements are at-issue (Simons et al. 2017; Roberts and Simons 2024; Qing, Goodman, and Lassiter 2016)\nThe Fundamental Gradience Hypothesis: No discrete factivity property exists. Gradient patterns reflect different degrees to which predicates support complement truth inferences (Tonhauser, Beaver, and Degen 2018).\nPDS allows us to implement both hypotheses formally and test their predictions against fine-grained response distributions—not just means, but entire judgment patterns including multimodality that might indicate mixture distributions. We’ll show how this approach can be applied to judgment data aimed at capturing factivity using various experimental paradigms (Tonhauser 2016; Djärv and Bacovcin 2017; Djärv, Zehr, and Schwarz 2018; White and Rawlins 2018; White et al. 2018; White 2021; Degen and Tonhauser 2021, 2022; Jeong 2021; Kane, Gantt, and White 2022)."
  },
  {
    "objectID": "background/theory-to-data.html#the-need-for-new-frameworks",
    "href": "background/theory-to-data.html#the-need-for-new-frameworks",
    "title": "The bridge from theory to data",
    "section": "The Need for New Frameworks",
    "text": "The Need for New Frameworks\nThese case studies illustrate what we need from a framework connecting formal semantics to experimental data:\nMaintain Compositionality: Theories must derive complex meanings compositionally, preserving insights from decades of formal semantic research. We cannot abandon compositionality just because judgments are gradient.\nModel Uncertainty Explicitly: The framework must represent both types of uncertainty—resolved ambiguities and unresolved gradience—and show how they interact during interpretation.\nMake Linking Hypotheses Precise: We need explicit theories of how semantic representations produce behavioral responses. What cognitive processes intervene between computing a meaning and moving a slider?\nEnable Quantitative Evaluation: Theories must make testable predictions about response distributions, not just average ratings. Different theories should be comparable using standard statistical metrics.\nAs we’ll see in the next section, existing computational approaches like Rational Speech Act (RSA) models attempt to bridge formal semantics with probabilistic reasoning (Frank and Goodman 2012; Goodman and Stuhlmüller 2013). While valuable, these approaches face challenges in maintaining the modularity that makes formal semantic theories powerful. This motivates the development of Probabilistic Dynamic Semantics—a framework that preserves semantic insights while adding the probabilistic tools needed to model gradient behavioral data."
  },
  {
    "objectID": "background/theory-to-data.html#footnotes",
    "href": "background/theory-to-data.html#footnotes",
    "title": "The bridge from theory to data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWe’ll spend a lot of time on Day 4 saying exactly what we mean by discrete here. Karttunen (1971), of course, classically argues that there are predicates that sometimes trigger presuppositions and sometimes don’t. For our purposes, we’ll say that this behavior is discrete in the sense that it’s more like ambiguity than vagueness. That is, we’ll show that uncertainty around factivity displays the hallmarks of resolved uncertainty.↩︎"
  },
  {
    "objectID": "background/rsa.html",
    "href": "background/rsa.html",
    "title": "Setting the stage",
    "section": "",
    "text": "To round out this set of notes, we give a brief overview of the main desiderata which we aim to have PDS satisfy. These are the following:\n\ncompositionality: models of inference should be derived compositionally from semantic grammar fragments.\nmodularity: factors affecting inference judgments should be theorized about independently and combined.\nabstraction: models of meaning and inference should be statable abstractly, without reference to implementation.\n\nWe say a little more about these here, in turn.\n\nCompositionality for models\nWhat could it mean for models of linguistic inference (e.g., as represented in a judgment dataset) to be compositional? Our basic basic strategy is to build the distributional assumptions associated with, e.g., a mixed-effects model, into the semantics. This way, when basic meanings compose, so do these distributional assumptions.\nIndeed, it is reasonable to ask what such distributional assumptions represent. Our answer is uncertainty; specifically, uncertainty about which particular inferences are licensed on any given occasion of language use. Importantly, these kinds of assumptions may be combined when determining the meanings of complex expressions from the meanings of the more basic expressions they contain. Thus while the meaning of a sentence such as Jo laughs might be determined compositionally as\n\\[\n⟦\\textit{jo laughs}⟧ = ⟦\\textit{laughs}⟧ ▹ ⟦\\textit{jo}⟧ = laughs(j)\n\\]\nwithin a traditional semantic framework, PDS, instead, compositionally associates this sentence with a probability distribution.\n\\[⟦\\textit{jo laughs}⟧ = ⟦\\textit{laughs}⟧ ▹ ⟦\\textit{jo}⟧ = \\begin{array}[t]{l}\nj ∼ JoDistr \\\\\nlaugh ∼ LaughDistr \\\\\nReturn (laugh(j))\n\\end{array}\n\\]\nThis distribution is a distribution over truth values: it assigns some probability \\(p\\) to True and \\(1 - p\\) to False. Moreover, it is determined by certain sampling statements (whose interpretations we will formally define tomorrow). Informally, the meaning of Jo takes some distribution over entities, while the meaning of laughs takes some distribution over functions from entities to truth values. These distributions may then be combined to yield a distribution over values gotten by applying such functions applied to such entities; i.e., a distribution over truth values. Remarkably, the distributions over the meanings of such basic expressions end up corresponding exactly, within PDS, to the parameters of some hierarchical Bayesian (e.g., mixed-effects) model which may be used to fit human inference judgment data.\n\n\nModularity\nWe also want theories constructed within PDS to be modular. Specifically, we want the factors affecting inference to be able to be theorized about independently and combined. These include:\n\nlexical and compositional semantics\nworld knowledge\nresponse behavior: how does someone use a testing instrument (e.g., slider scale)?\n\nAn upshot of this feature is that PDS can have different uses. For example, one could swap out a model of response behavior for a model of likely utterances (perhaps, \\(S_{1}\\)).\n\n\nAbstraction\nFinally, we want such theories to display a certain amount of abstraction. That is, we should be able to state models of inference judgment data that:\n\ndescribe probability distributions,\ndo not concern themselves with how distributions are computed.\n\nThere are a couple useful consequences of this feature. First, it allows traditional semantic theories to be plugged into PDS rather seamlessly. Second, it allows separation between theories stated within PDS and model stated within those thoeries. This second consequence allows:\n\nAllows flexibility about implementation.\nAllows the theory to be simpler.\nAllows seamless integration between formal semantics and probabilistic semantics. (More tomorrow!)"
  },
  {
    "objectID": "background/case-studies.html",
    "href": "background/case-studies.html",
    "title": "Two case studies",
    "section": "",
    "text": "\\[\n\\newcommand{\\expr}[3]{\\begin{array}{c}\n#1 \\\\\n\\bbox[lightblue,5px]{#2}\n\\end{array} ⊢ #3}\n\\newcommand{\\ct}[1]{\\bbox[font-size: 0.8em]{\\mathsf{#1}}}\n\\newcommand{\\updct}[1]{\\ct{upd\\_#1}}\n\\newcommand{\\abbr}[1]{\\bbox[transform: scale(0.95)]{\\mathtt{#1}}}\n\\newcommand{\\pure}[1]{\\bbox[border: 1px solid orange]{\\bbox[border: 4px solid transparent]{#1}}}\n\\newcommand{\\return}[1]{\\bbox[border: 1px solid black]{\\bbox[border: 4px solid transparent]{#1}}}\n\\def\\P{\\mathtt{P}}\n\\def\\Q{\\mathtt{Q}}\n\\def\\True{\\ct{T}}\n\\def\\False{\\ct{F}}\n\\def\\ite{\\ct{if\\_then\\_else}}\n\\def\\Do{\\abbr{do}}\n\\]\nTo illustrate how PDS bridges formal semantics and experimental data, we’ll examine two case studies that exemplify different aspects of the framework.",
    "crumbs": [
      "Background",
      "Two case studies"
    ]
  },
  {
    "objectID": "background/case-studies.html#footnotes",
    "href": "background/case-studies.html#footnotes",
    "title": "Two case studies",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWe’ll spend a lot of time on Day 4 saying exactly what we mean by discrete here. Karttunen (1971), of course, classically argues that there are predicates that sometimes trigger presuppositions and sometimes don’t. For our purposes, we’ll say that this behavior is discrete in the sense that it’s more like ambiguity than vagueness. That is, we’ll show that uncertainty around factivity displays the hallmarks of resolved uncertainty.↩︎",
    "crumbs": [
      "Background",
      "Two case studies"
    ]
  },
  {
    "objectID": "adjectives/norming-model.html",
    "href": "adjectives/norming-model.html",
    "title": "Norming model",
    "section": "",
    "text": "\\[\n\\newcommand{\\expr}[3]{\\begin{array}{c}\n#1 \\\\\n\\bbox[lightblue,5px]{#2}\n\\end{array} ⊢ #3}\n\\newcommand{\\ct}[1]{\\bbox[font-size: 0.8em]{\\mathsf{#1}}}\n\\newcommand{\\updct}[1]{\\ct{upd\\_#1}}\n\\newcommand{\\abbr}[1]{\\bbox[transform: scale(0.95)]{\\mathtt{#1}}}\n\\newcommand{\\pure}[1]{\\bbox[border: 1px solid orange]{\\bbox[border: 4px solid transparent]{#1}}}\n\\newcommand{\\return}[1]{\\bbox[border: 1px solid black]{\\bbox[border: 4px solid transparent]{#1}}}\n\\def\\P{\\mathtt{P}}\n\\def\\Q{\\mathtt{Q}}\n\\def\\True{\\ct{T}}\n\\def\\False{\\ct{F}}\n\\def\\ite{\\ct{if\\_then\\_else}}\n\\def\\Do{\\abbr{do}}\n\\]\nOur first model addresses a fundamental question: how do we infer the “shape” of people’s prior beliefs about the degrees that gradable adjectives operate on? The norming study provides a clean test case where participants directly report degrees on scales.\nWe’ll start with a realistic model of the norming data that one might design as a means for analyzing that dataset. What we’ll do is to build up the model block-by-block, explaining each line. Then, we’ll turn to how we might analyze this experiment using PDS and show which components of this model correspond to the PDS kernel model and which ones are extensions of the model by the analyst.",
    "crumbs": [
      "Vagueness and imprecision",
      "Norming model"
    ]
  },
  {
    "objectID": "adjectives/norming-model.html#understanding-the-experimental-setup",
    "href": "adjectives/norming-model.html#understanding-the-experimental-setup",
    "title": "Norming model",
    "section": "Understanding the experimental setup",
    "text": "Understanding the experimental setup\nBefore diving into the Stan code, let’s consider how we’ll represent the norming data, since this is important for understanding how we design Stan code. Here’s a sample of the data:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant\nitem\nitem_number\nadjective\nadjective_number\ncondition\ncondition_number\nscale_type\nscale_type_number\nresponse\n\n\n\n\n1\nclosed_mid\n6\nclosed\n2\nmid\n3\nabsolute\n1\n0.66\n\n\n1\nold_mid\n24\nold\n8\nmid\n3\nrelative\n2\n0.51\n\n\n1\nexpensive_mid\n15\nexpensive\n5\nmid\n3\nrelative\n2\n0.62\n\n\n1\nfull_high\n16\nfull\n6\nhigh\n1\nabsolute\n1\n1\n\n\n1\ndeep_low\n8\ndeep\n3\nlow\n2\nrelative\n2\n0.22\n\n\n\nEach row represents one judgment: - participant: Which person made this judgment (participant 1, 2, etc.) - item: A unique identifier combining adjective and condition (e.g., “tall_high”) - item_number: Numeric ID for the item (used in Stan) - adjective: The gradable adjective being tested - condition: Whether this is a high/mid/low standard context - response: The participant’s slider response (0-1)\nOur simplest model asks: what degree does each item have on its scale, and how do participants map these degrees to slider responses?",
    "crumbs": [
      "Vagueness and imprecision",
      "Norming model"
    ]
  },
  {
    "objectID": "adjectives/norming-model.html#the-structure-of-a-stan-program",
    "href": "adjectives/norming-model.html#the-structure-of-a-stan-program",
    "title": "Norming model",
    "section": "The structure of a Stan program",
    "text": "The structure of a Stan program\nEvery Stan program follows a particular architecture with blocks that appear in a specific order. Each block serves a specific purpose in defining our statistical model. Let’s build up our norming model block by block to understand how Stan works. This structure parallels the modular architecture of PDS itself—each block handles a distinct aspect of the modeling problem.\n\nThe data block\nEvery Stan program begins with a data block that tells Stan what information will be provided from the outside world—our experimental observations. Let’s build this up piece by piece:\ndata {\n  int&lt;lower=1&gt; N_item;        // number of items\n  int&lt;lower=1&gt; N_participant; // number of participants  \n  int&lt;lower=1&gt; N_data;        // number of data points\nThese first lines declare basic counts. The syntax breaks down as:\n\nint: This will be an integer (whole number)\n&lt;lower=1&gt;: This integer must be at least 1 (no negative counts!)\nN_item: The variable name (we’ll use this throughout our program)\n// number of items: A comment explaining what this represents\n\nWhy do we need these constraints? Stan uses them to:\n\nCatch data errors early (if we accidentally pass 0 items, Stan will complain)\nOptimize its algorithms (knowing bounds helps the sampler work efficiently)\n\nNext, we handle a subtle but important issue—boundary responses:\n  int&lt;lower=1&gt; N_0;           // number of 0s\n  int&lt;lower=1&gt; N_1;           // number of 1s\nWhy separate these out? Slider responses of exactly 0 or 1 are “censored”—they might represent even more extreme judgments that the scale can’t capture. We’ll handle these in a second.\nFor the actual response data:\n  vector&lt;lower=0, upper=1&gt;[N_data] y; // response in (0, 1)\nThis declares a vector (like an array) of length N_data, where each element must be between 0 and 1. Notice this is for responses between 0 and 1, not including the boundaries.\nFinally, we need to map responses to items and participants:\n  array[N_data] int&lt;lower=1, upper=N_item&gt; item;        // which item for each response\n  array[N_0] int&lt;lower=1, upper=N_item&gt; item_0;         // which item for each 0\n  array[N_1] int&lt;lower=1, upper=N_item&gt; item_1;         // which item for each 1\n  array[N_data] int&lt;lower=1, upper=N_participant&gt; participant;     \n  array[N_0] int&lt;lower=1, upper=N_participant&gt; participant_0;\n  array[N_1] int&lt;lower=1, upper=N_participant&gt; participant_1;\n}\nThese arrays work like lookup tables. If item[5] = 3, then the 5th response in our data was about item #3. This indexing structure connects our flat data file to the hierarchical structure of our experiment.\nLooking back at our CSV data, when Stan reads it, it will: 1. Count unique items → N_item (e.g., 36 if we have 12 adjectives × 3 conditions) 2. Count unique participants → N_participant 3. Extract all responses between 0 and 1 → y vector 4. Build index arrays mapping each response to its item and participant\n\nThe parameters block: What we want to learn\nAfter declaring our data, we declare the parameters—the unknown quantities we want to infer. This is where semantic theory meets statistical inference:\nparameters {\n  // Fixed effects\n  vector[N_item] mu_guess;\nThis declares a vector of “guesses” (degrees) for each item. Why mu_guess? In statistics, μ (mu) traditionally denotes a mean or central tendency. These means can be understood as representing our best guess, as researchers, about each item’s true degree on its scale—the theoretical degrees that the semantic analysis posits. Crucially, they can also be viewed as representing subjects’ uncertainty about these degrees—what unresolved uncertainty do they maintain when they make these guesses?\nBut people differ! We need random effects to capture individual variation:\n  // Random effects\n  real&lt;lower=0&gt; sigma_epsilon_guess;     // how much people vary\n  vector[N_participant] z_epsilon_guess; // each person's deviation\nThis uses a clever trick called “non-centered parameterization”: - sigma_epsilon_guess: The overall amount of person-to-person variation - z_epsilon_guess: Standardized (z-score) deviations for each person\nWe’ll combine these later to get each person’s actual adjustment. Why not just use vector[N_participant] epsilon_guess directly? This separation often helps Stan’s algorithms converge much faster—a practical consideration that doesn’t affect the semantic theory but matters for implementation.\nNext, measurement noise:\n  real&lt;lower=0,upper=1&gt; sigma_e;  // response variability\nEven if two people agree on an item’s degree, their slider responses might differ slightly. This parameter captures that noise.\nFinally, those boundary responses:\n  // Censored data\n  array[N_0] real&lt;upper=0&gt; y_0;  // true values for observed 0s\n  array[N_1] real&lt;lower=1&gt; y_1;  // true values for observed 1s\n}\nThis is subtle but important. When someone gives a 0 response, their “true” judgment might be -0.1 or -0.5—we just can’t see below 0. These parameters let Stan infer what those true values might have been.\n\n\nThe transformed parameters block: Building predictions\nNow we combine our basic parameters to build what we actually need. This block serves as a bridge between abstract parameters and concrete predictions:\ntransformed parameters {\n  vector[N_participant] epsilon_guess;\n  vector[N_data] guess;\n  vector[N_0] guess_0;\n  vector[N_1] guess_1;\nFirst, we convert those z-scores to actual participant adjustments:\n  // Non-centered parameterization\n  epsilon_guess = sigma_epsilon_guess * z_epsilon_guess;\nIf sigma_epsilon_guess = 0.2 and participant 3 has z_epsilon_guess[3] = 1.5, then participant 3 tends to give responses 0.3 units higher than average.\nNow we can compute predicted responses:\n  for (i in 1:N_data) {\n    guess[i] = mu_guess[item[i]] + epsilon_guess[participant[i]];\nLet’s trace through one prediction: - Response i is about item 5 by participant 3 - item[i] = 5, so we look up mu_guess[5] (say it’s 0.7) - participant[i] = 3, so we add epsilon_guess[3] (say it’s 0.1) - guess[i] = 0.7 + 0.1 = 0.8\nWe repeat this for the boundary responses:\n  for (i in 1:N_0) {\n    guess_0[i] = mu_guess[item_0[i]] + epsilon_guess[participant_0[i]];\n  }\n  \n  for (i in 1:N_1) {\n    guess_1[i] = mu_guess[item_1[i]] + epsilon_guess[participant_1[i]];\n  }\n}\n\n\n\nThe model block\nThe model block is where we specify our statistical assumptions—both our prior beliefs and how the data was generated. This is where most of the action in terms of how PDS relates to data.\nmodel {\n  // Priors on random effects\n  sigma_epsilon_guess ~ exponential(1);\n  z_epsilon_guess ~ std_normal();\nThese priors encode mild assumptions: - exponential(1): We expect person-to-person variation to be moderate (not huge) - std_normal(): By construction, z-scores have a standard normal distribution\nNotice we don’t specify priors for mu_guess—Stan treats this as an implicit uniform prior over the real numbers. Since our responses are bounded, the data will naturally constrain these values.\nNow the likelihood—how data relates to parameters:\n  // Likelihood\n  for (i in 1:N_data) {\n    y[i] ~ normal(guess[i], sigma_e);\n  }\nThis says: each response is drawn from a normal distribution centered at our prediction with standard deviation sigma_e. The ~ symbol means “is distributed as.”\nFor boundary responses, we use the latent values:\n  for (i in 1:N_0) {\n    y_0[i] ~ normal(guess_0[i], sigma_e);\n  }\n  \n  for (i in 1:N_1) {\n    y_1[i] ~ normal(guess_1[i], sigma_e);\n  } \n}\nRemember: we’re inferring y_0 and y_1 as parameters! Stan will sample plausible values that are consistent with both the model and the fact that we observed 0s and 1s.\n\n\nThe generated quantities block\nFinally, we compute quantities that help us understand and evaluate our model:\ngenerated quantities {\n  vector[N_data] ll; // log-likelihoods\n  \n  for (i in 1:N_data) {\n    if (y[i] &gt;= 0 && y[i] &lt;= 1)\n      ll[i] = normal_lpdf(y[i] | guess[i], sigma_e);\n    else\n      ll[i] = negative_infinity();\n  }\n}\nThe log-likelihood tells us how probable each observation is under our model. We’ll use these for model comparison—models that assign higher probability to the actual data are better.\n\n\nThe complete model\nHere’s our complete model with consistent naming:\ndata {\n  int&lt;lower=1&gt; N_item;              // number of items\n  int&lt;lower=1&gt; N_participant;       // number of participants\n  int&lt;lower=1&gt; N_data;              // number of data points in (0, 1)\n  int&lt;lower=1&gt; N_0;                 // number of 0s\n  int&lt;lower=1&gt; N_1;                 // number of 1s\n  vector&lt;lower=0, upper=1&gt;[N_data] y; // response in (0, 1)\n  array[N_data] int&lt;lower=1, upper=N_item&gt; item;\n  array[N_0] int&lt;lower=1, upper=N_item&gt; item_0;\n  array[N_1] int&lt;lower=1, upper=N_item&gt; item_1;\n  array[N_data] int&lt;lower=1, upper=N_participant&gt; participant;\n  array[N_0] int&lt;lower=1, upper=N_participant&gt; participant_0;\n  array[N_1] int&lt;lower=1, upper=N_participant&gt; participant_1;\n}\n\nparameters {\n  vector[N_item] mu_guess;\n  real&lt;lower=0&gt; sigma_epsilon_guess;\n  vector[N_participant] z_epsilon_guess;\n  real&lt;lower=0,upper=1&gt; sigma_e;\n  array[N_0] real&lt;upper=0&gt; y_0;\n  array[N_1] real&lt;lower=1&gt; y_1;\n}\n\ntransformed parameters {\n  vector[N_participant] epsilon_guess = sigma_epsilon_guess * z_epsilon_guess;\n  vector[N_data] guess;\n  vector[N_0] guess_0;\n  vector[N_1] guess_1;\n\n  for (i in 1:N_data) {\n    guess[i] = mu_guess[item[i]] + epsilon_guess[participant[i]];\n  }\n  for (i in 1:N_0) {\n    guess_0[i] = mu_guess[item_0[i]] + epsilon_guess[participant_0[i]];\n  }\n  for (i in 1:N_1) {\n    guess_1[i] = mu_guess[item_1[i]] + epsilon_guess[participant_1[i]];\n  }\n}\n\nmodel {\n  sigma_epsilon_guess ~ exponential(1);\n  z_epsilon_guess ~ std_normal();\n\n  for (i in 1:N_data) {\n    y[i] ~ normal(guess[i], sigma_e);\n  }\n  for (i in 1:N_0) {\n    y_0[i] ~ normal(guess_0[i], sigma_e);\n  }\n  for (i in 1:N_1) {\n    y_1[i] ~ normal(guess_1[i], sigma_e);\n  } \n}\n\ngenerated quantities {\n  vector[N_data] ll;\n  for (i in 1:N_data) {\n    if (y[i] &gt;= 0 && y[i] &lt;= 1)\n      ll[i] = normal_lpdf(y[i] | guess[i], sigma_e);\n    else\n      ll[i] = negative_infinity();\n  }\n}\nThis baseline model treats each item as having an inherent degree along the relevant scale, with participants providing noisy measurements of these degrees. The censoring approach handles the common issue of responses at the boundaries (0 and 1) of the slider scale.",
    "crumbs": [
      "Vagueness and imprecision",
      "Norming model"
    ]
  },
  {
    "objectID": "adjectives/norming-model.html#pds-to-stan",
    "href": "adjectives/norming-model.html#pds-to-stan",
    "title": "Norming model",
    "section": "PDS-to-Stan",
    "text": "PDS-to-Stan\nSo what components of the above model are derived from PDS? To answer this, we need to define our PDS model of the norming task itself. Here it is:\ns1'        = termOf $ getSemantics @Adjectives 1 [\"jo\", \"is\", \"a\", \"soccer player\"]\nq1'        = termOf $ getSemantics @Adjectives 0 [\"how\", \"tall\", \"jo\", \"is\"]\ndiscourse' = ty tau $ assert s1' &gt;&gt;&gt; ask q1'\nscaleNormingExample = asTyped tau (betaDeltaNormal deltaRules . adjectivesRespond scaleNormingPrior) discourse'\nThis code:\n\nAsserts that Jo is a soccer player (establishing context)\nAsks “how tall is Jo?” using the degree-argument version of the adjective\nApplies beta and delta-reduction rules via betaDeltaNormal\nUses scaleNormingPrior to generate prior distributions\nApplies adjectivesRespond to specify the response function\n\nNote the use of certain convenience functions. For example, getSemantics retrieves one of the meanings (in the λ-calculus) for the expression it is given as a string of strings, using the parser implemented at Grammar.Parser. The other functions, termOf, ty, and tau serve as basic plumbing and can be found in the documentation.\n\nWorking through degree questions\nDegree questions like “how tall is Jo?” use a special lexical entry for adjectives that exposes the degree argument. From Grammar.Lexica.SynSem.Adjectives:\ninstance Interpretation Adjectives SynSem where\n  combineR = Convenience.combineR\n  combineL = Convenience.combineL\n  \n  lexica = [lex]\n    where lex = \\case\n      ...\n      \"tall\"          -&gt; [ SynSem {\n                              syn = AP :\\: Deg,\n                              sem = ty tau (purePP (lam d (lam x (lam i (sCon \"(≥)\" @@ (sCon \"height\" @@ i @@ x) @@ d)))))\n                              }\n                           ...\n                         ]\n      ...\n      \"how\"           -&gt;  [ SynSem {\n                              syn =  Qdeg :/: (S :/: AP) :/: (AP :\\: Deg),\n                              sem = ty tau (purePP (lam x (lam y (lam z (y @@ (x @@ z))))))\n                            }\n                            ...\n                          ]\n      ...\n\n\ndelta-rules and semantic computation\nPDS applies delta-rules to simplify these complex λ-terms. As discussed in the implementation section, delta-rules enable different semantic computations while preserving semantic equivalence. The formalism is strongly normalizing and confluent, so the order of rule application doesn’t affect the final result—a crucial property that ensures our semantic theory remains consistent.\nKey delta-rules for adjectives include: - Arithmetic operations: Simplifying comparisons like \\(\\ct{(≥)}\\) when applied to constants - State/index extraction: Rules for \\(\\ct{height}\\), \\(\\ct{d\\_tall}\\), etc. - Beta reduction: Standard λ-calculus reduction\nThese rules transform the complex compositional semantics into simpler forms suitable for compilation to Stan. The transformation preserves the semantic content while making it computationally tractable.\n\n\nWorking through delta-reductions\nHaving seen the PDS code for degree questions, we now trace through how delta-rules transform these complex λ-terms into forms suitable for Stan compilation. delta-rules, as introduced in Lambda.Delta, are partial functions from terms to terms that implement semantic computations.\nFor degree questions like how tall is Jo?, the compositional semantics produces:\n\\[\nλd, i.\\ct{height}(i)(j) ≥ d\n\\]\nWhen \\(\\abbr{respond}\\) comes into the picture, some index \\(i^{\\prime}\\) is sampled from the common ground, and the maximal answer to the question is determined to be:\n\\[\n\\ct{max}(λd.\\ct{height}(i^{\\prime})(j) ≥ d)\n\\] This term undergoes several delta-reductions. First, the indices rule extracts the height value from whatever actual index is sampled from the common ground of the current discourse state. From Lambda.Delta:\nindices :: DeltaRule\nindices = \\case\n  ...\n  Height (UpdHeight p _) -&gt; Just p\n  Height (UpdSocPla _ i) -&gt; Just (Height i)\n  ...\n  _                      -&gt; Nothing\nCalling this height value \\(h\\), this rule yields:\n\\[\n\\ct{max}(λd.h ≥ d)\n\\]\nwhere \\(h\\) represents Jo’s actual height at index \\(i\\). The \\(\\ct{max}\\) operator then extracts this unique value using the following delta-rule:\nmaxes :: DeltaRule\nmaxes = \\case\n   Max (Lam y (GE x (Var y'))) | y' == y -&gt; Just x\n   _                                     -&gt; Nothing  \nThis gives us \\(h\\).\nThis final form directly corresponds to the Stan parameter we need to infer—the degree on the height scale.\n\n\nFrom lambda terms to Stan parameters\nThe challenge is translating abstract semantic computations into Stan’s parameter space. This translation embodies (some of) our linking hypothesis between semantic competence and performance.\n\nDegree extraction becomes parameter inference:\n\n\\(\\ct{max}(λd.\\ct{height}(i)(j) ≥ d)\\) → Infer parameter height_jo\nThe unique degree satisfying the equation becomes a parameter to estimate\n\nFunctions become arrays:\n\n\\(\\ct{height} : \\iota \\to e \\to r\\) → Array height[person]\nFunction application → Array indexing\n\nPropositions become probabilities:\n\nTruth values → Real numbers in [0,1]\nLogical operations → Probabilistic operations\n\nThe monad becomes Stan’s target:\n\nThe \\(\\Do\\)-notation structures sequential computation:\n\\(\\begin{array}[t]{l}\nx ∼ \\ct{normal}(0, 1) \\\\\ny ∼ \\ct{normal}(x, 1) \\\\\n\\pure{y}\n\\end{array}\\)\nThis determines Stan’s log probability\n\n\nThis translation embodies our linking hypothesis: semantic computations generate behavioral data through a noisy measurement process captured by adjectivesRespond.\n\n\n\n\n\n\nPDS Compilation Details\n\n\n\nInput PDS:\ndiscourse' = ty tau $ assert s1' &gt;&gt;&gt; ask q1'\nscaleNormingExample = asTyped tau (betaDeltaNormal deltaRules . adjectivesRespond scaleNormingPrior) discourse'\ndelta-reductions:\n\nParse the answer to “how tall jo is” → \\(\\ct{max}(λd.\\ct{height}(i)(j) ≥ d)\\)\nApply indices rule → \\(\\ct{max}(λd.h ≥ d)\\)\nApply \\(\\ct{max}\\) extraction → \\(h\\)\nMonadic structure maps to Stan parameter inference\n\nKernel output:1\nmodel {\n  // FIXED EFFECTS\n  w ~ normal(0.0, 1.0);\n  \n  // LIKELIHOOD\n  target += normal_lpdf(y | w, sigma);\n}\n\n\n\n\nThe PDS kernel model\nThe PDS system outputs the following kernel model:2\nmodel {\n  // FIXED EFFECTS\n  w ~ normal(0.0, 1.0);\n  \n  // LIKELIHOOD\n  target += normal_lpdf(y | w, sigma);\n}\nThis is the semantic core—it captures the essential degree-based semantics where w represents the degree on the height scale. But reality is complicated: we need random effects, the ability to model censored data, and proper indexing for multiple items and participants. This gap between the kernel model and a full statistical implementation represents ongoing research: how to get from here (PDS output) to here (actual implementation).\nThe full model with analyst augmentations looks like:\nmodel {\n  // PRIORS (analyst-added)\n  sigma_epsilon_guess ~ exponential(1);\n  sigma_e ~ beta(2, 10);\n  \n  // FIXED EFFECTS (PDS kernel)\n  mu_guess ~ normal(0.0, 1.0);\n  \n  // RANDOM EFFECTS (analyst-added)\n  z_epsilon_guess ~ std_normal();\n  \n  // LIKELIHOOD (PDS kernel with modifications)\n  y[i] ~ normal(mu_guess[item[i]] + epsilon_guess[participant[i]], sigma_e);\n}\nLines 6 and 13 (highlighted) show the kernel model from PDS. The unhighlighted portions add statistical machinery for real data: hierarchical priors, random effects, and indexed parameters. The kernel captures the core semantic computation—degrees on scales—while the augmentations handle the realities of experimental data.\nThis baseline model establishes how PDS transforms degree questions into parameter inference. Next, we’ll see how this extends to modeling the vagueness inherent in gradable adjective judgments.",
    "crumbs": [
      "Vagueness and imprecision",
      "Norming model"
    ]
  },
  {
    "objectID": "adjectives/norming-model.html#footnotes",
    "href": "adjectives/norming-model.html#footnotes",
    "title": "Norming model",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nActual PDS output: model { w ~ normal(0.0, 1.0); target += normal_lpdf(y | w, sigma); }↩︎\nActual PDS output: model { w ~ normal(0.0, 1.0); target += normal_lpdf(y | w, sigma); }↩︎",
    "crumbs": [
      "Vagueness and imprecision",
      "Norming model"
    ]
  },
  {
    "objectID": "adjectives/collecting-judgments.html",
    "href": "adjectives/collecting-judgments.html",
    "title": "Collecting inference judgments",
    "section": "",
    "text": "In ongoing work, we are collecting and modeling inference judgments involving gradable adjectives using two experiments: one in which we collect scale-norming judgments, and another in which we collect likelihood judgments.\n\nThe scale-norming task\nIn the scale-norming task, we provide experimental participants prompts like the following:\n\n\n\n\nThe idea here is to assess where people believe objects of different kinds fall on the scale associated with some gradable adjective. This information, which we will attempt to model, is useful because allows us to estimate one of the possible sources of uncertainty which are commonly thought to affect the inferences associated with these kinds of adjectives—that which comes from world knowledge about the entity itself (in particular where it falls on the adjective’s scale). For each adjective we collected judgments for three different entities, thus providing three different contexts preceding the question prompt.\nWe obtained data of this kind for six gradable adjectives that give rise to vagueness in their positive forms, obtaining the following distributions of responses (collapsed across the three contexts for each adjective):\n\n\n\nThe likelihood task\nIn the likelihood task, we provide a different group of participants with prompts like the following:\n\n\n\n\nHere, we use the same three contexts for each adjective that were featured in the scale-norming experiment, but now the question prompt is different: we ask about likelihood that the adjective is true in its positive form in order to gauge how the vague properties of these adjectives influence people’s subjective probabilities about their application. The judgment data we obtained for each adjective are summarized in the following histograms (again, collapsed across contexts):\n\n \n\n\n \n\n\nLikelihood judgment",
    "crumbs": [
      "Vagueness and imprecision",
      "Collecting inference judgments"
    ]
  },
  {
    "objectID": "adjectives/modeling-vagueness.html",
    "href": "adjectives/modeling-vagueness.html",
    "title": "Modeling vagueness",
    "section": "",
    "text": "\\[\n\\newcommand{\\expr}[3]{\\begin{array}{c}\n#1 \\\\\n\\bbox[lightblue,5px]{#2}\n\\end{array} ⊢ #3}\n\\newcommand{\\ct}[1]{\\bbox[font-size: 0.8em]{\\mathsf{#1}}}\n\\newcommand{\\updct}[1]{\\ct{upd\\_#1}}\n\\newcommand{\\abbr}[1]{\\bbox[transform: scale(0.95)]{\\mathtt{#1}}}\n\\newcommand{\\pure}[1]{\\bbox[border: 1px solid orange]{\\bbox[border: 4px solid transparent]{#1}}}\n\\newcommand{\\return}[1]{\\bbox[border: 1px solid black]{\\bbox[border: 4px solid transparent]{#1}}}\n\\def\\P{\\mathtt{P}}\n\\def\\Q{\\mathtt{Q}}\n\\def\\True{\\ct{T}}\n\\def\\False{\\ct{F}}\n\\def\\ite{\\ct{if\\_then\\_else}}\n\\def\\Do{\\abbr{do}}\n\\]\nOur next model addresses how speakers reason about the likelihood that gradable adjectives apply. We’ll start with a realistic model of the vagueness data that one might design as a means for analyzing that dataset. As for the norming model, what we’ll do is to build up the model block-by-block, explaining each line. Then, we’ll turn to how we might analyze this experiment using PDS and show which components of this model correspond to the PDS kernel model and which are extensions by the analyst.",
    "crumbs": [
      "Vagueness and imprecision",
      "Modeling vagueness"
    ]
  },
  {
    "objectID": "adjectives/modeling-vagueness.html#understanding-the-experimental-setup",
    "href": "adjectives/modeling-vagueness.html#understanding-the-experimental-setup",
    "title": "Modeling vagueness",
    "section": "Understanding the experimental setup",
    "text": "Understanding the experimental setup\nBefore diving into the Stan code, let’s consider how we’ll represent the vagueness data. Here’s a sample:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant\nitem\nitem_number\nadjective\nadjective_number\nscale_type\nscale_type_number\ncondition\ncondition_number\nresponse\n\n\n\n\n1\n9_high\n25\nquiet\n9\nabsolute\n1\nhigh\n1\n0.82\n\n\n1\n4_low\n11\nwide\n4\nrelative\n2\nlow\n2\n0.34\n\n\n1\n5_mid\n15\ndeep\n5\nrelative\n2\nmid\n3\n0.77\n\n\n\nEach row represents one likelihood judgment: - participant: Which person made this judgment - item: A unique identifier combining adjective and condition (e.g., “quiet_high”) - adjective: The gradable adjective being tested - condition: Whether this is a high/mid/low standard context - response: The participant’s likelihood judgment (0-1)\nThe key difference from norming: we now distinguish between items (specific adjective-condition pairs) and adjectives themselves. This structure lets us model properties that belong to adjectives (like how context-sensitive they are) separately from properties of specific items—a distinction motivated by the semantic theory.",
    "crumbs": [
      "Vagueness and imprecision",
      "Modeling vagueness"
    ]
  },
  {
    "objectID": "adjectives/modeling-vagueness.html#the-structure-of-the-stan-program",
    "href": "adjectives/modeling-vagueness.html#the-structure-of-the-stan-program",
    "title": "Modeling vagueness",
    "section": "The structure of the Stan program",
    "text": "The structure of the Stan program\nLet’s build up our vagueness model block by block. Since you’re already familiar with Stan’s architecture from the norming model, we’ll focus on what’s different for modeling likelihood judgments.\n\nThe data block\nThe data block for vagueness extends the norming structure with adjective-level information:\ndata {\n  int&lt;lower=1&gt; N_item;              // number of items (adjective × condition)\n  int&lt;lower=1&gt; N_adjective;         // number of unique adjectives\n  int&lt;lower=1&gt; N_participant;       // number of participants\n  int&lt;lower=1&gt; N_data;              // responses in (0,1)\n  int&lt;lower=1&gt; N_0;                 // boundary responses at 0\n  int&lt;lower=1&gt; N_1;                 // boundary responses at 1\n  \n  // Response data\n  vector&lt;lower=0, upper=1&gt;[N_data] y;  // slider responses\n  \n  // NEW: Mapping structure\n  array[N_item] int&lt;lower=1, upper=N_adjective&gt; item_adj;  // which adjective for each item\n  \n  // Indexing arrays for responses\n  array[N_data] int&lt;lower=1, upper=N_item&gt; item;\n  array[N_0] int&lt;lower=1, upper=N_item&gt; item_0;\n  array[N_1] int&lt;lower=1, upper=N_item&gt; item_1;\n  array[N_data] int&lt;lower=1, upper=N_adjective&gt; adjective;\n  array[N_0] int&lt;lower=1, upper=N_adjective&gt; adjective_0;\n  array[N_1] int&lt;lower=1, upper=N_adjective&gt; adjective_1;\n  array[N_data] int&lt;lower=1, upper=N_participant&gt; participant;\n  array[N_0] int&lt;lower=1, upper=N_participant&gt; participant_0;\n  array[N_1] int&lt;lower=1, upper=N_participant&gt; participant_1;\n}\nThe key addition is the adjective-level structure. We need to track both items (e.g., “tall_high”) and adjectives (e.g., “tall”) because our semantic theory posits that context-sensitivity is a property of adjectives, not individual items.\n\n\nThe parameters block\nThe parameters capture both semantic quantities and statistical variation:\nparameters {\n  // SEMANTIC PARAMETERS\n  \n  // Each item has a degree on its scale\n  vector&lt;lower=0, upper=1&gt;[N_item] d;\n  \n  // Global vagueness: how fuzzy are threshold comparisons?\n  real&lt;lower=0&gt; sigma_guess;\n  \n  // Adjective-specific context sensitivity\n  vector&lt;lower=0&gt;[N_adjective] spread;\n\n  // PARTICIPANT VARIATION\n  \n  // How much participants vary in their thresholds\n  real&lt;lower=0&gt; sigma_epsilon_mu_guess;\n  // Each participant's standardized deviation\n  vector[N_participant] z_epsilon_mu_guess;\n  \n  // RESPONSE NOISE\n  real&lt;lower=0, upper=1&gt; sigma_e;\n  \n  // CENSORED DATA\n  array[N_0] real&lt;upper=0&gt; y_0;  // latent values for 0s\n  array[N_1] real&lt;lower=1&gt; y_1;  // latent values for 1s\n}\nThe parameters include:\n\nd: The degree each item has on its scale (e.g., how tall basketball players are)\nsigma_guess: Global vagueness parameter controlling threshold fuzziness\nspread: How much each adjective’s standard shifts across contexts\n\n\n\nThe transformed parameters block\nThis block computes the semantic judgments from our parameters:\ntransformed parameters {\n  // Convert standardized participant effects to natural scale\n  vector[N_participant] epsilon_mu_guess = sigma_epsilon_mu_guess * z_epsilon_mu_guess;\n  \n  // STEP 1: Set up base thresholds for each item\n  vector[N_item] mu_guess0;\n  \n  // This assumes our data has 3 conditions per adjective in order:\n  // high (index 1), low (index 2), mid (index 3)\n  for (i in 0:(N_adjective-1)) {\n    // High condition: positive threshold shift\n    mu_guess0[3 * i + 1] = spread[i + 1];\n    // Low condition: negative threshold shift  \n    mu_guess0[3 * i + 2] = -spread[i + 1];\n    // Mid condition: no shift (baseline)\n    mu_guess0[3 * i + 3] = 0;\n  }\n  \n  // STEP 2: Transform thresholds to probability scale\n  vector&lt;lower=0, upper=1&gt;[N_data] mu_guess;\n  vector&lt;lower=0, upper=1&gt;[N_0] mu_guess_0;\n  vector&lt;lower=0, upper=1&gt;[N_1] mu_guess_1;\n  \n  // STEP 3: Compute predicted responses\n  vector&lt;lower=0, upper=1&gt;[N_data] response_rel;\n  vector&lt;lower=0, upper=1&gt;[N_0] response_rel_0;\n  vector&lt;lower=0, upper=1&gt;[N_1] response_rel_1;\n  \n  // For each response in (0,1)\n  for (i in 1:N_data) {\n    // Add participant adjustment to base threshold\n    real threshold_logit = mu_guess0[item[i]] + epsilon_mu_guess[participant[i]];\n    // Convert from logit scale to probability scale\n    mu_guess[i] = inv_logit(threshold_logit);\n    \n    // KEY SEMANTIC COMPUTATION:\n    // P(adjective applies) = P(degree &gt; threshold)\n    // Using normal CDF for smooth threshold crossing\n    response_rel[i] = 1 - normal_cdf(d[item[i]] | mu_guess[i], sigma_guess);\n  }\n  \n  // Repeat for censored data\n  for (i in 1:N_0) {\n    mu_guess_0[i] = inv_logit(mu_guess0[item_0[i]] + epsilon_mu_guess[participant_0[i]]);\n    response_rel_0[i] = 1 - normal_cdf(d[item_0[i]] | mu_guess_0[i], sigma_guess);\n  }\n  \n  for (i in 1:N_1) {\n    mu_guess_1[i] = inv_logit(mu_guess0[item_1[i]] + epsilon_mu_guess[participant_1[i]]);\n    response_rel_1[i] = 1 - normal_cdf(d[item_1[i]] | mu_guess_1[i], sigma_guess);\n  }\n}\nLine 40 is the crucial one: response_rel[i] = 1 - normal_cdf(d[item[i]] | mu_guess[i], sigma_guess). This implements the likelihood that the adjective applies, using a smooth threshold crossing via the normal CDF. We’ll return to this shortly.\n\n\nThe model block\nThe model block specifies our priors and likelihood:\nmodel {\n  // PRIORS\n  \n  // Vagueness: smaller values = more precise thresholds\n  sigma_guess ~ exponential(5);\n  \n  // Context effects: how much standards shift\n  spread ~ exponential(1);\n  \n  // Participant variation\n  sigma_epsilon_mu_guess ~ exponential(1);\n  z_epsilon_mu_guess ~ std_normal();\n  \n  // LIKELIHOOD\n  \n  // Observed responses are noisy measurements of semantic judgments\n  for (i in 1:N_data) {\n    y[i] ~ normal(response_rel[i], sigma_e);\n  }\n  \n  // Censored responses\n  for (i in 1:N_0) {\n    y_0[i] ~ normal(response_rel_0[i], sigma_e);\n  }\n  \n  for (i in 1:N_1) {\n    y_1[i] ~ normal(response_rel_1[i], sigma_e);\n  }\n}\nThe likelihood connects our semantic computation (response_rel) to the observed data through a measurement model.\n\n\nThe complete model\nHere’s our complete vagueness model—the exact model we’ll use for analysis:\ndata {\n  int&lt;lower=1&gt; N_item;              // number of items\n  int&lt;lower=1&gt; N_adjective;          // number of adjectives\n  int&lt;lower=1&gt; N_participant;          // number of participants\n  int&lt;lower=1&gt; N_data;              // number of data points in (0, 1)\n  int&lt;lower=1&gt; N_0;              // number of 0s\n  int&lt;lower=1&gt; N_1;              // number of 1s\n  vector&lt;lower=0, upper=1&gt;[N_data] y; // response in (0, 1)\n  array[N_item] int&lt;lower=1, upper=N_adjective&gt; item_adj; // map from items to adjectives\n  array[N_data] int&lt;lower=1, upper=N_item&gt; item; // map from data points to items\n  array[N_0] int&lt;lower=1, upper=N_item&gt; item_0;     // map from 0s to items\n  array[N_1] int&lt;lower=1, upper=N_item&gt; item_1;     // map from 1s to items\n  array[N_data] int&lt;lower=1, upper=N_adjective&gt; adjective; // map from data points to adjectives\n  array[N_0] int&lt;lower=1, upper=N_adjective&gt; adjective_0; // map from 0s to adjectives\n  array[N_1] int&lt;lower=1, upper=N_adjective&gt; adjective_1; // map from 1s to adjectives\n  array[N_data] int&lt;lower=1, upper=N_participant&gt; participant; // map from data points to participants\n  array[N_0] int&lt;lower=1, upper=N_participant&gt; participant_0; // map from 0s to participants\n  array[N_1] int&lt;lower=1, upper=N_participant&gt; participant_1; // map from 1s to participants\n}\n\nparameters {\n  // \n  // FIXED EFFECTS\n  // \n  \n  // items:\n  vector&lt;lower=0, upper=1&gt;[N_item] d;\n  real&lt;lower=0&gt; sigma_guess;\n  vector&lt;lower=0&gt;[N_adjective] spread;\n\n  // \n  // RANDOM EFFECTS\n  //\n\n  real&lt;lower=0&gt; sigma_epsilon_mu_guess;        // global scaling factor\n  vector[N_participant] z_epsilon_mu_guess; // by-participant z-scores \n\n  real&lt;lower=0, upper=1&gt; sigma_e;\n\n  //\n  // CENSORED DATA\n  //\n\n  array[N_0] real&lt;upper=0&gt; y_0;\n  array[N_1] real&lt;lower=1&gt; y_1;\n}\n\ntransformed parameters {\n  vector[N_participant] epsilon_mu_guess;\n  vector[N_item] mu_guess0;\n  vector&lt;lower=0, upper=1&gt;[N_data] mu_guess;\n  vector&lt;lower=0, upper=1&gt;[N_0] mu_guess_0;\n  vector&lt;lower=0, upper=1&gt;[N_1] mu_guess_1;\n  vector&lt;lower=0, upper=1&gt;[N_data] response_rel;\n  vector&lt;lower=0, upper=1&gt;[N_0] response_rel_0;\n  vector&lt;lower=0, upper=1&gt;[N_1] response_rel_1;\n\n  // \n  // DEFINITIONS\n  //\n\n  // non-centered parameterization of the participant random intercepts:\n  epsilon_mu_guess = sigma_epsilon_mu_guess * z_epsilon_mu_guess;\n\n  for (i in 0:N_adjective-1) {\n    mu_guess0[3 * i + 1] = spread[i + 1];\n    mu_guess0[3 * i + 2] = -spread[i + 1];\n    mu_guess0[3 * i + 3] = 0;\n  }\n  \n  for (i in 1:N_data) {\n    mu_guess[i] = inv_logit(mu_guess0[item[i]] + epsilon_mu_guess[participant[i]]);\n    response_rel[i] = 1 - normal_cdf(d[item[i]] | mu_guess[i], sigma_guess);\n  }\n\n  for (i in 1:N_0) {\n    mu_guess_0[i] = inv_logit(mu_guess0[item_0[i]] + epsilon_mu_guess[participant_0[i]]);\n    response_rel_0[i] = 1 - normal_cdf(d[item_0[i]] | mu_guess_0[i], sigma_guess);\n  }\n\n  for (i in 1:N_1) {\n    mu_guess_1[i] = inv_logit(mu_guess0[item_1[i]] + epsilon_mu_guess[participant_1[i]]);\n    response_rel_1[i] = 1 - normal_cdf(d[item_1[i]] | mu_guess_1[i], sigma_guess);\n  }\n}\n\nmodel {\n  // \n  // FIXED EFFECTS\n  //\n\n  // scale estimate standard deviations:\n  sigma_guess ~ exponential(5);\n\n  // scale estimate spread\n  spread ~ exponential(1);\n\n  //\n  // RANDOM EFFECTS\n  // \n  \n  // by-participant random intercepts:\n  sigma_epsilon_mu_guess ~ exponential(1);\n  z_epsilon_mu_guess ~ std_normal();\n\n  //\n  // LIKELIHOOD\n  // \n\n  for (i in 1:N_data) {\n    y[i] ~ normal(response_rel[i], sigma_e);\n  }\n  for (i in 1:N_0) {\n    y_0[i] ~ normal(response_rel_0[i], sigma_e);\n  }\n  for (i in 1:N_1) {\n    y_1[i] ~ normal(response_rel_1[i], sigma_e);\n  }\n}\n\ngenerated quantities {\n  vector[N_data] ll;      // log-likelihoods (needed for WAIC/PSIS calculations)\n  \n  // definition:\n  for (i in 1:N_data) {\n    ll[i] = normal_lpdf(\n            y[i] |\n            response_rel[i],\n            sigma_e\n            );\n  }\n}\nThis model for vagueness treats each item as having a degree on its scale, with participants making likelihood judgments based on comparing these degrees to contextually shifted thresholds. The vagueness parameter controls how fuzzy these comparisons are.",
    "crumbs": [
      "Vagueness and imprecision",
      "Modeling vagueness"
    ]
  },
  {
    "objectID": "adjectives/modeling-vagueness.html#pds-to-stan",
    "href": "adjectives/modeling-vagueness.html#pds-to-stan",
    "title": "Modeling vagueness",
    "section": "PDS-to-Stan",
    "text": "PDS-to-Stan\nSo what components of the above model are derived from PDS? To answer this, we need to define our PDS model of the likelihood judgment task itself. Here it is:\n-- From Grammar.Parser and Grammar.Lexica.SynSem.Adjectives\nexpr1 = [\"jo\", \"is\", \"a\", \"soccer\", \"player\"]\nexpr2 = [\"how\", \"likely\", \"that\", \"jo\", \"is\", \"tall\"]\ns1 = getSemantics @Adjectives 0 expr1\nq1 = getSemantics @Adjectives 0 expr2\ndiscourse = ty tau $ assert s1 &gt;&gt;&gt; ask q1\nlikelihoodExample = asTyped tau (betaDeltaNormal deltaRules . adjectivesRespond likelihoodPrior) discourse\nThis code: 1. Asserts that Jo is a soccer player (updated the common ground) 2. Asks “how likely (is it) that Jo is tall?” using the likelihood operator 3. Applies beta and delta reduction rules via betaDeltaNormal 4. Uses likelihoodPrior to generate prior distributions 5. Applies adjectivesRespond to specify the response function\n\nThe PDS implementation: Gradable adjectives\nNow that we understand Stan’s structure and how to translate from PDS, let’s look at how we might capture vagueness. For this, we’ll need to add to our lexicon from the previous section a new denotation for the adjective tall and the wh-word how. We’ll also need an entry for likely.\ninstance Interpretation Adjectives SynSem where\n  combineR = Convenience.combineR\n  combineL = Convenience.combineL\n  \n  lexica = [lex]\n    where lex = \\case\n      ...\n      \"tall\"         -&gt; [ SynSem {\n                            syn = AP :\\: Deg,\n                            sem = ty tau (purePP (lam d (lam x (lam i (sCon \"(≥)\" @@ (sCon \"height\" @@ i @@ x) @@ d)))))\n                            }\n                        , SynSem {\n                            syn = AP,\n                            sem = ty tau (lam s (purePP (lam x (lam i (sCon \"(≥)\" @@ (sCon \"height\" @@ i @@ x) @@ (sCon \"d_tall\" @@ s)))) @@ s))\n                                } ]\n      ...\n      \"likely\"      -&gt;  [ SynSem {\n                            syn = S :\\: Deg :/: S,\n                            sem = ty tau (lam s (purePP (lam p (lam d (lam _' (sCon \"(≥)\" @@ (Pr (let' i (CG s) (Return (p @@ i)))) @@ d)))) @@ s))\n                          } ]\n      \"how\"         -&gt;  [ SynSem {\n                            syn =  Qdeg :/: (S :/: AP) :/: (AP :\\: Deg),\n                            sem = ty tau (purePP (lam x (lam y (lam z (y @@ (x @@ z))))))\n                          }\n                          , SynSem {\n                              syn = Qdeg :/: (S :\\: Deg),\n                              sem = ty tau (purePP (lam x x))\n                            } ]\n      ...\nThe key components of the gradable adjective entries are: - sCon \"height\" represents an \\(e \\rightarrow r\\) function from individuals to their heights - sCon \"d_tall\" represents the contextual threshold from the discourse state - sCon \"(≥)\" represents the comparison relation\nThe lexical entry for tall is related to the one we talked about in the last section but has a few key differences:\n\nSyntactic type: AP indicates this is an adjective phrase (in contrast to the degree-question version AP :\\: Deg)\nSemantic computation: The meaning is a function that:\n\nTakes a discourse state s (containing threshold information)\nReturns a function from entities x to propositions (functions from indices i to truth values)\nThe proposition is true when the entity’s height exceeds the contextual threshold\n\nSemantic components:\n\n\\(\\ct{height}\\): A function from indices to entity-to-degree mappings (type: \\(\\iota \\to e \\to r\\))\n\\(\\ct{d\\_tall}\\): Extracts the threshold for “tall” from the discourse state (type: \\(\\sigma \\to r\\))\n\\(\\ct{(≥)}\\): Comparison operator (type: \\(r \\to r \\to t\\))\n\n\nThis implements degree-based semantics where gradable adjectives denote relations between degrees and contextually determined thresholds. The use of the discourse state for threshold storage captures the context-sensitivity of standards.\nImportant also is the lexical entry for likely:\n\nSyntactic type: S :\\: Deg :/: S indicates this takes a sentence and a degree to give back a sentence (this syntactic type is not completely realistic, but it serves our purposes)\nSemantic computation: The meaning is a function that:\n\nTakes a discourse state s (containing threshold information)\nReturns a function from propositions p to propositions to functions from degrees d to propositions.\nThe resulting proposition is true (at any index) when the probability of the original proposition given the common ground of s exceeds the contextual threshold\n\nSemantic components:\n\n\\(\\ct{Pr}\\): A function from probability distributions over truth values to real numbers that computes the probability of True\n\\(\\ct{CG}\\): Grabs the common ground of the current state—a value of type \\(\\P ι\\)\n\\(\\ct{(≥)}\\): Comparison operator (type: \\(r \\to r \\to t\\))\n\n\n\n\nWorking through likelihood judgments\nHaving seen the PDS code for likelihood judgments, we now trace through how delta rules transform these complex λ-terms into forms suitable for Stan compilation. Delta rules, as introduced in Lambda.Delta, are partial functions from terms to terms that implement semantic computations.\nFor likelihood judgments like how likely (is it) that Jo is tall?, the compositional semantics first produces the embedded proposition Jo is tall:\n(sCon \"(≥)\" @@ (sCon \"height\" @@ i @@ j) @@ (sCon \"d_tall\" @@ s))\n\\[\\ct{(≥)}(\\ct{height}(i)(\\ct{j}))(\\ct{d\\_tall}(s))\\]\nThis undergoes delta reduction using the states rule from Lambda.Delta:\n-- From Lambda.Delta (lines 167-183)\nstates :: DeltaRule\nstates = \\case\n  CG      (UpdCG cg s)   -&gt; Just cg\n  CG      (UpdDTall _ s) -&gt; Just (CG s)\n  DTall   (UpdDTall d _) -&gt; Just d\n  DTall   (UpdCG _ s)    -&gt; Just (DTall s)\n  _                      -&gt; Nothing\nApplied to extract the threshold for “tall”:\n(sCon \"(≥)\" @@ (sCon \"height\" @@ i @@ j) @@ d)\n\\[\\ct{(≥)}(\\ct{height}(i)(\\ct{j}))(d)\\]\nNext, the indices rule extracts Jo’s height:\n-- From Lambda.Delta (lines 106-120)\nindices :: DeltaRule\nindices = \\case\n  Height (UpdHeight p _) -&gt; Just p\n  _                      -&gt; Nothing\nThis yields:\n(sCon \"(≥)\" @@ h @@ d)\n\\[\\ct{(≥)}(h)(d)\\]\nwhere \\(h\\) is Jo’s height.\n\n\nThe probabilities delta rule\nThe comparison stays symbolic—it cannot be reduced without concrete values. This is where the probabilities rule becomes crucial. Here’s the FULL probabilities rule:\n-- From Lambda.Delta (lines 156-164)\nprobabilities :: DeltaRule\nprobabilities = \\case\n  Pr (Return Tr)                                             -&gt; Just 1\n  Pr (Return Fa)                                             -&gt; Just 0\n  Pr (Bern x)                                                -&gt; Just x\n  Pr (Disj x t u)                                            -&gt; Just (x * Pr t + (1 - x) * Pr u)\n  Pr (Let v (Normal x y) (Return (GE t (Var v')))) | v' == v -&gt; Just (NormalCDF x y t)\n  Pr (Let v (Normal x y) (Return (GE (Var v') t))) | v' == v -&gt; Just (NormalCDF (- x) y t)\n  _                                                          -&gt; Nothing\nThis handles the case where we compute the probability that a normally distributed variable exceeds (or is exceeded by) a threshold. When both degrees and thresholds are uncertain, the system computes the appropriate probabilistic comparison.\n\n\nBinding\nThe bind operator allows us to sequence probabilistic computations:\n\\[\n\\begin{array}{l}\nd \\sim \\ct{Normal}(\\mu, \\sigma) \\\\\nh \\sim \\ct{Normal}(\\mu_h, \\sigma_h) \\\\\n\\pure{h \\geq d}\n\\end{array}\n\\]\nWhen we have probabilistic comparisons like height vs threshold, both drawn from distributions, the system can compute the probability that one exceeds the other. If both are normally distributed:\n\n\\(h \\sim \\ct{Normal}(\\mu_h, \\sigma_h)\\) (height)\n\\(d \\sim \\ct{Normal}(\\mu_d, \\sigma_d)\\) (threshold)\n\nThen \\(P(h \\geq d)\\) can be computed using the fact that \\(h - d \\sim \\ct{Normal}(\\mu_h - \\mu_d, \\sqrt{\\sigma_h^2 + \\sigma_d^2})\\).\nThis property allows the compilation to Stan code that efficiently computes these probabilities:\nreal p = normal_cdf((mu_h - mu_d) / sqrt(sigma_h^2 + sigma_d^2) | 0, 1);\ntarget += normal_lpdf(y | p, sigma_response);\n\n\n\n\n\n\nPDS Compilation Details\n\n\n\nInput PDS:\nexpr1 = [\"jo\", \"is\", \"a\", \"soccer\", \"player\"]\nexpr2 = [\"how\", \"likely\", \"that\", \"jo\", \"is\", \"tall\"]\ns1 = getSemantics @Adjectives 0 expr1\nq1 = getSemantics @Adjectives 0 expr2\ndiscourse = ty tau $ assert s1 &gt;&gt;&gt; ask q1\nlikelihoodExample = asTyped tau (betaDeltaNormal deltaRules . adjectivesRespond likelihoodPrior) discourse\nDelta reductions:\n\nParse “jo is tall” (embedded in likelihood) → \\(\\ct{(≥)}(\\ct{height}(i)(\\ct{j}))(\\ct{d\\_tall}(s))\\)\nApply states rule → \\(\\ct{(≥)}(\\ct{height}(i)(\\ct{j}))(d)\\)\nApply indices rule → \\(\\ct{(≥)}(h)(d)\\)\nWrap in Pr operator for likelihood computation\nApply probabilities rule → NormalCDF computation\n\nKernel output:1\nmodel {\n  // FIXED EFFECTS\n  v ~ normal(0.0, 1.0);\n  \n  // LIKELIHOOD\n  target += normal_lpdf(y | 1 - normal_cdf(v, 0.0, 1.0), sigma);\n}\n\n\n\n\nThe PDS kernel model\nThe PDS system outputs the following kernel model:\nmodel {\n  v ~ normal(0.0, 1.0);\n  target += normal_lpdf(y | 1 - normal_cdf(v, 0.0, 1.0), sigma);\n}\nThis kernel captures the likelihood questions effect where v represents Jo’s height and the normal_cdf implements the probability that Jo counts as tall given vagueness in the threshold.\n\n\nThe full model\nBut as we saw for the norming model and in our discussion above, reality is complicated: we need to handle multiple adjectives, context effects, participant variation, and censored data.\nThe full model with analyst augmentations looks like:\nfor (i in 1:N_data) {\n  mu_guess[i] = inv_logit(mu_guess0[item[i]] + epsilon_mu_guess[participant[i]]);\n  response_rel[i] = 1 - normal_cdf(d[item[i]] | mu_guess[i], sigma_guess);  // PDS KERNEL\n}\nThe highlighted line shows the kernel model from PDS. Everything else in our complete model adds the statistical machinery needed for real data:\nmodel {\n  // FIXED EFFECTS (analyst-added structure)\n  sigma_guess ~ exponential(5);      // PDS vagueness parameter\n  spread ~ exponential(1);            // analyst-added context effects\n  \n  // RANDOM EFFECTS (analyst-added)\n  sigma_epsilon_mu_guess ~ exponential(1);\n  z_epsilon_mu_guess ~ std_normal();\n  \n  // LIKELIHOOD\n  for (i in 1:N_data) {\n    y[i] ~ normal(response_rel[i], sigma_e);  // Wraps PDS computation\n  }\n}\nThe transformed parameters computes the semantic judgment (PDS kernel), while the model block adds measurement noise and hierarchical structure.\n\n\nHow the model components map to semantic theory\nLet’s trace through a specific example to see how this model works:\n\nItem degree: Suppose we’re modeling “tall” in the high condition. The parameter d[item[\"tall_high\"]] might be 0.85, representing that basketball players (high condition) have high degrees on the height scale.\nAdjective spread: The parameter spread[\"tall\"] might be 2.0, meaning “tall” is highly context-sensitive—its threshold shifts dramatically between conditions.\nThreshold computation:\n\nBase threshold (logit scale): mu_guess0[\"tall_high\"] = spread[\"tall\"] = 2.0\nParticipant adjustment: Say participant 5 has epsilon_mu_guess[5] = -0.3\nFinal threshold (logit): 2.0 + (-0.3) = 1.7\nFinal threshold (probability): inv_logit(1.7) ≈ 0.85\n\nSemantic judgment (THE PDS KERNEL):\nresponse_rel = 1 - normal_cdf(0.85 | 0.85, sigma_guess)\n\nIf sigma_guess = 0.1 (precise threshold), this gives ≈ 0.5\nIf sigma_guess = 0.3 (vague threshold), the response is more variable\n\nResponse generation: The participant’s actual slider response is a noisy measurement of this semantic judgment, with noise sigma_e.\n\nThis vagueness model extends our baseline by capturing threshold uncertainty through probabilistic computation. The kernel represents the core semantic judgment—comparing degrees to thresholds—while the augmentations handle experimental realities.\ndata {\n  // Basic counts\n  int&lt;lower=1&gt; N_item;         // number of items (adjective × condition)\n  int&lt;lower=1&gt; N_adjective;    // number of unique adjectives\n  int&lt;lower=1&gt; N_participant;  // number of participants\n  int&lt;lower=1&gt; N_data;         // responses in (0,1)\n  int&lt;lower=1&gt; N_0;            // boundary responses at 0\n  int&lt;lower=1&gt; N_1;            // boundary responses at 1\n  \n  // Response data\n  vector&lt;lower=0, upper=1&gt;[N_data] y;  // slider responses\n  \n  // NEW: Mapping structure\n  array[N_item] int&lt;lower=1, upper=N_adjective&gt; item_adj;  // which adjective for each item\n  \n  // Indexing arrays for responses\n  array[N_data] int&lt;lower=1, upper=N_item&gt; item;\n  array[N_0] int&lt;lower=1, upper=N_item&gt; item_0;\n  array[N_1] int&lt;lower=1, upper=N_item&gt; item_1;\n  array[N_data] int&lt;lower=1, upper=N_adjective&gt; adjective;\n  array[N_0] int&lt;lower=1, upper=N_adjective&gt; adjective_0;\n  array[N_1] int&lt;lower=1, upper=N_adjective&gt; adjective_1;\n  array[N_data] int&lt;lower=1, upper=N_participant&gt; participant;\n  array[N_0] int&lt;lower=1, upper=N_participant&gt; participant_0;\n  array[N_1] int&lt;lower=1, upper=N_participant&gt; participant_1;\n}\n\nparameters {\n  // SEMANTIC PARAMETERS\n  \n  // Each item has a degree on its scale\n  vector&lt;lower=0, upper=1&gt;[N_item] d;\n  \n  // Global vagueness: how fuzzy are threshold comparisons?\n  real&lt;lower=0&gt; sigma_guess;\n  \n  // Adjective-specific context sensitivity\n  vector&lt;lower=0&gt;[N_adjective] spread;\n  \n  // PARTICIPANT VARIATION\n  \n  // How much participants vary in their thresholds\n  real&lt;lower=0&gt; sigma_epsilon_mu_guess;\n  // Each participant's standardized deviation\n  vector[N_participant] z_epsilon_mu_guess;\n  \n  // RESPONSE NOISE\n  real&lt;lower=0, upper=1&gt; sigma_e;\n  \n  // CENSORED DATA\n  array[N_0] real&lt;upper=0&gt; y_0;  // latent values for 0s\n  array[N_1] real&lt;lower=1&gt; y_1;  // latent values for 1s\n}\n\ntransformed parameters {\n  // Convert standardized participant effects to natural scale\n  vector[N_participant] epsilon_mu_guess = sigma_epsilon_mu_guess * z_epsilon_mu_guess;\n  \n  // STEP 1: Set up base thresholds for each item\n  vector[N_item] mu_guess0;\n  \n  // This assumes our data has 3 conditions per adjective in order:\n  // high (index 1), low (index 2), mid (index 3)\n  for (i in 0:(N_adjective-1)) {\n    // High condition: positive threshold shift\n    mu_guess0[3 * i + 1] = spread[i + 1];\n    // Low condition: negative threshold shift  \n    mu_guess0[3 * i + 2] = -spread[i + 1];\n    // Mid condition: no shift (baseline)\n    mu_guess0[3 * i + 3] = 0;\n  }\n  \n  // STEP 2: Transform thresholds to probability scale\n  vector&lt;lower=0, upper=1&gt;[N_data] mu_guess;\n  vector&lt;lower=0, upper=1&gt;[N_0] mu_guess_0;\n  vector&lt;lower=0, upper=1&gt;[N_1] mu_guess_1;\n  \n  // STEP 3: Compute predicted responses\n  vector&lt;lower=0, upper=1&gt;[N_data] response_rel;\n  vector&lt;lower=0, upper=1&gt;[N_0] response_rel_0;\n  vector&lt;lower=0, upper=1&gt;[N_1] response_rel_1;\n  \n  // For each response in (0,1)\n  for (i in 1:N_data) {\n    // Add participant adjustment to base threshold\n    real threshold_logit = mu_guess0[item[i]] + epsilon_mu_guess[participant[i]];\n    // Convert from logit scale to probability scale\n    mu_guess[i] = inv_logit(threshold_logit);\n    \n    // KEY SEMANTIC COMPUTATION:\n    // P(adjective applies) = P(degree &gt; threshold)\n    // Using normal CDF for smooth threshold crossing\n    response_rel[i] = 1 - normal_cdf(d[item[i]] | mu_guess[i], sigma_guess);\n  }\n  \n  // Repeat for censored data\n  for (i in 1:N_0) {\n    mu_guess_0[i] = inv_logit(mu_guess0[item_0[i]] + epsilon_mu_guess[participant_0[i]]);\n    response_rel_0[i] = 1 - normal_cdf(d[item_0[i]] | mu_guess_0[i], sigma_guess);\n  }\n  \n  for (i in 1:N_1) {\n    mu_guess_1[i] = inv_logit(mu_guess0[item_1[i]] + epsilon_mu_guess[participant_1[i]]);\n    response_rel_1[i] = 1 - normal_cdf(d[item_1[i]] | mu_guess_1[i], sigma_guess);\n  }\n}\n\nmodel {\n  // PRIORS\n  \n  // Vagueness: smaller values = more precise thresholds\n  sigma_guess ~ exponential(5);\n  \n  // Context effects: how much standards shift\n  spread ~ exponential(1);\n  \n  // Participant variation\n  sigma_epsilon_mu_guess ~ exponential(1);\n  z_epsilon_mu_guess ~ std_normal();\n  \n  // LIKELIHOOD\n  \n  // Observed responses are noisy measurements of semantic judgments\n  for (i in 1:N_data) {\n    y[i] ~ normal(response_rel[i], sigma_e);\n  }\n  \n  // Censored responses\n  for (i in 1:N_0) {\n    y_0[i] ~ normal(response_rel_0[i], sigma_e);\n  }\n  \n  for (i in 1:N_1) {\n    y_1[i] ~ normal(response_rel_1[i], sigma_e);\n  }\n}\n\ngenerated quantities {\n  // Log-likelihood for model comparison\n  vector[N_data] ll;\n  \n  for (i in 1:N_data) {\n    ll[i] = normal_lpdf(y[i] | response_rel[i], sigma_e);\n  }\n  \n  // We could also compute other quantities of interest:\n  // - Average vagueness per adjective\n  // - Predicted responses for new items\n  // - Posterior predictive checks\n}\nThis model for vagueness implements several key components:\n\nVagueness as threshold uncertainty: The sigma_guess parameter captures the participant’s uncertainty about people’s heights\nContext sensitivity: The spread parameters capture how standards shift across contexts\nIndividual differences: Participants can have systematically different thresholds\nMeasurement error: Slider responses are noisy measurements of semantic judgments\n\nThe model thus operationalizes the theoretical distinctions introduced earlier while adding the statistical machinery needed for real experimental data.",
    "crumbs": [
      "Vagueness and imprecision",
      "Modeling vagueness"
    ]
  },
  {
    "objectID": "adjectives/modeling-vagueness.html#footnotes",
    "href": "adjectives/modeling-vagueness.html#footnotes",
    "title": "Modeling vagueness",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nActual PDS output: model { v ~ normal(0.0, 1.0); target += normal_lpdf(y | normal_cdf(v, -0.0, 1.0), sigma); }↩︎",
    "crumbs": [
      "Vagueness and imprecision",
      "Modeling vagueness"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Probabilistic dynamic semantics",
    "section": "",
    "text": "Outline\nThe recent advent of linguistic datasets and their associated statistical models have given rise to two major kinds of questions bearing on linguistic theory and methodology:\n\nHow can semanticists use such datasets? That is, how can the statistical properties of a dataset inform semantic theory directly, and what guiding principles regulate the link between such properties and semantic theory?\nHow should semantic theories themselves be modified so that they may characterize not only informally collected acceptability and inference judgments, but statistical generalizations observed from datasets?\n\nThis course brings the compositional, algebraic view of meaning employed by semanticists into contact with linguistic datasets by introducing and applying the framework of Probabilistic Dynamic Semantics (Grove and White 2024a, 2025, 2024b). PDS seamlessly integrates theories of semantic competence with accounts of linguistic behavior in experimental settings by taking a modular approach: given a dataset involving some semantic phenomenon, and which exhibits certain statistical properties, this course offers an approach to developing both (a) theories of the meanings assigned to the expressions present in the dataset, and (b) linking hypotheses that directly relate these theories to linguistic behavior.\n\n\nExisting probabilistic approaches to meaning\nThe ideas developed in this course build on and respond to existing probabilistic approaches to semantics and pragmatics, including those which use computational modeling to characterize inference (Zeevat and Schmitz 2015; Franke and Jäger 2016; Brasoveanu and Dotlačil 2020; Bernardy et al. 2022; Noah D. Goodman, Tenenbaum, and Contributors 2016). Such models are motivated, in part, by the observation that linguistic inference tends to display substantial gradience, giving rise to quantitative patterns that traditional semantic theory has difficulty capturing. Meanwhile, they often aim to explain Gricean linguistic behavior (Grice 1975) by regarding humans as Bayesian reasoners. Indeed, due to this emphasis on pragmatic principles, much modeling work blurs the semantics/pragmatics distinction, rendering the connection to traditional semantic theory somewhat opaque.\nTo take a paradigm case, models within the Rational Speech Act (RSA) framework consider human interpreters as inferring meanings for an utterance which maximize the utterance’s utility relative to a set of possible alternative utterances (Frank and Goodman 2012; Lassiter 2011; Noah D. Goodman and Stuhlmüller 2013; Noah D. Goodman and Frank 2016; Lassiter and Goodman 2017; Degen 2023). Probabilistic models of linguistic inference, including RSA, tend to encode Bayesian principles of probabilistic update in terms of Bayes’ theorem, which states that the posterior probability of an event given an observation is proportional to the prior probability of the event, multiplied by the likelihood of the observation given the event. RSA models give an explicit operational interpretation to Bayes’ theorem by assuming that prior distributions over inferences encode world knowledge, and that likelihoods represent the utility-maximizing behavior of a pragmatic speaker.\nDespite their success in modeling a wide variety of semantic and pragmatic phenomena, probabilistic models of linguistic data remain largely divorced from semantic and pragmatic practice, both in theory and in implementation. RSA models, for example, regard the semantic interpretations which humans pragmatically reason about as being provided by a literal listener that determines a distribution over inferences, given an utterance (Degen 2023). But aside from the constraint that the literal listener’s posterior distribution is proportional to its prior distribution (i.e., that it acts as a filter), the semantic components of RSA models are generally designed by researchers on an ad hoc basis: on the one hand, the space (I) of possible inferences must be decided by individual researchers in a way that depends on the task being modeled; on the other hand, the relation (⟦·⟧) between utterances and inferences is often assumed without a justified connection to any semantic theory using, e.g., an explicit grammar fragment in the style of Montague (1973).\n\n\nPDS as a bridge between probabilistic models and semantic theory\nGiven this background, this course introduces a novel approach to probabilistic meaning which integrates traditional Montague semantics, as well as ideas in compositional dynamic semantics, with probabilistic computational models in a completely seamless fashion. The theoretical framework and methodology we introduce retain the beneficial features of both kinds of approach to meaning: PDS may be used to construct probabilistic models of human inference data, and it is in principle compatible with existing probabilistic modeling paradigms such as RSA; meanwhile, it seamlessly connects probabilistic models to compositional dynamic semantics in the Montagovian tradition by providing a setting to write full-fledged grammar fragments.\nPDS additionally provides a theory of dynamic discourse update, integrating aspects of discourse such as the common ground, the question under discussion (Ginzburg 1996; Roberts 2012; Farkas and Bruce 2010), and uncertainty about lexical meaning. Crucially, given a semantic theory of some discourse phenomenon couched with PDS, one may obtain a probabilistic model of some linguistic dataset, given a particular response function (Grove and White 2024a, 2025, 2024b). We introduce PDS in the context empirical datasets studying factivity, gradable adjectives, and the question under discussion.\n\n\n\n\n\n\n\nReferences\n\nBernardy, Jean-Philippe, Rasmus Blanck, Stergios Chatzikyriakidis, and Aleksandre Maskharashvili. 2022. “Bayesian Natural Language Semantics and Pragmatics.” In Probabilistic Approaches to Linguistic Theory, edited by Jean-Philippe Bernardy, Rasmus Blanck, Stergios Chatzikyriakidis, Shalom Lappin, and Aleksandre Maskharashvili. CSLI Publications.\n\n\nBrasoveanu, Adrian, and Jakub Dotlačil. 2020. Computational Cognitive Modeling and Linguistic Theory. Vol. 6. Language, Cognition, and Mind. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-030-31846-8.\n\n\nDegen, Judith. 2023. “The Rational Speech Act Framework.” Annual Review of Linguistics 9 (Volume 9, 2023): 519–40. https://doi.org/10.1146/annurev-linguistics-031220-010811.\n\n\nFarkas, Donka F., and Kim B. Bruce. 2010. “On Reacting to Assertions and Polar Questions.” Journal of Semantics 27 (1): 81–118. https://doi.org/10.1093/jos/ffp010.\n\n\nFrank, Michael C., and Noah D. Goodman. 2012. “Predicting Pragmatic Reasoning in Language Games.” Science 336 (6084): 998–98. https://doi.org/10.1126/science.1218633.\n\n\nFranke, Michael, and Gerhard Jäger. 2016. “Probabilistic Pragmatics, or Why Bayes’ Rule Is Probably Important for Pragmatics.” Zeitschrift Für Sprachwissenschaft 35 (1): 3–44. https://doi.org/10.1515/zfs-2016-0002.\n\n\nGinzburg, Jonathan. 1996. “Dynamics and the Semantics of Dialogue.” In Logic, Language, and Computation, edited by Jerry Seligman and Dag Westerståhl, 1:221–37. Stanford: CSLI Publications.\n\n\nGoodman, Noah D., and Michael C. Frank. 2016. “Pragmatic Language Interpretation as Probabilistic Inference.” Trends in Cognitive Sciences 20 (11): 818–29. https://doi.org/10.1016/j.tics.2016.08.005.\n\n\nGoodman, Noah D., and Andreas Stuhlmüller. 2013. “Knowledge and Implicature: Modeling Language Understanding as Social Cognition.” Topics in Cognitive Science 5 (1): 173–84. https://doi.org/10.1111/tops.12007.\n\n\nGoodman, Noah D, Joshua B. Tenenbaum, and The ProbMods Contributors. 2016. “Probabilistic Models of Cognition.” http://probmods.org/v2.\n\n\nGrice, H. Paul. 1975. “Logic and Conversation.” In Syntax and Semantics, edited by Peter Cole and Jerry L. Morgan, 3, Speech Acts:41–58. New York: Academic Press.\n\n\nGrove, Julian, and Aaron Steven White. 2024a. “Factivity, Presupposition Projection, and the Role of Discrete Knowlege in Gradient Inference Judgments.” LingBuzz. https://ling.auf.net/lingbuzz/007450.\n\n\n———. 2024b. “Probabilistic Dynamic Semantics.” University of Rochester. https://ling.auf.net/lingbuzz/008478.\n\n\n———. 2025. “Modeling the Prompt in Inference Judgment Tasks.” Experiments in Linguistic Meaning 3 (January): 176–87. https://doi.org/10.3765/elm.3.5857.\n\n\nLassiter, Daniel. 2011. “Vagueness as Probabilistic Linguistic Knowledge.” In Vagueness in Communication, edited by Rick Nouwen, Robert van Rooij, Uli Sauerland, and Hans-Christian Schmitz, 127–50. Lecture Notes in Computer Science. Berlin, Heidelberg: Springer. https://doi.org/10.1007/978-3-642-18446-8_8.\n\n\nLassiter, Daniel, and Noah D. Goodman. 2017. “Adjectival Vagueness in a Bayesian Model of Interpretation.” Synthese 194 (10): 3801–36. https://doi.org/10.1007/s11229-015-0786-1.\n\n\nMontague, Richard. 1973. “The Proper Treatment of Quantification in Ordinary English.” In Approaches to Natural Language: Proceedings of the 1970 Stanford Workshop on Grammar and Semantics, edited by K. J. J. Hintikka, J. M. E. Moravcsik, and P. Suppes, 221–42. Synthese Library. Dordrecht: Springer Netherlands. https://doi.org/10.1007/978-94-010-2506-5_10.\n\n\nRoberts, Craige. 2012. “Information Structure: Towards an Integrated Formal Theory of Pragmatics.” Semantics and Pragmatics 5 (December): 6:1–69. https://doi.org/10.3765/sp.5.6.\n\n\nZeevat, Henk, and Hans-Christian Schmitz, eds. 2015. Bayesian Natural Language Semantics and Pragmatics. Vol. 2. Language, Cognition, and Mind. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-17064-0.",
    "crumbs": [
      "Probabilistic dynamic semantics"
    ]
  },
  {
    "objectID": "factivity/index.html",
    "href": "factivity/index.html",
    "title": "Notes",
    "section": "",
    "text": "Note\n\n\n\nThese notes will become available on June 27.",
    "crumbs": [
      "Factivity inferences",
      "Notes"
    ]
  },
  {
    "objectID": "adjectives/compiling-kernel-models.html",
    "href": "adjectives/compiling-kernel-models.html",
    "title": "Compiling kernel models",
    "section": "",
    "text": "\\[\n\\newcommand{\\expr}[3]{\\begin{array}{c}\n#1 \\\\\n\\bbox[lightblue,5px]{#2}\n\\end{array} ⊢ #3}\n\\newcommand{\\ct}[1]{\\bbox[font-size: 0.8em]{\\mathsf{#1}}}\n\\newcommand{\\updct}[1]{\\ct{upd\\_#1}}\n\\newcommand{\\abbr}[1]{\\bbox[transform: scale(0.95)]{\\mathtt{#1}}}\n\\newcommand{\\pure}[1]{\\bbox[border: 1px solid orange]{\\bbox[border: 4px solid transparent]{#1}}}\n\\newcommand{\\return}[1]{\\bbox[border: 1px solid black]{\\bbox[border: 4px solid transparent]{#1}}}\n\\def\\P{\\mathtt{P}}\n\\def\\Q{\\mathtt{Q}}\n\\def\\True{\\ct{T}}\n\\def\\False{\\ct{F}}\n\\def\\ite{\\ct{if\\_then\\_else}}\n\\def\\Do{\\abbr{do}}\n\\]\nHaving seen how gradable adjectives are represented in PDS’s compositional semantics, we now turn to the practical challenge of implementing statistical models that test these semantic theories against experimental data. The translation from abstract semantic theory to concrete statistical models requires careful attention to how theoretical commitments manifest as computational procedures. This section demonstrates this translation through two models: the first is a relatively simple model of the norming data we just discussed; the second is a model of the gradable adjectives data.",
    "crumbs": [
      "Vagueness and imprecision",
      "Compiling kernel models"
    ]
  },
  {
    "objectID": "adjectives/compiling-kernel-models.html#stan-as-an-intermediary",
    "href": "adjectives/compiling-kernel-models.html#stan-as-an-intermediary",
    "title": "Compiling kernel models",
    "section": "Stan as an intermediary",
    "text": "Stan as an intermediary\nThe translation from abstract semantic analyses to concrete statistical models requires an intermediate representation—basically, a language that relates the abstract probabilistic models we state in PDS to the data we want to fit these models to. Stan has emerged as the de facto standard for this role in computational semantics and psycholinguistics (Bürkner 2017; Stan Development Team 2024). We are going to use it for our implementations, but any language that allows us to express sets of interrelated distributional assumptions would do.\nStan is a probabilistic programming language designed for statistical inference. Unlike general-purpose programming languages, Stan is specialized for stating distributional assumptions that can then be translated to a C++ backend that performs statistical inference–usually, using a form of Markov Chain Monte Carlo (MCMC). Stan allows for imperative constructs, but for our purposes, we can think of it as declaring the structure of a probability model in the sense that we don’t every write code that specifies how to fit the model to the data.\nThis approach aligns well with our goals: just as formal semantics declares some representation of the semantic content rather than how that representation is used in verifying truth or drawing inferences, Stan declares probabilistic relationships rather than sampling algorithms. The parallel is not accidental—both frameworks separate the what (semantic content, distributional assumptions) from the how (verification or proof, inference algorithms). Said another way, our translation to Stan allows us to retain modularity: it provides an interface that hides the nasty details of actually fitting the models from our semantic theory.",
    "crumbs": [
      "Vagueness and imprecision",
      "Compiling kernel models"
    ]
  },
  {
    "objectID": "adjectives/compiling-kernel-models.html#kernel-models",
    "href": "adjectives/compiling-kernel-models.html#kernel-models",
    "title": "Compiling kernel models",
    "section": "Kernel models",
    "text": "Kernel models\nBefore diving into the implementation details, it’s important to understand what PDS produces and how it relates to the full statistical models we’ll develop. PDS outputs what we term a kernel model—the semantic core that corresponds directly to the lexical and compositional semantics. This kernel can in principle be augmented with other components: random effects, hierarchical priors, and other statistical machinery, but the current implementation focuses on producing just the semantic kernel.\nThis distinction is crucial: PDS automates the translation from compositional semantics to the core statistical model, while leaving room for analysts to add domain-specific statistical structure. We take this to be a useful separation of concerns because it allows the semantic theory to remain agnostic about aspects of the statistical model that are have nothing to do with the semantic theory.\nWith this understanding of kernel models and Stan’s role, we can now examine specific implementations. We’ll start with the simplest case—inferring degrees from norming data—before building up to a model of vagueness. We’ll be showing prettified versions of what the system actually outputs. For every model block, we’ll also provide the current system output in a footnote, in addition to the prettified version.",
    "crumbs": [
      "Vagueness and imprecision",
      "Compiling kernel models"
    ]
  },
  {
    "objectID": "adjectives/future-directions.html",
    "href": "adjectives/future-directions.html",
    "title": "Future directions",
    "section": "",
    "text": "\\[\n\\newcommand{\\expr}[3]{\\begin{array}{c}\n#1 \\\\\n\\bbox[lightblue,5px]{#2}\n\\end{array} ⊢ #3}\n\\newcommand{\\ct}[1]{\\bbox[font-size: 0.8em]{\\mathsf{#1}}}\n\\newcommand{\\updct}[1]{\\ct{upd\\_#1}}\n\\newcommand{\\abbr}[1]{\\bbox[transform: scale(0.95)]{\\mathtt{#1}}}\n\\newcommand{\\pure}[1]{\\bbox[border: 1px solid orange]{\\bbox[border: 4px solid transparent]{#1}}}\n\\newcommand{\\return}[1]{\\bbox[border: 1px solid black]{\\bbox[border: 4px solid transparent]{#1}}}\n\\def\\P{\\mathtt{P}}\n\\def\\Q{\\mathtt{Q}}\n\\def\\True{\\ct{T}}\n\\def\\False{\\ct{F}}\n\\def\\ite{\\ct{if\\_then\\_else}}\n\\def\\Do{\\abbr{do}}\n\\]\n\nThrough our exploration of gradable adjectives, we’ve seen how PDS transforms semantic theory into testable statistical models. From simple degree inference through complex mixture models, each step has revealed how delta rules bridge abstract semantics and empirical data.\nThis work opens several avenues for development:\n\nAutomated augmentation: Currently, analysts manually add statistical structure to kernel models. Future versions of PDS could automate common augmentations like random effects and hierarchical priors.\nFormally verified compilation: Delta rules could be accompanied by formal proofs in Agda or Coq, ensuring soundness while enabling generic transformations.\nRicher kernel models: Extending PDS to output mixture models, censoring mechanisms, and other statistical structures that directly encode semantic theories.\nCommunity contributions: The modular design of PDS invites researchers to contribute new lexical entries, delta rules, and compilation strategies.\n\nBuilding on the PDS framework introduced in previous sections, we’ve seen how computational tools can bridge the gap between formal semantic theory and experimental data. These models provide the foundation for understanding factivity—where gradience poses even deeper theoretical puzzles that we’ll explore in the next section."
  },
  {
    "objectID": "adjectives/adjectives-intro.html",
    "href": "adjectives/adjectives-intro.html",
    "title": "Vague gradable adjectives",
    "section": "",
    "text": "Adjectives such as tall, wide, expensive, and happy are often considered to be vague. The example in (1), taken from Kennedy (2007), appears to have somewhat uncertain truth conditions.\n\nThe coffee in Rome is expensive.\n\nIt is true if the cost of coffee in Rome is as great as some salient threshold for costs—something associated with the adjective expensive—but this threshold intuitively remains uncertain when attempting to evaluate whether or not (1) might be true. It may range somewhere from 2 euros to 4 euros, for example, but an exact value appears very difficult to pin down.\nA hallmark property of vague adjectives like expensive is that they exhibit certain unique inference patterns, such as borderline cases (Kennedy 2007). For example while the Mud Blend ($1.50/lb), might be considered not expensive, and Organic Kona ($20/lb) might be considered expensive, it’s harder to say which category the Swell Start ($9.25/lb) falls into.\nPerhaps most famously, vague adjectives—and vague predicates in general—give rise to sorites paradoxes. Such paradoxes arise from considering arguments (known as sorites arguments) that go as follows.\n\nPremise 1: A $10 cup of coffee is expensive.\nPremise 2: If an expensive cup of coffee were 1 cent cheaper, it would still be expensive.\nConclusion: Therefore, a free cup of coffee is expensive!\n\nThese kinds of inference profiles are notoriously tricky to analyze in terms of the classical notion of truth conditions. Specifically, borderline cases provide instances in which the property denoted by the adjective seems neither to apply nor not to apply to certain entities; but this conflicts with the theoretical requirement that truth conditions provide a definition when a sentence is true—they should bifurcate the space of possible situations into those in which it is true and those in which it is false. Such inference patterns thus at least suggest that traditional model theoretic tools might not be sufficient for studying these kinds of adjectives.\nMeanwhile, the sorites paradox is troublesome because it appears to contravene the assumption that inferences should be closed under implication. For example, if we have the following two premises:\n\n$10 is expensive implies $9.99 is expensive\n$9.99 is expensive implies $9.98 is expensive\n\nWe should be able to draw the following conclusion:\n\n$10.00 is expensive implies $9.98 expensive\n\nAnd so on, such that we should eventually be able to conclude that $10.00 being expensive (true) implies that $0.00 is expensive (false).\n\n\n\n\n\n\nReferences\n\nKennedy, Christopher. 2007. “Vagueness and Grammar: The Semantics of Relative and Absolute Gradable Adjectives.” Linguistics and Philosophy 30 (1): 1–45. https://doi.org/10.1007/s10988-006-9008-0.",
    "crumbs": [
      "Vagueness and imprecision",
      "Vague gradable adjectives"
    ]
  },
  {
    "objectID": "background/new-frameworks.html",
    "href": "background/new-frameworks.html",
    "title": "The need for new frameworks",
    "section": "",
    "text": "\\[\n\\newcommand{\\expr}[3]{\\begin{array}{c}\n#1 \\\\\n\\bbox[lightblue,5px]{#2}\n\\end{array} ⊢ #3}\n\\newcommand{\\ct}[1]{\\bbox[font-size: 0.8em]{\\mathsf{#1}}}\n\\newcommand{\\updct}[1]{\\ct{upd\\_#1}}\n\\newcommand{\\abbr}[1]{\\bbox[transform: scale(0.95)]{\\mathtt{#1}}}\n\\newcommand{\\pure}[1]{\\bbox[border: 1px solid orange]{\\bbox[border: 4px solid transparent]{#1}}}\n\\newcommand{\\return}[1]{\\bbox[border: 1px solid black]{\\bbox[border: 4px solid transparent]{#1}}}\n\\def\\P{\\mathtt{P}}\n\\def\\Q{\\mathtt{Q}}\n\\def\\True{\\ct{T}}\n\\def\\False{\\ct{F}}\n\\def\\ite{\\ct{if\\_then\\_else}}\n\\def\\Do{\\abbr{do}}\n\\]\n\nThese case studies illustrate what we need from a framework connecting formal semantics to experimental data:\nMaintain Compositionality: Theories must derive complex meanings compositionally, preserving insights from decades of formal semantic research. We cannot abandon compositionality just because judgments are gradient.\nModel Uncertainty Explicitly: The framework must represent both types of uncertainty—resolved ambiguities and unresolved gradience—and show how they interact during interpretation.\nMake Linking Hypotheses Precise: We need explicit theories of how semantic representations produce behavioral responses. What cognitive processes intervene between computing a meaning and moving a slider?\nEnable Quantitative Evaluation: Theories must make testable predictions about response distributions, not just average ratings. Different theories should be comparable using standard statistical metrics.\nAs we’ll see in the next section, existing computational approaches like Rational Speech Act (RSA) models attempt to bridge formal semantics with probabilistic reasoning (Frank and Goodman 2012; Goodman and Stuhlmüller 2013). While valuable, these approaches face challenges in maintaining the modularity that makes formal semantic theories powerful. This motivates the development of Probabilistic Dynamic Semantics—a framework that preserves semantic insights while adding the probabilistic tools needed to model gradient behavioral data.\n\n\n\n\n\n\nReferences\n\nFrank, Michael C., and Noah D. Goodman. 2012. “Predicting Pragmatic Reasoning in Language Games.” Science 336 (6084): 998–98. https://doi.org/10.1126/science.1218633.\n\n\nGoodman, Noah D., and Andreas Stuhlmüller. 2013. “Knowledge and Implicature: Modeling Language Understanding as Social Cognition.” Topics in Cognitive Science 5 (1): 173–84. https://doi.org/10.1111/tops.12007.",
    "crumbs": [
      "Background",
      "The need for new frameworks"
    ]
  },
  {
    "objectID": "background/theoretically-oriented-approach.html",
    "href": "background/theoretically-oriented-approach.html",
    "title": "Rational Speech Act models",
    "section": "",
    "text": "Rational speech act (RSA) models are a very popular approach to modeling pragmatic inference that integrates ideas from formal semantics into mathematically explicit models of Gricean reasoning (Grice 1975). Crucially, these models aim for a certain kind of modularity: they allow one to provide separate accounts of the literal semantics of expressions, on the one hand, and the inferences that people make when they encounter utterances of these expressions, on the other. They achieve this kind of modularity, essentially, by allowing one to state a theory of literal meaning and then to use a systematic recipe for turning it into a theory of pragmatic inference.\nHere we describe what is sometimes called vanilla RSA. Vanilla RSA is RSA more or less as it was originally formulated Frank and Goodman (2012) and Goodman and Stuhlmüller (2013) (see Degen (2023) for a recent comprehensive overview of the RSA literature). The basic idea is that there are two sets of models, listener models, and speaker models, which are kind of mirror images of each other.\n\nListener models\nIn particular, any given listener model \\(L_{i}\\) characterizes a probability distribution over possible worlds \\(w\\), given some utterance \\(u\\). \\[\n\\begin{aligned}\nP_{L_0}(w | u) &= \\frac{\\begin{cases}\nP_{L_0}(w) & ⟦u⟧^w = \\mathtt{T} \\\\\n0 & ⟦u⟧^w = \\mathtt{F}\n\\end{cases}}{∑_{w^\\prime}\\begin{cases}\nP_{L_0}(w^\\prime) & ⟦u⟧^{w^\\prime} = \\mathtt{T} \\\\\n0 & ⟦u⟧^{w^\\prime} = \\mathtt{F}\n\\end{cases}} \\\\[2mm]\nP_{L_i}(w | u) &= \\frac{P_{L_i}(u | w) * P_{L_i}(w)}{∑_{w^\\prime}P_{L_i}(u | w^\\prime) *\nP_{L_i}(w^\\prime)}\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,(i &gt; 0) \\\\[2mm]\n& = \\frac{P_{L_i}(u | w) * P_{L_i}(w)}{P_{L_i}(u)}\n\\end{aligned}\n\\] In words, \\(P_{L_0}(w | u)\\) depends only on whether or not \\(u\\) and \\(w\\) are compatible. It thus acts as a filter, eliminating possible worlds from the prior in which the utterance \\(u\\) is false.\nThe definition of \\(P_{L_i}(w | u)\\) for \\(i &gt; 0\\) uses Bayes’ theorem. To state that this definition uses Bayes’ theorem is kind of a tautology when viewed simply as a mathematical description. Thus what this statement really means is something more operational: RSA models make distinguishing choices about the definitions of \\(P_{L_i}(u | w)\\) and \\(P_{L_i}(w)\\), and it is these latter choices which are used, in turn, to compute \\(P_{L_i}(w | u)\\).\nIn general, the choice \\(P_{L_i}(w)\\) of a prior distribution over \\(w\\) is made once and for all, regardless of the particular model, so we can just call this choice \\(P(w)\\). \\(P(w)\\) can be seen to give a representation of the context set in a given discourse; that is, the distribution over possible worlds known in common among the interlocutors, before anything is uttered.\n\n\nSpeaker models\nThe definition of \\(P_{L_i}(u | w)\\), on the other hand, is chosen to reflect the model \\(S_i\\) of the speaker, which brings us to the other set of models. Thus \\(P_{L_i}(u | w) = P_{S_i}(u | w)\\), where \\[\\begin{aligned}\nP_{S_i}(u | w) &= \\frac{e^{α * 𝕌_{S_i}(u; w)}}{∑_{u^\\prime}e^{α *\n𝕌_{S_i}(u^\\prime; w)}}\n\\end{aligned}\\] \\(𝕌_{S_i}(u; w)\\) is the utility \\(S_i\\) assigns to the utterance \\(u\\), given its intention to communicate the world \\(w\\). Utility for \\(S_i\\) is typically defined as \\[𝕌_{S_i}(u; w) = ln(P_{L_{i-1}}(w | u)) - C(u)\\] that is, the natural log of the probability that \\(L_{i-1}\\) assigns to \\(w\\) (given \\(u\\)), minus \\(u\\)’s cost (\\(C(u)\\)). \\(α\\) is known as the temperature (or the rationality parameter) associated with \\(S_i\\). When \\(α = 0\\), \\(S_i\\) chooses utterances randomly (from a uniform distribution), without attending to their utility in communicating \\(w\\). When \\(α\\) tends toward \\(∞\\), \\(S_i\\) becomes more and more deterministic in its choice of utterance, assigning more and more probability mass to the utterance that maximizes utility in communicating \\(w\\). A little more formally, \\[\\lim_{α → ∞}\\frac{e^{α * 𝕌_{S_i}(u; w)}}{∑_{u^\\prime}e^{α *\n𝕌_{S_i}(u^\\prime; w)}} = \\begin{cases}\n1 & u = \\arg\\max_{u^\\prime}(𝕌_{S_i}(u^\\prime; w)) \\\\\n0 & u ≠ \\arg\\max_{u^\\prime}(𝕌_{S_i}(u^\\prime; w))\n\\end{cases}\\] Because the cost \\(C(u)\\) only depends on \\(u\\), it is nice to view \\(e^{α * 𝕌_{S_i}(u; w)}\\) as factored into a prior and (something like) a likelihood, so that \\(P_{S_i}(u | w)\\) has a formulation symmetrical to that of \\(P_{L_i}(w | u)\\) (when \\(i &gt; 0\\)); that is, it can be formulated in the following way: \\[\\begin{aligned}\ne^{α * 𝕌_{S_i}(u; w)} &= P_{L_{i - 1}}(w | u)^α * \\frac{1}{e^{α * C(u)}}\n\\\\[2mm] &∝ P_{S_i}(w | u) * P_{S_i}(u) \\\\[2mm]\n&= P_{S_i}(w | u) * P(u)\n\\end{aligned}\\] In effect, we can define \\(P_{S_i}(w | u)\\), viewed as a function of \\(u\\), to be proportional to \\(P_{L_{i - 1}}(w | u)^α\\); meanwhile, we can define \\(P(u)\\), the prior probability over utterances, to be proportional to \\(\\frac{1}{e^{α * C(u)}}\\). (Note that if we ignore cost altogether, so that \\(C(u)\\) is always, say, 0, then \\(P(u)\\) just becomes a uniform distribution.)\nTaking these points into consideration, we may reformulate our speaker model, \\(S_i\\), as follows: \\[\\begin{aligned}\nP_{S_i}(u | w) &= \\frac{P_{S_i}(w | u) * P(u)}{∑_{u^\\prime}P_{S_i}(w |\nu^\\prime) * P(u^\\prime)} \\\\[2mm]\n&= \\frac{P_{S_i}(w | u) * P(u)}{P_{S_i}(w)}\n\\end{aligned}\\] In words, the speaker model, just like the listener model, may be viewed operationally in terms of Bayes’ theorem. Note that \\(P_{S_i}(w)\\), in general, defines a different distribution from \\(P(w)\\), the listener’s prior distribution over worlds (i.e., the context set). The former represents, not prior knowledge about the context, but rather something more like the relative “communicability” of a given possible world, given the distribution \\(P(u)\\) over utterances; that is, how likely a random utterance makes \\(w\\), though with the exponential \\(α\\) applied.\n\n\nAn example\nAn example helps illustrate how the probability distributions determined by RSA speaker and listener models are computed in practice. Let’s say there are seven cookies, as depicted in the image below.\n\n\n\nCookies (7 of them)\n\n\nFurther, say someone utters the sentence Jo ate five cookies. We’ll assume that the literal meaning of such a sentence is lower bounded: it is true just in case the number cookies Jo ate is at least five, i.e., \\[\nn_{\\textit{cookies}} ≥ 5\n\\] Let’s now consider the probability distributions computed by the models \\(L_{0}\\), \\(S_{1}\\), and \\(L_{1}\\), following the definitions given earlier.\n\nThe literal listener \\(L_{0}\\)\nRecall that the literal listener is a filter: \\[\nP_{L_{0}}(w ∣ u) ∝ 𝟙(w ≥ n) × P (w)\n\\] Let’s also assume that \\(P(w)\\), the prior distribution over the number of cookies Jo ate is uniform. Then, the literal listener is simply zeroing out the portion of this prior distribution in which Jo ate less than five cookies and renormalizing the resulting distribution. The following table illustrates this for Jo ate five cookies, as well as two other utterances. Here, \\(w\\) (the world) is identified with a possible inference; i.e., about how many cookies Jo actually ate.\n\n\n\n\\(w =\\)\n5\n6\n7\n\n\n\n\n\\(u = \\textit{Jo ate 5 cookies}\\)\n1/3\n1/3\n1/3\n\n\n\\(u = \\textit{Jo ate 6 cookies}\\)\n0\n1/2\n1/2\n\n\n\\(u = \\textit{Jo ate 7 cookies}\\)\n0\n0\n1\n\n\n\nThus if Jo ate five cookies is uttered, \\(L_{0}\\) assigns a probability of 1/3 to each of the possible inferences compatible with the utterance’s lower-bounded literal meaning.\n\n\nThe pragmatic speaker \\(S_{1}\\)\nHere is the pragmatic speaker model again, reformulated (i) as a proportionality statement, and (ii) by moving the cost term into the denominator: \\[\nP_{S_{1}}(u ∣ w) ∝ \\frac{P_{L_{0}}(w ∣ u)^{α}}{e^{α × C(u)}}\n\\] For the purposes of the example, let’s assume that the rationality parameter \\(α = 4\\), and that the cost \\(C(u)\\) of an utterance is constant across utterances. Let’s further assume that the speaker is only considering the utterances listed in the following table; i.e., its prior distribution—given the constant cost function—is uniform over these alternatives. Then, we obtain the following distributions over utterances for three possible worlds corresponding to the inference which the speaker intends to communicate.\n\n\n\n\\(w =\\)\n5\n6\n7\n\n\n\n\n\\(u = \\textit{Jo ate 5 cookies}\\)\n1\n0.16\n0.01\n\n\n\\(u = \\textit{Jo ate 6 cookies}\\)\n0\n0.84\n0.06\n\n\n\\(u = \\textit{Jo ate 7 cookies}\\)\n0\n0\n0.93\n\n\n\nThus if \\(S_{1}\\) wishes to convey that Jo ate exactly five cookies, it chooses the first utterance with a probability of 1. This is because the literal listener assigns 5 cookies a probability of 0 if one of the other two stronger sentences is uttered. Meanwhile, if it wishes to convey that Jo ate exactly six cookies, it chooses the first utterance with probability \\(\\frac{(1/3)^4}{(1/3)^4 + (1/2)^4} ≈ 0.16\\) and the second utterance with probability \\(\\frac{(1/2)^4}{(1/3)^4 + (1/2)^4} ≈ 0.84\\). Crucially, we see that probabilities are normalized within columns of the table, rather than rows, as is the case for the listener models.\n\n\nThe pragmatic listener \\(L_{1}\\)\nFinally, recall that the pragmatic listener model uses the pragmatic speaker model as a representation of the likelihood of some utterance, given an intended inference. \\[\nP_{L_{1}}(w ∣ u) ∝ P_{S_{1}}(u ∣ w) × P (w)\n\\] Given that there is a uniform prior distribution over numbers of cookies, we may obtain probability distributions for the same three utterances by taking the table in the previous subsection and renormalizing its probabilities within rows.\n\n\n\n\\(w =\\)\n5\n6\n7\n\n\n\n\n\\(u = \\textit{Jo ate 5 cookies}\\)\n0.85\n0.14\n0.01\n\n\n\\(u = \\textit{Jo ate 6 cookies}\\)\n0\n0.93\n0.07\n\n\n\\(u = \\textit{Jo ate 7 cookies}\\)\n0\n0\n1\n\n\n\nNote that if we had a non-uniform prior over numbers of cookies—e.g., if 6 is more probable than 5 (classic Jo)—we can simply multiply the entries of this table by their prior probabilities and renormalize them within rows once again.\n\n\n\nRSA discussion\nAs noted earlier, RSA models come with a very appealing feature: that they provide a modular separation between semantic and pragmatic concerns. In particular, the \\(L_{0}\\) model can be seen as instantiating a semantic analysis of some utterance (which is, ideally, provided by some external theory of the semantics of utterances), while the \\(L_{1}\\) model can be seen as instantiating a pragmatic theory that is built up from the semantic theory in a fairly deterministic way (once, e.g., cost parameters, rationality parameters, and prior distributions over utterance alternatives are fixed). Indeed, such a separation can be methodologically useful, since it allows one to test particular semantic theories in the face of human inference data that arises from pragmatic (as well as other) factors (see, e.g., Waldon and Degen (2020) for discussion)\n\nChallenges\nThere is a particular set of challenges for RSA models, as they are typically stated, that we aim to address in this course. Namely, it is not super obvious what role the Montagovian notion of semantic compositionality can play. Note that the account of the literal listener \\(L_{0}\\) must come “from outside”: RSA models are typically defined on top of analyses of sentence meaning, as opposed to the meanings of basic expressions, though the latter are presumably implicated in deriving the former. Thus there are certain questions about semantic compositionality which such models don’t address:\n\nHow may the semantics of individual expressions be studied in tandem with their pragmatic effects? How should such pragmatic effects be formally encoded in lexical meaning representations?\nHow do pragmatic effects compose, in order to yield the global pragmatic effects associated with entire utterances?\n\nOne of the aims of this course is to provide a framework in which the pragmatic effects of individual expressions may be stated and composed, and then tested against human inference data.\n\n\n\n\n\n\n\n\nReferences\n\nDegen, Judith. 2023. “The Rational Speech Act Framework.” Annual Review of Linguistics 9 (Volume 9, 2023): 519–40. https://doi.org/10.1146/annurev-linguistics-031220-010811.\n\n\nFrank, Michael C., and Noah D. Goodman. 2012. “Predicting Pragmatic Reasoning in Language Games.” Science 336 (6084): 998–98. https://doi.org/10.1126/science.1218633.\n\n\nGoodman, Noah D., and Andreas Stuhlmüller. 2013. “Knowledge and Implicature: Modeling Language Understanding as Social Cognition.” Topics in Cognitive Science 5 (1): 173–84. https://doi.org/10.1111/tops.12007.\n\n\nGrice, H. Paul. 1975. “Logic and Conversation.” In Syntax and Semantics, edited by Peter Cole and Jerry L. Morgan, 3, Speech Acts:41–58. New York: Academic Press.\n\n\nWaldon, Brandon, and Judith Degen. 2020. “Modeling Behavior in Truth Value Judgment Task Experiments.” In Proceedings of the Society for Computation in Linguistics 2020, edited by Allyson Ettinger, Gaja Jarosz, and Joe Pater, 238–47. New York, New York: Association for Computational Linguistics. https://aclanthology.org/2020.scil-1.29/.",
    "crumbs": [
      "Background",
      "Rational Speech Act models"
    ]
  },
  {
    "objectID": "background/experimental-turn.html",
    "href": "background/experimental-turn.html",
    "title": "The experimental turn",
    "section": "",
    "text": "\\[\n\\newcommand{\\expr}[3]{\\begin{array}{c}\n#1 \\\\\n\\bbox[lightblue,5px]{#2}\n\\end{array} ⊢ #3}\n\\newcommand{\\ct}[1]{\\bbox[font-size: 0.8em]{\\mathsf{#1}}}\n\\newcommand{\\updct}[1]{\\ct{upd\\_#1}}\n\\newcommand{\\abbr}[1]{\\bbox[transform: scale(0.95)]{\\mathtt{#1}}}\n\\newcommand{\\pure}[1]{\\bbox[border: 1px solid orange]{\\bbox[border: 4px solid transparent]{#1}}}\n\\newcommand{\\return}[1]{\\bbox[border: 1px solid black]{\\bbox[border: 4px solid transparent]{#1}}}\n\\def\\P{\\mathtt{P}}\n\\def\\Q{\\mathtt{Q}}\n\\def\\True{\\ct{T}}\n\\def\\False{\\ct{F}}\n\\def\\ite{\\ct{if\\_then\\_else}}\n\\def\\Do{\\abbr{do}}\n\\]\n\nThe traditional methodology’s success has created a foundation solid enough to support exciting new extensions. Experimental semantics brings the tools of behavioral experimentation to bear on questions about meaning, allowing us to test and refine theoretical insights at unprecedented scale.\n\nScaling Semantic Investigation\nWhere traditional methods might examine a handful of predicates, experimental approaches can investigate entire lexical domains. Extending our example involving the verb love: English has thousands of similar clause-embedding predicates, each potentially varying in its inferential properties. We can now test whether generalizations based on canonical examples extend across these vast lexicons.\nThe MegaAttitude project (White and Rawlins 2016, 2018, 2020; White et al. 2018; An and White 2020; Moon and White 2020; Kane, Gantt, and White 2022) is one example of this approach. This project aims to collect inference judgments for hundreds of predicates across multiple contexts and inference types. This scale reveals patterns that are very difficult to see and evaluate the quality of using traditional methods—subtle distinctions between near-synonyms, unexpected predicate clusters, and systematic variation across semantic domains.\n\n\nTeasing Apart Contributing Factors\nExperimental methods also allow us to investigate the rich array of factors that influence inference judgments:\n\nSemantic knowledge: The core meanings of expressions\nWorld knowledge: Prior beliefs about plausibility\n\nContextual factors: The discourse context and QUD\nIndividual differences: Variation in how speakers interpret expressions\nResponse strategies: How participants use rating scales\n\nRather than viewing these as confounds, we can see them as windows into the cognitive processes underlying semantic interpretation. For instance, Degen and Tonhauser (2021) systematically manipulated world knowledge to show how prior beliefs modulate the strength of factive inferences, revealing the interplay between semantic and pragmatic factors.\n\n\nMaking Linking Hypotheses Explicit\nPerhaps most importantly, experimental approaches force us to make explicit what traditional methods leave implicit: the link between semantic representations and behavioral responses (Jasbi, Waldon, and Degen 2019; Waldon and Degen 2020; Phillips et al. 2021). When we say speakers judge that an inference follows, what cognitive processes produce that judgment? How do abstract semantic representations map onto the responses on some scale?\nThis is not merely a methodological detail—it’s a substantive theoretical question. Different linking hypotheses make different predictions about response patterns, allowing us to test not just our semantic theories but our assumptions about how those theories connect to behavior. Even if our real interest is in characterizing the semantic representations of speakers, we can’t ignore the way those representations map onto their responses in some task.\n\n\n\n\n\n\n\nReferences\n\nAn, Hannah, and Aaron White. 2020. “The Lexical and Grammatical Sources of Neg-Raising Inferences.” Proceedings of the Society for Computation in Linguistics 3 (1): 220–33. https://doi.org/https://doi.org/10.7275/yts0-q989.\n\n\nDegen, Judith, and Judith Tonhauser. 2021. “Prior Beliefs Modulate Projection.” Open Mind 5 (September): 59–70. https://doi.org/10.1162/opmi_a_00042.\n\n\nJasbi, Masoud, Brandon Waldon, and Judith Degen. 2019. “Linking Hypothesis and Number of Response Options Modulate Inferred Scalar Implicature Rate.” Frontiers in Psychology 10 (February). https://doi.org/10.3389/fpsyg.2019.00189.\n\n\nKane, Benjamin, Will Gantt, and Aaron Steven White. 2022. “Intensional Gaps: Relating Veridicality, Factivity, Doxasticity, Bouleticity, and Neg-Raising.” Semantics and Linguistic Theory 31 (0): 570–605. https://doi.org/10.3765/salt.v31i0.5137.\n\n\nMoon, Ellise, and Aaron White. 2020. “The Source of Nonfinite Temporal Interpretation.” In Proceedings of the 50th Annual Meeting of the North East Linguistic Society, edited by Mariam Asatryan, Yixiao Song, and Ayana Whitmal, 3:11–24. Amherst: GLSA Publications.\n\n\nPhillips, Colin, Phoebe Gaston, Nick Huang, and Hanna Muller. 2021. “Theories All the Way Down: Remarks on ‘Theoretical’ and ‘Experimental’ Linguistics.” In The Cambridge Handbook of Experimental Syntax, edited by Grant Goodall, 587–616. Cambridge Handbooks in Language and Linguistics. Cambridge: Cambridge University Press. https://doi.org/10.1017/9781108569620.023.\n\n\nWaldon, Brandon, and Judith Degen. 2020. “Modeling Behavior in Truth Value Judgment Task Experiments.” In Proceedings of the Society for Computation in Linguistics 2020, edited by Allyson Ettinger, Gaja Jarosz, and Joe Pater, 238–47. New York, New York: Association for Computational Linguistics. https://aclanthology.org/2020.scil-1.29/.\n\n\nWhite, Aaron Steven, and Kyle Rawlins. 2016. “A Computational Model of S-Selection.” Semantics and Linguistic Theory 26 (0): 641–63. https://doi.org/10.3765/salt.v26i0.3819.\n\n\n———. 2018. “The Role of Veridicality and Factivity in Clause Selection.” In NELS 48: Proceedings of the Forty-Eighth Annual Meeting of the North East Linguistic Society, edited by Sherry Hucklebridge and Max Nelson, 48:221–34. University of Iceland: GLSA (Graduate Linguistics Student Association), Department of Linguistics, University of Massachusetts.\n\n\n———. 2020. “Frequency, Acceptability, and Selection: A Case Study of Clause-Embedding.” Glossa: A Journal of General Linguistics 5 (1). https://doi.org/10.5334/gjgl.1001.\n\n\nWhite, Aaron Steven, Rachel Rudinger, Kyle Rawlins, and Benjamin Van Durme. 2018. “Lexicosyntactic Inference in Neural Models.” In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, 4717–24. Brussels, Belgium: Association for Computational Linguistics. https://doi.org/10.18653/v1/D18-1501.",
    "crumbs": [
      "Background",
      "The experimental turn"
    ]
  },
  {
    "objectID": "background/traditional-methodology.html",
    "href": "background/traditional-methodology.html",
    "title": "From theory to data",
    "section": "",
    "text": "\\[\n\\newcommand{\\expr}[3]{\\begin{array}{c}\n#1 \\\\\n\\bbox[lightblue,5px]{#2}\n\\end{array} ⊢ #3}\n\\newcommand{\\ct}[1]{\\bbox[font-size: 0.8em]{\\mathsf{#1}}}\n\\newcommand{\\updct}[1]{\\ct{upd\\_#1}}\n\\newcommand{\\abbr}[1]{\\bbox[transform: scale(0.95)]{\\mathtt{#1}}}\n\\newcommand{\\pure}[1]{\\bbox[border: 1px solid orange]{\\bbox[border: 4px solid transparent]{#1}}}\n\\newcommand{\\return}[1]{\\bbox[border: 1px solid black]{\\bbox[border: 4px solid transparent]{#1}}}\n\\def\\P{\\mathtt{P}}\n\\def\\Q{\\mathtt{Q}}\n\\def\\True{\\ct{T}}\n\\def\\False{\\ct{F}}\n\\def\\ite{\\ct{if\\_then\\_else}}\n\\def\\Do{\\abbr{do}}\n\\]\nSemantic theory has achieved remarkable success in characterizing the compositional structure of natural language meaning. Through decades of careful theoretical work, semanticists have developed elegant formal systems that capture how complex meanings arise from the systematic combination of simpler parts. These theories explain two fundamental types of judgments that speakers make: acceptability judgments about whether strings are well-formed, and inference judgments about what follows from what speakers say.\nThe field now stands at an exciting juncture. The rise of large-scale experimental methods and computational modeling opens new opportunities to test and refine these theoretical insights against rich behavioral data. The challenge—and opportunity—is to connect our elegant formal theories to the messy, gradient patterns we observe when hundreds of speakers make thousands of judgments. How can we maintain the theoretical insights that formal semantics has achieved while extending them to account for this new empirical richness?\nProbabilistic Dynamic Semantics (PDS) aims to provide a systematic bridge between these theoretical insights and behavioral data. It takes the compositional analyses developed using traditional Montagovian methods and maps them to probabilistic models that can be quantitatively evaluated against experimental results. The goal is not to replace traditional semantics but to extend its reach, allowing us to test theoretical predictions at unprecedented scale while maintaining formal rigor.",
    "crumbs": [
      "Background",
      "From theory to data"
    ]
  },
  {
    "objectID": "background/traditional-methodology.html#traditional-semantic-methodology-foundations-of-success",
    "href": "background/traditional-methodology.html#traditional-semantic-methodology-foundations-of-success",
    "title": "From theory to data",
    "section": "Traditional Semantic Methodology: Foundations of Success",
    "text": "Traditional Semantic Methodology: Foundations of Success\nSemanticists study the systematic relationships between linguistic expressions and the inferences they support. The field’s methodology centers on two types of judgments:\nAcceptability judgments assess whether strings are well-formed relative to a language and in a particular context of use (see Schütze 2016 and references therein).   For example, in a context where a host asks what a guest wants with coffee, (1) is clearly acceptable, while (2) is not Sprouse and Villata (2021):\n\nWhat would you like with your coffee?\n#What would you like and your coffee?\n\nInference judgments assess relationships between strings (see Davis and Gillon 2004).   When speakers hear (3), they typically infer (4) (White 2019):\n\nJo loved that Mo left.\nMo left.\n\n\nObservational Adequacy\nA core desideratum for semantic theories is observational adequacy (Chomsky 1964): for any string \\(s \\in \\Sigma^*\\), we should predict how acceptable speakers find it in context, and for acceptable strings \\(s, s'\\), we should predict whether speakers judge \\(s'\\) inferable from \\(s\\). Achieving observational adequacy requires mapping vocabulary elements to abstractions that predict judgments parsimoniously.\nThese abstractions may be discrete or continuous, simple or richly structured. Through careful analysis of consistent inference patterns, semanticists have identified powerful generalizations. For instance, examining predicates like love, hate, be surprised, and know, theorists observed they all give rise to inferences about their complement clauses that survive under negation and questioning. This led to positing that they all share a property that predicts systematic inferential behavior across diverse predicates (Kiparsky and Kiparsky 1970; cf. Karttunen 1971).\n\n\nDescriptive Adequacy and Theoretical Depth\nBeyond observational adequacy lies descriptive adequacy: capturing data “in terms of significant generalizations that express underlying regularities in the language” (Chomsky 1964, 63). This drive for deeper explanation motivates the field’s emphasis on parsimony and formal precision.\nThe history of generative syntax illustrates two approaches to achieving descriptive adequacy:\n\nAnalysis-driven: Start with observationally adequate analyses in expressive formalisms, then extract generalizations as constraints Baroni (2022).\nHypothesis-driven: Begin with constrained formalisms (like CCG or minimalist grammars) and test their empirical coverage Steedman (2000).\n\nThe hypothesis-driven approach, which PDS adopts for semantics, aims to delineate phenomena through representational constraints. This becomes crucial when developing models that both accord with theoretical assumptions and can be evaluated quantitatively.\n\n\nThe Power and Natural Boundaries of Traditional Methods\nThis methodology has yielded profound insights into semantic composition, scope phenomena, discourse dynamics, and the semantics-pragmatics interface more generally. By focusing on carefully constructed examples and native speaker intuitions, theorists have uncovered deep regularities in how meaning is constructed and interpreted.\nYet every methodology has natural boundaries. Traditional semantic methods excel at identifying patterns and building theories but face practical constraints when we ask:\n\nHow well do our generalizations, based on examining 5-10 predicates, extend to the thousands of predicates in the lexicon?\nWhat factors beyond semantic knowledge influence the judgments we observe?\nHow exactly does abstract semantic knowledge produce concrete behavioral responses?",
    "crumbs": [
      "Background",
      "From theory to data"
    ]
  },
  {
    "objectID": "background/setting-stage.html",
    "href": "background/setting-stage.html",
    "title": "Setting the stage",
    "section": "",
    "text": "To round out this set of notes, we give a brief overview of the main desiderata which we aim to have PDS satisfy. These are the following:\n\ncompositionality: models of inference should be derived compositionally from semantic grammar fragments.\nmodularity: factors affecting inference judgments should be theorized about independently and combined.\nabstraction: models of meaning and inference should be statable abstractly, without reference to implementation.\n\nWe say a little more about these here, in turn.\n\nCompositionality for models\nWhat could it mean for models of linguistic inference (e.g., as represented in a judgment dataset) to be compositional? Our basic basic strategy is to build the distributional assumptions associated with, e.g., a mixed-effects model, into the semantics. This way, when basic meanings compose, so do these distributional assumptions.\nIndeed, it is reasonable to ask what such distributional assumptions represent. Our answer is uncertainty; specifically, uncertainty about which particular inferences are licensed on any given occasion of language use. Importantly, these kinds of assumptions may be combined when determining the meanings of complex expressions from the meanings of the more basic expressions they contain. Thus while the meaning of a sentence such as Jo laughs might be determined compositionally as\n\\[\n⟦\\textit{jo laughs}⟧ = ⟦\\textit{laughs}⟧ ▹ ⟦\\textit{jo}⟧ = laughs(j)\n\\]\nwithin a traditional semantic framework, PDS, instead, compositionally associates this sentence with a probability distribution.\n\\[⟦\\textit{jo laughs}⟧ = ⟦\\textit{laughs}⟧ ▹ ⟦\\textit{jo}⟧ = \\begin{array}[t]{l}\nj ∼ JoDistr \\\\\nlaugh ∼ LaughDistr \\\\\nReturn (laugh(j))\n\\end{array}\n\\]\nThis distribution is a distribution over truth values: it assigns some probability \\(p\\) to True and \\(1 - p\\) to False. Moreover, it is determined by certain sampling statements (whose interpretations we will formally define tomorrow). Informally, the meaning of Jo takes some distribution over entities, while the meaning of laughs takes some distribution over functions from entities to truth values. These distributions may then be combined to yield a distribution over values gotten by applying such functions applied to such entities; i.e., a distribution over truth values. Remarkably, the distributions over the meanings of such basic expressions end up corresponding exactly, within PDS, to the parameters of some hierarchical Bayesian (e.g., mixed-effects) model which may be used to fit human inference judgment data.\n\n\nModularity\nWe also want theories constructed within PDS to be modular. Specifically, we want the factors affecting inference to be able to be theorized about independently and combined. These include:\n\nlexical and compositional semantics\nworld knowledge\nresponse behavior: how does someone use a testing instrument (e.g., slider scale)?\n\nAn upshot of this feature is that PDS can have different uses. For example, one could swap out a model of response behavior for a model of likely utterances (perhaps, \\(S_{1}\\)).\n\n\nAbstraction\nFinally, we want such theories to display a certain amount of abstraction. That is, we should be able to state models of inference judgment data that:\n\ndescribe probability distributions,\ndo not concern themselves with how distributions are computed.\n\nThere are a couple useful consequences of this feature. First, it allows traditional semantic theories to be plugged into PDS rather seamlessly. Second, it allows separation between theories stated within PDS and model stated within those thoeries. This second consequence allows:\n\nAllows flexibility about implementation.\nAllows the theory to be simpler.\nAllows seamless integration between formal semantics and probabilistic semantics. (More tomorrow!)",
    "crumbs": [
      "Background",
      "Setting the stage"
    ]
  },
  {
    "objectID": "pds-intro/overview.html",
    "href": "pds-intro/overview.html",
    "title": "Overview",
    "section": "",
    "text": "\\[\n\\newcommand{\\expr}[3]{\\begin{array}{c}\n#1 \\\\\n\\bbox[lightblue,5px]{#2}\n\\end{array} ⊢ #3}\n\\newcommand{\\ct}[1]{\\bbox[font-size: 0.8em]{\\mathsf{#1}}}\n\\newcommand{\\updct}[1]{\\ct{upd\\_#1}}\n\\newcommand{\\abbr}[1]{\\bbox[transform: scale(0.95)]{\\mathtt{#1}}}\n\\newcommand{\\pure}[1]{\\bbox[border: 1px solid orange]{\\bbox[border: 4px solid transparent]{#1}}}\n\\newcommand{\\return}[1]{\\bbox[border: 1px solid black]{\\bbox[border: 4px solid transparent]{#1}}}\n\\def\\P{\\mathtt{P}}\n\\def\\Q{\\mathtt{Q}}\n\\def\\True{\\ct{T}}\n\\def\\False{\\ct{F}}\n\\def\\ite{\\ct{if\\_then\\_else}}\n\\def\\Do{\\abbr{do}}\n\\]\nCompositional dynamic semantic theories often model utterance meanings as maps from discourse states into sets of discourse states.1 PDS inherits this functional view of utterances; but following much work in the probabilistic semantics and pragmatics literature (van Benthem, Gerbrandy, and Kooi 2009; Lassiter 2011; Frank and Goodman 2012; Zeevat 2013; Lassiter and Goodman 2017; Bergen, Levy, and Goodman 2016, i.a.), it translates this idea into a probabilistic setting: in PDS, utterances denote maps from discourse states to probability distributions over discourse states. Thus in comparison to traditional dynamic semantics, PDS introduces a weighting on discourse states, allowing one to model preferences for certain resolutions of ambiguity over others.",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Overview"
    ]
  },
  {
    "objectID": "pds-intro/overview.html#probability-distributions-as-monadic-values",
    "href": "pds-intro/overview.html#probability-distributions-as-monadic-values",
    "title": "Overview",
    "section": "Probability distributions as monadic values",
    "text": "Probability distributions as monadic values\nIn and of itself, this extension is not novel. More novel is that we view probability distributions as monadic values that inhabit types arising from a probability monad (see, e.g., Giorgolo and Asudeh 2014; Bernardy et al. 2019; Grove and Bernardy 2023). We formalize this view soon; but the gist is that viewing probability distributions this way allows PDS (i) to map linguistic expressions of a particular type to probability distributions over objects of that type so that the usual compositional structure of semantic analyses is retained; and thereby (ii) to compose probabilistic analyses with other analyses of, say, anaphora; as well as (iii) to define explicit linking models that map probability distributions over discourse states to probability distributions over judgments recorded using some response instrument.2\nCrucial for PDS is that because probability distributions are characterized by a monad, they may themselves be stacked while retaining properties important for semantic composition.3 That is, the types derived from a probability monad may be inhabited by distributions over familiar types of objects—entities, truth values, functions from entities to truth values, and the like—or they may be inhabited by distributions over such distributions. And this stacking can be as deep as is necessary to model the sorts of uncertainty of interest to the analyst.",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Overview"
    ]
  },
  {
    "objectID": "pds-intro/overview.html#two-kinds-of-uncertainty",
    "href": "pds-intro/overview.html#two-kinds-of-uncertainty",
    "title": "Overview",
    "section": "Two kinds of uncertainty",
    "text": "Two kinds of uncertainty\nWe argue here that at least two levels of stacking are necessary in order to appropriately model two kinds of interpretive uncertainty, respectively, which we refer to as resolved (or type-level) uncertainty and unresolved (or token-level) uncertainty. Resolved uncertainty is any kind of uncertainty which relates to lexical, structural, or semantic (e.g., scopal) ambiguity. For example, a polysemous word gives rise to resolved uncertainty. Based on the content of its direct object, ran in (1) seems likely to take on its locomotion sense, though it remains plausible that it has a management sense if Jo is understood to be the race’s organizer.\n\nJo ran a race.\n\nIn contrast, unresolved uncertainty is that which is associated with an expression in view of some fixed meaning it has. Vague adjectives may give rise to unresolved uncertainty, for example, as witnessed by the vague inferences they support: the minimum degree of height tall requires to hold of entities of which it is true remains uncertain on any use of (2), even while the adjective’s meaning plausibly does not always vary across such uses.\n\nJo is tall.\n\nIn general, we conceptualize unresolved uncertainty as reflecting the uncertainty that one has about a given inference at a particular point in some discourse, having fixed the meanings of the linguistic expressions.\nPut slightly differently, resolved uncertainty is a property of one’s knowledge about the meanings of expressions qua expressions. Sometimes run means this; sometimes it means that. Thus, any analysis of the uncertainty about the meaning of run should capture that it is uncertainty about types of utterance act. In contrast, unresolved uncertainty encompasses any semantic uncertainty which remains, having fixed the type of utterance act—it is uncertainty pertaining to the semantically licensed inferences themselves.4\nTo capture this idea, our approach regards these types of uncertainty as interacting with each other in a restricted fashion by taking advantage of the fact that distributions may be stacked. Because resolved uncertainty must be resolved in order for one to draw semantically licensed inferences from uses of particular expressions, we take resolved parameters to be fixed in the computation of unresolved uncertainty. This rigid connection among sources of uncertainty is a natural consequence of structuring probabilistic reasoning in terms of stacked probability distributions.",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Overview"
    ]
  },
  {
    "objectID": "pds-intro/overview.html#discourse-states",
    "href": "pds-intro/overview.html#discourse-states",
    "title": "Overview",
    "section": "Discourse states",
    "text": "Discourse states\nWe follow a common in dynamic semantics practice by regarding discourse states as lists of parameters. We depart slightly from the usual assumption that these lists are homogenous by treating them as potentially arbitrarily complex, i.e., heterogeneous (though see Bumford and Charlow 2022). As such, they could be structured according to a variety of models sometimes employed in formal pragmatics (e.g., Farkas and Bruce 2010). For example, we will define one parameter of this list to be a representation of the Stalnakerian common ground (or more aptly, the “context set”: Stalnaker 1978 et seq.) and another parameter to be a stack of Questions Under Discussion (QUDs: Ginzburg 1996; Roberts 2012).\nWe represent common grounds as probability distributions over indices encoding information about possible worlds, as well as what we call contexts. The possible world part of an index represents facts about how the (non-linguistic) world is—e.g., a particular individual’s height—while the context part encodes certain facts about lexical meaning—e.g., the identity of the height threshold conveyed by a vague adjective, such as tall (see, i.a.: Kennedy and McNally 2005; Kennedy 2007; Lassiter 2011).\nUtterances—and more broadly, discourses—map tuples of parameters onto probability distributions over new tuples of parameters. Moreover, complex linguistic acts may be sequenced; in general, the effect on an ongoing discourse of multiple linguistic acts may be computed by using the sequencing operation (bind) native to the probability monad. In this sense, compositionality of interpretation obtains in PDS from the level of individual morphemes all the way up to the level of complex exchanges. For example, a discourse may consist in (i) making an assertion, which (perhaps, under a simplified model) modifies the common ground; (ii) asking a question, which adds a QUD to the top of the QUD stack; or (iii) a sequence of these. Regardless, we require the functions encoding discourses to return probabilistic values, in order to capture their inherent uncertainty.",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Overview"
    ]
  },
  {
    "objectID": "pds-intro/overview.html#linking-models",
    "href": "pds-intro/overview.html#linking-models",
    "title": "Overview",
    "section": "Linking models",
    "text": "Linking models\nA linking model takes a discourse as conceived above, together with an initial probability distribution over discourse states, and links them to a distribution over responses to the current QUD. The possible responses to the QUD are determined by a data collection instrument, which could be a Likert scale, a slider scale, or something else. Furthermore, the distribution over responses is fixed by a likelihood function whose choice is constrained by the nature of the values encoded by the instrument. Thus a Bernoulli distribution for instruments that produce binary values; a categorical distribution for instruments that produce unordered, multivalued discrete responses; a linked logit distribution for instruments that produce ordered, multivalued discrete responses; and so on.",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Overview"
    ]
  },
  {
    "objectID": "pds-intro/overview.html#haskell",
    "href": "pds-intro/overview.html#haskell",
    "title": "Overview",
    "section": "Haskell",
    "text": "Haskell\nThroughout these sets of notes, we include code snippets in the Haskell programming language to illustrate concepts that we introduce. There is a working Haskell implementation of PDS, which is currently undergoing further development, and which can translate PDS models into minimal pieces of code in the Stan programming language for several of the example modeling cases that we will discuss. Since the components of PDS are presented with their computational implementation in mind, we think it is particularly revealing to see the code itself. Thus we will interleave relevant code with the prose and semantic formulae.",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Overview"
    ]
  },
  {
    "objectID": "pds-intro/overview.html#footnotes",
    "href": "pds-intro/overview.html#footnotes",
    "title": "Overview",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n In its distributive implementations, that is. For a discussion of distributive vs. non-distributive variants of dynamic semantics, see, e.g., Charlow (2019).↩︎\n This type of capability is often discussed in the experimental linguistics literature under the heading of linking hypotheses or linking assumptions (see Phillips et al. (2021)). For our purposes, we define linking models to be statistical models that relate a PDS analysis (which determines a probability distribution over the inferences supported by a linguistic expression) to comprehenders’ judgments, as recorded using a particular instrument.↩︎\n More to the point, monads give rise to functors, which are composable, giving rise to the “stacking”.↩︎\n See Beaver (1999) and Beaver (2001), which describe an analogous bifurcation of orders of pragmatic reasoning in the representation of the common ground.↩︎",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Overview"
    ]
  },
  {
    "objectID": "pds-intro/adding-probabilistic-types.html",
    "href": "pds-intro/adding-probabilistic-types.html",
    "title": "Adding probabilistic types",
    "section": "",
    "text": "\\[\n\\newcommand{\\expr}[3]{\\begin{array}{c}\n#1 \\\\\n\\bbox[lightblue,5px]{#2}\n\\end{array} ⊢ #3}\n\\newcommand{\\ct}[1]{\\bbox[font-size: 0.8em]{\\mathsf{#1}}}\n\\newcommand{\\updct}[1]{\\ct{upd\\_#1}}\n\\newcommand{\\abbr}[1]{\\bbox[transform: scale(0.95)]{\\mathtt{#1}}}\n\\newcommand{\\pure}[1]{\\bbox[border: 1px solid orange]{\\bbox[border: 4px solid transparent]{#1}}}\n\\newcommand{\\return}[1]{\\bbox[border: 1px solid black]{\\bbox[border: 4px solid transparent]{#1}}}\n\\def\\P{\\mathtt{P}}\n\\def\\Q{\\mathtt{Q}}\n\\def\\True{\\ct{T}}\n\\def\\False{\\ct{F}}\n\\def\\ite{\\ct{if\\_then\\_else}}\n\\def\\Do{\\abbr{do}}\n\\]\nThe type system presented in above included types for entities, truth values, and types formed from these. PDS is inspired by the presentation in Grove and Bernardy (2023), who illustrate how a semantics incorporating Bayesian reasoning can be encoded using a λ-calculus with such a frugal type system; however, whereas Grove and Bernardy (2023) represent probabilistic reasoning using continuations, we employ a somewhat more abstract presentation by incorporating a new type constructor (\\(\\P\\)). In addition, we add a type \\(r\\) to represent real numbers, for the following new set of atomic types.\n\\[\nA \\Coloneqq e ∣ t ∣ r\n\\]\nThen, the full (and final) set of types can be given as follows.\n\\[\n\\mathcal{T}_{A} \\Coloneqq A ∣ \\mathcal{T}_{A} → \\mathcal{T}_{A} ∣ \\mathcal{T}_{A} × \\mathcal{T}_{A} ∣ ⋄ ∣ \\P \\mathcal{T}_{A}\n\\]\nIn Haskell\nTypes of the form \\(\\P α\\) are inhabited by probabilistic programs that represent probability distributions over values of type \\(α\\). For example, a program of type \\(\\P t\\) represents a probability distribution over truth values (i.e., a Bernoulli distribution); a program of type \\(\\P e\\) represents a probability distribution over entities (e.g., a categorical distribution; a program of type \\(\\P r\\) represents a probability distribution over real numbers (e.g., a normal distribution); and a program of type \\(\\P (e → t)\\) represents a probability distribution over functions from entities to truth values. Given the new inventory of probabilistic types, probabilistic programs are typed as follows:\n\\[\n\\begin{array}{c}\n\\begin{prooftree}\n\\AxiomC{$Γ ⊢ t : α$}\n\\RightLabel{$\\mathtt{Return}$}\\UnaryInfC{$Γ ⊢ \\pure{t} : \\P α$}\n\\end{prooftree}\n& \\begin{prooftree}\n\\AxiomC{$Γ ⊢ t : \\P α$}\n\\AxiomC{$Γ, x : α ⊢ u : \\P β$}\n\\RightLabel{$\\mathtt{Bind}$}\\BinaryInfC{$Γ ⊢ \\left(\\begin{array}{l} x ∼ t \\\\ u\\end{array}\\right) : \\P β$}\n\\end{prooftree}\n\\end{array}\n\\]\nThus there are to constructors that can be used to produce typed probabilistic programs; we call these ‘return’, and ‘bind’. The \\(\\mathtt{Return}\\) rule effectively turns any value \\(t\\) into a degenerate distribution; i.e., a probability distribution all of whose probability mass is assigned to the value \\(t\\). We denote this distribution by wrapping the relevant value in an orange box, as shown. Meanwhile, the \\(\\mathtt{Bind}\\) rule allows one to compose probabilistic programs together. Given some program \\(t\\), one can sample a value (\\(x\\)) from \\(t\\) and then keep going with the program \\(u\\). We describe some of the interactions between return and bind in a little more detail (and with some illustrative examples) next.\nWe also upgrade our λ-terms in Haskell to reflect these constructors:\nHere, the bind operator is notated using Let: Let x t u is to be read as\n\\[\n\\begin{array}{l}\nx ∼ t \\\\\nu\n\\end{array}\n\\]",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Adding probabilistic types"
    ]
  },
  {
    "objectID": "pds-intro/adding-probabilistic-types.html#the-probability-monad",
    "href": "pds-intro/adding-probabilistic-types.html#the-probability-monad",
    "title": "Adding probabilistic types",
    "section": "The probability monad",
    "text": "The probability monad\nImportantly, the map \\(\\P\\) from types to types is defined to be a monad. The typing rules given above feature one rule corresponding to each of two different monadic operators: \\(\\mathtt{Return}\\) (an introduction rule) and \\(\\mathtt{Bind}\\) (an elimination rule).1 As a monad, \\(\\P\\) (together with return and bind) should satisfy the following monad laws; i.e., the following equalities—Left identity, Right identity, and Associativity—should be supported:\n\\[\n\\begin{array}{c}\n\\textit{Left identity} & \\textit{Right identity} & \\textit{Associativity} \\\\[1mm]\n\\begin{array}{l}\nx ∼ \\pure{v} \\\\\nk\n\\end{array}\\ \\ =\\ \\ k[v/x]\n& \\begin{array}{l}\nx ∼ m \\\\\n\\pure{x}\n\\end{array}\\ \\ =\\ \\ m\n& \\begin{array}{l}\ny ∼ \\left(\\begin{array}{l}\nx ∼ m \\\\\nn\n\\end{array}\\right) \\\\\no\n\\end{array}\\ \\ =\\ \\ \\begin{array}{l}\nx ∼ m \\\\\ny ∼ n \\\\\no\n\\end{array}\n\\end{array}\n\\]\nThese provide tight constraints on the behavior probabilistic programs. Left identity says that sampling a value from a degenerate distribution (via return and bind) is trivial: it can only result in the single value that the degenerate distribution assigns all of its mass to. The law encodes this fact by allowing one to simply continue with rest of the relevant probabilistic program (\\(k\\), whatever that may be), but with the returned value \\(v\\) substituted for the sampled value \\(x\\).\nWhat Right identity says is sort of symmetrical: sampling a value from a program \\(m\\) and immediately returning that value as new degenerate distribution is also trivial; you can always get rid of this extra step.\nFinally, Associativity says that sampling a value (\\(y\\)) from a complex probabilistic program is the same as sampling it from the distribution defined in the final step of this program. For example, if one has one normal distribution parameterized by a value sampled from another,\n\\[\n\\begin{array}{l}\ny ∼ \\left(\\begin{array}{l}\nx ∼ \\abbr{Normal}(0, 1) \\\\\n\\abbr{Normal}(x, 1)\n\\end{array}\\right) \\\\\no\n\\end{array}\n\\]\none can always pull out the parts of this complex distribution to yield a series of bind statements:\n\\[\n\\begin{array}{l}\nx ∼ \\abbr{Normal}(0, 1) \\\\\ny ∼ \\abbr{Normal}(x, 1) \\\\\no\n\\end{array}\n\\]",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Adding probabilistic types"
    ]
  },
  {
    "objectID": "pds-intro/adding-probabilistic-types.html#some-examples",
    "href": "pds-intro/adding-probabilistic-types.html#some-examples",
    "title": "Adding probabilistic types",
    "section": "Some examples",
    "text": "Some examples\nWe can recruit return and bind to characterize complex probability distributions. To illustrate, suppose we have some categorical distribution, \\(\\ct{mammal}: \\P e\\), on mammals. We can represent a distribution on mammals’ mothers as in (1).\n\n\\[\n\\begin{array}[t]{l}\nx ∼ \\ct{mammal}\\\\\n\\pure{\\ct{mother}(x)}\n\\end{array}\n\\]\n\nHere, a random entity \\(x: e\\) is sampled from \\(\\ct{mammal}: \\P e\\) using bind, and then \\(\\ct{mother}(x): e\\) is returned, as indicated by the orange box. Since return turns things of type \\(α\\) into probabilistic programs of type \\(\\P α\\), the resulting probabilistic program is of type \\(\\P e\\). Furthermore, assuming that the probability distribution \\(\\ct{mammal}\\) only has support on (i.e., assigns non-zero probability to) the entities which are mammals, the distribution which results will only have support on the entities which are the mothers of entities which are mammals.\n\nReweighting distributions\nOur probabilistic language also comes with an operator \\(\\ct{factor}\\) for scaling probability distributions according to some weight.2\n\n\\[\\ct{factor} : r → \\P ⋄\\]\n\nFor instance, we may constrain our “mother” distribution so that it assigns more weight to the mothers of mammals which are hungrier.\n\n\\[\\begin{array}[t]{l}\nx ∼ \\ct{mammal} \\\\\n\\ct{factor}(\\ct{hungry}(x)) \\\\\n\\pure{\\ct{mother}(x)}\n\\end{array}\\]\n\nHere, \\(\\ct{hungry} : e → r\\) maps entities onto degrees representing how hungry they are. Thus the program above represents a probability distribution over entities which assigns non-zero probabilities only to entities which are the mother of some mammal, and which assigns greater probabilities to entities the hungrier their children are.\n\n\nMaking observations\nIn terms of \\(\\ct{factor}\\), we may define another function, \\(\\ct{observe}\\).\n\n\\[\n\\begin{align*}\n\\ct{observe}\\ \\ &:\\ \\ t → \\P ⋄ \\\\\n\\ct{observe}(p)\\ \\ &=\\ \\ \\ct{factor}(𝟙(p))\n\\end{align*}\n\\]\n\n\\(\\ct{observe}\\) takes a truth value and either keeps or throws out the distribution represented by the expression which follows it, depending on whether this truth value is \\(\\True\\) or \\(\\False\\). This is accomplished by factoring a distribution by the value of an indicator function (\\(𝟙\\)) applied to the truth value.3\n\n\\[\n\\begin{align*}\n𝟙\\ \\ &:\\ \\ t → r \\\\\n𝟙(\\True)\\ \\ &=\\ \\ 1 \\\\\n𝟙(\\False)\\ \\ &=\\ \\ 0\n\\end{align*}\n\\]\n\nFor instance, we may instead constrain our “mother” program to describe a distribution over only dogs’ mothers.\n\n\\[\n\\begin{array}[t]{l}\nx ∼ \\ct{mammal} \\\\\n\\ct{observe}(\\ct{dog}(x)) \\\\\n\\pure{\\ct{mother}(x)}\n\\end{array}\n\\]\n\nThis distribution assigns a probability of \\(0\\) to any entity which is not the mother of some dog. Indeed, we could use both \\(\\ct{factor}\\) and \\(\\ct{observe}\\) to define another distribution which assigns a probability of \\(0\\) to any entity which is not the mother of some dog, and which assigns greater probabilities to mothers of hungrier dogs.\n\n\\[\n\\begin{array}[t]{l}\nx ∼ \\ct{mammal} \\\\\n\\ct{factor}(\\ct{hungry}(x)) \\\\\n\\ct{observe}(\\ct{dog}(x)) \\\\\n\\pure{\\ct{mother}(x)}\n\\end{array}\n\\]",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Adding probabilistic types"
    ]
  },
  {
    "objectID": "pds-intro/adding-probabilistic-types.html#typing-constants-in-haskell",
    "href": "pds-intro/adding-probabilistic-types.html#typing-constants-in-haskell",
    "title": "Adding probabilistic types",
    "section": "Typing constants in Haskell",
    "text": "Typing constants in Haskell\nThe implemented system relies on a Hindley-Milner-style type inference algorithm that finds any λ-term’s principal type—i.e., the most general polymorphic type it can have, given its structure and the types of any constants it contains. We omit the full algorithm here to save space, but it’s still useful to illustrate how constants are assigned types. In general, we rely on signatures to type constants, i.e., partial functions from constants to types:\n-- | Assign types to constants.\ntype Sig = Constant -&gt; Maybe Type\nFor example, a signature that assigns the appropriate types to \\(\\ct{observe}\\) and \\(\\ct{factor}\\), as well as constants formed out of Doubles, is the following one (note that the following syntax requires the LambdaCase Haskell language extension):\nt, r :: Type\nt = At T\nr = At R\n\ntau :: Sig\ntau = \\case\n  Left  \"factor\"  -&gt; Just (r :→ P Unit)\n  Left  \"observe\" -&gt; Just (t :→ P Unit)\n  Right _         -&gt; Just r\nIt may be useful to think about how tau could be extended to accommodate the other expressions mentioned above.",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Adding probabilistic types"
    ]
  },
  {
    "objectID": "pds-intro/adding-probabilistic-types.html#footnotes",
    "href": "pds-intro/adding-probabilistic-types.html#footnotes",
    "title": "Adding probabilistic types",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n See , where similar rules are presented in a somewhat more refined, dependently typed setting.↩︎\n We define \\(\\ct{factor}\\) here as a primitive of the language of probabilistic programs (i.e., a constant). In their continuation-based treatment, implement \\(\\ct{factor}\\) so that it has the scaling behavior described only informally here. One could (if they wanted to) interpret the current system into one that uses continuations, so that \\(\\ct{factor}\\) has the behavior needed.↩︎\n See Grove and Bernardy (2023) for further details.↩︎",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Adding probabilistic types"
    ]
  },
  {
    "objectID": "pds-intro/common-ground.html",
    "href": "pds-intro/common-ground.html",
    "title": "The common ground",
    "section": "",
    "text": "\\[\n\\newcommand{\\expr}[3]{\\begin{array}{c}\n#1 \\\\\n\\bbox[lightblue,5px]{#2}\n\\end{array} ⊢ #3}\n\\newcommand{\\ct}[1]{\\bbox[font-size: 0.8em]{\\mathsf{#1}}}\n\\newcommand{\\updct}[1]{\\ct{upd\\_#1}}\n\\newcommand{\\abbr}[1]{\\bbox[transform: scale(0.95)]{\\mathtt{#1}}}\n\\newcommand{\\pure}[1]{\\bbox[border: 1px solid orange]{\\bbox[border: 4px solid transparent]{#1}}}\n\\newcommand{\\return}[1]{\\bbox[border: 1px solid black]{\\bbox[border: 4px solid transparent]{#1}}}\n\\def\\P{\\mathtt{P}}\n\\def\\Q{\\mathtt{Q}}\n\\def\\True{\\ct{T}}\n\\def\\False{\\ct{F}}\n\\def\\ite{\\ct{if\\_then\\_else}}\n\\def\\Do{\\abbr{do}}\n\\]\n\nHere, we make good on the assumption mentioned earlier that common grounds amount to probability distributions over indices of some kind. In general, we will allow the meanings of expressions to be determined by indices in the following way. For any constants, e.g.,\n\\[\n\\begin{align*}\n\\ct{see} &: ι → e → e → t \\\\\n\\ct{ling} &: ι → e → t\n\\end{align*}\n\\]\netc., there are other constants\n\\[\n\\begin{align*}\n\\updct{see} &: (e → e → t) → ι → ι \\\\\n\\updct{ling} &: (e → t) → ι → ι\n\\end{align*}\n\\]\nwhich may update some index \\(i\\) with a particular value. Thus our theory of indices is effectively a theory of states and locations: any given index represents a kind of state; meanwhile, constants such as \\(\\ct{see}\\) and \\(\\ct{ling}\\) represent different locations associated with that state. For example, given some index \\(i\\), \\(\\updct{see}(p)(i)\\) is a new index just like \\(i\\), but where the value stored at the location \\(\\ct{see}\\) has been overwritten by \\(p\\). As a result, our constants should satisfy equations like the following:\n\n\\[\n\\begin{align*}\n\\ct{see}(\\updct{see}(p)(i)) &= p \\\\\n\\ct{see}(\\updct{ling}(p)(i)) &= \\ct{see}(i) \\\\[2mm]\n\\ct{ling}(\\updct{ling}(p)(i)) &= p \\\\\n\\ct{ling}(\\updct{see}(p)(i)) &= \\ct{ling}(i)\n\\end{align*}\n\\]\n\nThat is, when \\(\\ct{see}\\) encounters an index which has been updated at its associated location, it grabs the value that the index has been updated with. If it encounters an index which has been updated at a different location, it keeps looking. (Similarly, for \\(\\ct{ling}\\).)\nFinally, we define a common ground to be a probability distribution over indices.\n\nDefinition: a common ground is a probabilistic program of type \\(\\P ι\\).\n\nHere, again, \\(ι\\) is understood to be a variable over types: its type doesn’t really matter, as long as it can be understood as supporting the theory of states and locations described just above. We further define a constant representing a starting index, which we call ‘\\(\\ct{@}\\)’.\n\n\\[\\ct{@} : ι\\]\n\nLet’s briefly consider a concrete example. One way of defining a common ground is by encoding a distribution over heights for some entity; say, Jo. The following common ground updates the value stored for the constant \\(\\ct{height} : ι → e → r\\):\n\n\\[\n\\begin{array}[t]{l}\nh ∼ \\abbr{Normal}(0, 1) \\\\\n\\pure{\\updct{height}(λx.h)(\\ct{@})}\n\\end{array}\n\\]\n\nThis common ground encodes uncertainty about Jo’s height by associating it with a normal distribution centered at 0 and with a standard deviation of 1. Note that because we are considering only one individual—Jo—we can update the height value globally. If we wish to describe a common ground that encodes uncertainty about the heights of more than individual—say, Jo and Bo—we can make the function with which indices are updated a bit more sophisticated:\n\n\\[\n\\begin{array}[t]{l}\nh_{j} ∼ \\abbr{Normal}(0, 1) \\\\\nh_{b} ∼ \\abbr{Normal}(0, 1) \\\\\n\\pure{\\updct{height}(λx.\\ite(x = \\ct{j}, h_{j}, h_{b}))(\\ct{@})}\n\\end{array}\n\\]\n\nHere, \\(\\ite\\) should be understood as satisfying the following two equations:\n\n\\[\n\\begin{align*}\n\\ite(\\True, x, y) &= x \\\\\n\\ite(\\False, x, y) &= y\n\\end{align*}\n\\]\n\nThus the common ground in (5) updates the starting index with a value for \\(\\ct{height}\\) consisting of a function that returns \\(h_{j}\\) on the argument \\(\\ct{j}\\) (i.e., Jo) and \\(h_{b}\\) otherwise (i.e., when the argument is \\(\\ct{b}\\), i.e., Bo).",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "The common ground"
    ]
  },
  {
    "objectID": "pds-intro/delta-rules.html",
    "href": "pds-intro/delta-rules.html",
    "title": "Delta rules",
    "section": "",
    "text": "\\[\n\\newcommand{\\expr}[3]{\\begin{array}{c}\n#1 \\\\\n\\bbox[lightblue,5px]{#2}\n\\end{array} ⊢ #3}\n\\newcommand{\\ct}[1]{\\bbox[font-size: 0.8em]{\\mathsf{#1}}}\n\\newcommand{\\updct}[1]{\\ct{upd\\_#1}}\n\\newcommand{\\abbr}[1]{\\bbox[transform: scale(0.95)]{\\mathtt{#1}}}\n\\newcommand{\\pure}[1]{\\bbox[border: 1px solid orange]{\\bbox[border: 4px solid transparent]{#1}}}\n\\newcommand{\\return}[1]{\\bbox[border: 1px solid black]{\\bbox[border: 4px solid transparent]{#1}}}\n\\def\\P{\\mathtt{P}}\n\\def\\Q{\\mathtt{Q}}\n\\def\\True{\\ct{T}}\n\\def\\False{\\ct{F}}\n\\def\\ite{\\ct{if\\_then\\_else}}\n\\def\\Do{\\abbr{do}}\n\\]\nNow that we have constants, we would like to able to do things (i.e., compute) with them. For example, following the discussion here, we would like for the encoding of expressions such as\n\\[\n\\ct{CG}(\\updct{CG}(cg)(s))\n\\]\nto be able to be evaluated—in this case—to \\(cg\\). We implement computations involving constants in terms of what we call delta-rules.1 In Haskell, we encode these as the following type of function:\nThus a delta rule is a partial function taking terms onto terms. It is partial because any given rule may only apply to some constants. For example, a delta rule that performs arithmetic computations might be defined on constants representing real numbers—but not, for example, on constants representing truth values.\nHere we list some example rules. For clarity of presentation, the rules are defined using Haskell’s PatternSynonyms language extension. It should be fairly clear what the relevant synonyms abbreviate.",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Delta rules"
    ]
  },
  {
    "objectID": "pds-intro/delta-rules.html#footnotes",
    "href": "pds-intro/delta-rules.html#footnotes",
    "title": "Delta rules",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n Named after δ-reduction.↩︎",
    "crumbs": [
      "Introduction to probabilistic dynamic semantics",
      "Delta rules"
    ]
  }
]